{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cOuPcrympZNP",
    "outputId": "7d7aa666-7673-4d34-a1dc-7be90d7330ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x15a75f838b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hDlWkGH2pZNV"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ud7G5HtNpZNa"
   },
   "outputs": [],
   "source": [
    "args = {'batch_size': 128,\n",
    "        'lr': 3e-3,\n",
    "        'hidden_dim': 128,\n",
    "        'n_layers': 3,\n",
    "        'bidirectional': True,\n",
    "        'dropout': 0.25,\n",
    "        'n_epochs': 50\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M4q_7bs-pZNe"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/training_data/data1.csv\", sep=\",\")\n",
    "\n",
    "for i in range(2, 11):\n",
    "    if i != 3:\n",
    "        filename = \"../data/training_data/data\" + str(i) + \".csv\"\n",
    "        df = df.append(pd.read_csv(filename, sep=\",\"))\n",
    "import math\n",
    "\n",
    "train_num = math.ceil(0.7 * len(df))\n",
    "valid_num = math.ceil(0.9 * len(df))\n",
    "train_data = df.iloc[:train_num, :]\n",
    "valid_data = df.iloc[train_num:valid_num, :].reset_index()\n",
    "test_data = df.iloc[valid_num:, :].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1568, 0.4639, 0.3793])\n"
     ]
    }
   ],
   "source": [
    "num_positive = (df[\"sentiment\"] == \"positive\").sum()\n",
    "num_negative = (df[\"sentiment\"] == \"negative\").sum()\n",
    "num_neutral = (df[\"sentiment\"] == \"neutral\").sum()\n",
    "\n",
    "args[\"weight\"] = torch.tensor([num_negative / len(df), num_neutral / len(df), num_positive / len(df)], dtype=torch.float32)\n",
    "\n",
    "print(args[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_k0emIZYpZNh"
   },
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kc73gO9zpZNj"
   },
   "outputs": [],
   "source": [
    "tokenized_train = train_data['text'].apply((\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "tokenized_valid = valid_data['text'].apply((\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "tokenized_test = test_data['text'].apply((\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1yfrURp5pZNm",
    "outputId": "2f06b8f7-dc3c-420a-e7c1-8128dc116b6e"
   },
   "outputs": [],
   "source": [
    "# max_len = tokenizer.max_model_input_sizes['distilbert-base-uncased']\n",
    "\n",
    "# print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Xdf2dN5pZNp"
   },
   "outputs": [],
   "source": [
    "def get_max_len(tokenized):\n",
    "    max_len = 0\n",
    "    for i in tokenized.values:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    return max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HqyggJL0pZNr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "60\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "max_len_train = get_max_len(tokenized_train)\n",
    "print(max_len_train)\n",
    "max_len_valid = get_max_len(tokenized_valid)\n",
    "print(max_len_valid)\n",
    "max_len_test = get_max_len(tokenized_test)\n",
    "print(max_len_test)\n",
    "max_len = max([max_len_train, max_len_valid, max_len_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNbavbblpZNx"
   },
   "outputs": [],
   "source": [
    "padded_train = torch.tensor([i + [0] * (max_len - len(i)) \n",
    "                             for i in tokenized_train.values])\n",
    "padded_valid = torch.tensor([i + [0] * (max_len - len(i)) \n",
    "                             for i in tokenized_valid.values])\n",
    "padded_test = torch.tensor([i + [0] * (max_len - len(i)) \n",
    "                            for i in tokenized_test.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWoyP2sNpZN2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_label = torch.tensor(train_data['sentiment'].replace(\n",
    "    to_replace='positive', value=2).replace(\n",
    "    to_replace='negative', value=0).replace(\n",
    "    to_replace='neutral', value=1).to_numpy())\n",
    "valid_label = torch.tensor(valid_data['sentiment'].replace(\n",
    "    to_replace='positive', value=2).replace(\n",
    "    to_replace='negative', value=0).replace(\n",
    "    to_replace='neutral', value=1).to_numpy())\n",
    "test_label = torch.tensor(test_data['sentiment'].replace(\n",
    "    to_replace='positive', value=2).replace(\n",
    "    to_replace='negative', value=0).replace(\n",
    "    to_replace='neutral', value=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9l1JWIBpZN_"
   },
   "outputs": [],
   "source": [
    "# Define the dataset and data iterators\n",
    "class Dataset(data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, x, labels):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "\n",
    "        # Load data and get label\n",
    "        x = self.x[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KN8l3lb2pZOB"
   },
   "outputs": [],
   "source": [
    "trainset = Dataset(padded_train, train_label)\n",
    "validset = Dataset(padded_valid, valid_label)\n",
    "testset = Dataset(padded_test, test_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset,\n",
    "                                           batch_size=args['batch_size'],\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "valid_loader = torch.utils.data.DataLoader(validset,\n",
    "                                           batch_size=args['batch_size'],\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(testset,\n",
    "                                           batch_size=args['batch_size'],\n",
    "                                           shuffle=True,\n",
    "                                           drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O38su5K_pZOF"
   },
   "outputs": [],
   "source": [
    "bert = DistilBertModel.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XvF4-cF-pZOH"
   },
   "outputs": [],
   "source": [
    "class BERTGRUSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 bert,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert = bert\n",
    "        \n",
    "        embedding_dim = bert.config.to_dict()['dim']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        #text = [batch size, sent len]\n",
    "        attention_mask = text.masked_fill(text != 0, 1)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(text, attention_mask=attention_mask)[0]\n",
    "                \n",
    "        #embedded = [batch size, sent len, emb dim]\n",
    "        \n",
    "        _, hidden = self.rnn(embedded)\n",
    "        \n",
    "        #hidden = [n layers * n directions, batch size, emb dim]\n",
    "        \n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "                \n",
    "        #hidden = [batch size, hid dim]\n",
    "        \n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        #output = [batch size, out dim]\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a_LOY0xrpZOJ"
   },
   "outputs": [],
   "source": [
    "model = BERTGRUSentiment(bert,\n",
    "                         args['hidden_dim'],\n",
    "                         3,\n",
    "                         args['n_layers'],\n",
    "                         args['bidirectional'],\n",
    "                         args['dropout'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fW94YLX-pZOQ"
   },
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9h1H2wJ5pZOM",
    "outputId": "9c1ddc1a-02dd-4148-854d-ae56ced5e82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,283,331 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "qTzScxaXpZOT",
    "outputId": "7630a095-52a0-4dd2-bcaf-1014da28254c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn.weight_ih_l0\n",
      "rnn.weight_hh_l0\n",
      "rnn.bias_ih_l0\n",
      "rnn.bias_hh_l0\n",
      "rnn.weight_ih_l0_reverse\n",
      "rnn.weight_hh_l0_reverse\n",
      "rnn.bias_ih_l0_reverse\n",
      "rnn.bias_hh_l0_reverse\n",
      "rnn.weight_ih_l1\n",
      "rnn.weight_hh_l1\n",
      "rnn.bias_ih_l1\n",
      "rnn.bias_hh_l1\n",
      "rnn.weight_ih_l1_reverse\n",
      "rnn.weight_hh_l1_reverse\n",
      "rnn.bias_ih_l1_reverse\n",
      "rnn.bias_hh_l1_reverse\n",
      "rnn.weight_ih_l2\n",
      "rnn.weight_hh_l2\n",
      "rnn.bias_ih_l2\n",
      "rnn.bias_hh_l2\n",
      "rnn.weight_ih_l2_reverse\n",
      "rnn.weight_hh_l2_reverse\n",
      "rnn.bias_ih_l2_reverse\n",
      "rnn.bias_hh_l2_reverse\n",
      "out.weight\n",
      "out.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bqpKLW5KpZOW"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
    "criterion = nn.CrossEntropyLoss(weight=args['weight'])\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CuYWWnMcpZOY"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_label):\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    y_pred_softmax = softmax(y_pred)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "\n",
    "    # accu\n",
    "    correct_pred = (y_pred_tags == y_label).float()\n",
    "    acc = correct_pred.sum() / len(y_label)\n",
    "\n",
    "    # roc-auc\n",
    "    one_hot_label = nn.functional.one_hot(y_label)\n",
    "    roc_auc = roc_auc_score(one_hot_label.detach().cpu(), y_pred_softmax.detach().cpu(), average=\"macro\")\n",
    "\n",
    "    # f1\n",
    "    f1 = f1_score(y_label.detach().cpu(), y_pred_tags.detach().cpu(), average='weighted')\n",
    "    \n",
    "    return acc, roc_auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PC4S8kt4pZOa"
   },
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_rocauc = 0\n",
    "    epoch_f1 = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(data).squeeze(1)\n",
    "        \n",
    "        loss = criterion(predictions, target)\n",
    "        \n",
    "        acc, roc_auc, f1 = multi_acc(predictions, target)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        epoch_rocauc += roc_auc\n",
    "        epoch_f1 += f1\n",
    "\n",
    "        print(\"batch idx {}: | train loss: {} | train accu: {:.3f} | train roc: {:.3f} | train f1: {}\".format(\n",
    "            batch_idx, loss.item(), acc.item(), roc_auc, f1))\n",
    "        \n",
    "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader), epoch_rocauc / len(data_loader), epoch_f1 / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJWccuIGpZOd"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_rocauc = 0\n",
    "    epoch_f1 = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch_idx, (data, target) in enumerate(data_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            predictions = model(data).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, target)\n",
    "            \n",
    "            acc, roc_auc, f1 = multi_acc(predictions, target)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_rocauc += roc_auc\n",
    "            epoch_f1 += f1\n",
    "        \n",
    "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader), epoch_rocauc / len(data_loader), epoch_f1 / len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ANdP4TtjpZOg"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "hkGmKBdcpZOl",
    "outputId": "1f634257-c5a8-499c-f379-48f183f486cd",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 0: | train loss: 0.7391921877861023 | train accu: 0.609 | train roc: 0.765 | train f1: 0.5658255912162161\n",
      "batch idx 1: | train loss: 0.6732923984527588 | train accu: 0.641 | train roc: 0.823 | train f1: 0.5774831964152353\n",
      "batch idx 2: | train loss: 0.5953079462051392 | train accu: 0.672 | train roc: 0.859 | train f1: 0.637475397040858\n",
      "batch idx 3: | train loss: 0.5380573272705078 | train accu: 0.742 | train roc: 0.857 | train f1: 0.7267660440613026\n",
      "batch idx 4: | train loss: 0.6385010480880737 | train accu: 0.656 | train roc: 0.818 | train f1: 0.6272423094997107\n",
      "batch idx 5: | train loss: 0.7005694508552551 | train accu: 0.594 | train roc: 0.817 | train f1: 0.5361637654613817\n",
      "batch idx 6: | train loss: 0.6688470244407654 | train accu: 0.617 | train roc: 0.829 | train f1: 0.5833167170105893\n",
      "batch idx 7: | train loss: 0.5266201496124268 | train accu: 0.742 | train roc: 0.887 | train f1: 0.7357954545454546\n",
      "batch idx 8: | train loss: 0.6955465078353882 | train accu: 0.609 | train roc: 0.827 | train f1: 0.597608604845447\n",
      "batch idx 9: | train loss: 0.6724057793617249 | train accu: 0.633 | train roc: 0.824 | train f1: 0.6077197025954972\n",
      "batch idx 10: | train loss: 0.5932299494743347 | train accu: 0.711 | train roc: 0.843 | train f1: 0.7041306315366052\n",
      "batch idx 11: | train loss: 0.657699704170227 | train accu: 0.609 | train roc: 0.824 | train f1: 0.582000248015873\n",
      "batch idx 12: | train loss: 0.5988573431968689 | train accu: 0.656 | train roc: 0.884 | train f1: 0.6248750868960724\n",
      "batch idx 13: | train loss: 0.7052795886993408 | train accu: 0.633 | train roc: 0.700 | train f1: 0.5969104960231748\n",
      "batch idx 14: | train loss: 0.6738007664680481 | train accu: 0.609 | train roc: 0.815 | train f1: 0.5803187086092715\n",
      "batch idx 15: | train loss: 0.5811520218849182 | train accu: 0.680 | train roc: 0.841 | train f1: 0.6279887621858979\n",
      "batch idx 16: | train loss: 0.583328902721405 | train accu: 0.680 | train roc: 0.811 | train f1: 0.6485933503836318\n",
      "batch idx 17: | train loss: 0.604920506477356 | train accu: 0.711 | train roc: 0.845 | train f1: 0.690238535101065\n",
      "batch idx 18: | train loss: 0.6606519818305969 | train accu: 0.688 | train roc: 0.783 | train f1: 0.6595102616476997\n",
      "batch idx 19: | train loss: 0.6510605812072754 | train accu: 0.617 | train roc: 0.859 | train f1: 0.5498351926977687\n",
      "batch idx 20: | train loss: 0.6569803357124329 | train accu: 0.641 | train roc: 0.834 | train f1: 0.5831356143856146\n",
      "batch idx 21: | train loss: 0.566260814666748 | train accu: 0.695 | train roc: 0.866 | train f1: 0.652717731829574\n",
      "batch idx 22: | train loss: 0.5612649917602539 | train accu: 0.742 | train roc: 0.885 | train f1: 0.7342680723660692\n",
      "batch idx 23: | train loss: 0.6149345636367798 | train accu: 0.727 | train roc: 0.842 | train f1: 0.7150203903106193\n",
      "batch idx 24: | train loss: 0.6606613397598267 | train accu: 0.641 | train roc: 0.816 | train f1: 0.6244922693920336\n",
      "batch idx 25: | train loss: 0.607030987739563 | train accu: 0.680 | train roc: 0.839 | train f1: 0.6454169561131089\n",
      "batch idx 26: | train loss: 0.6634141206741333 | train accu: 0.641 | train roc: 0.832 | train f1: 0.6188179130712688\n",
      "batch idx 27: | train loss: 0.5375595092773438 | train accu: 0.711 | train roc: 0.895 | train f1: 0.6865111603807816\n",
      "batch idx 28: | train loss: 0.6465845108032227 | train accu: 0.625 | train roc: 0.843 | train f1: 0.5739836626139818\n",
      "batch idx 29: | train loss: 0.6433985829353333 | train accu: 0.633 | train roc: 0.835 | train f1: 0.5788415404040403\n",
      "batch idx 30: | train loss: 0.7129921317100525 | train accu: 0.664 | train roc: 0.814 | train f1: 0.6547358734567259\n",
      "batch idx 31: | train loss: 0.688627302646637 | train accu: 0.609 | train roc: 0.815 | train f1: 0.6086706705295686\n",
      "batch idx 32: | train loss: 0.6413323283195496 | train accu: 0.688 | train roc: 0.860 | train f1: 0.6858596517119244\n",
      "batch idx 33: | train loss: 0.7125528454780579 | train accu: 0.617 | train roc: 0.828 | train f1: 0.605506786754729\n",
      "batch idx 34: | train loss: 0.6317210793495178 | train accu: 0.625 | train roc: 0.835 | train f1: 0.5707040355477855\n",
      "batch idx 35: | train loss: 0.6899257898330688 | train accu: 0.594 | train roc: 0.812 | train f1: 0.5544923698646125\n",
      "batch idx 36: | train loss: 0.5934246778488159 | train accu: 0.688 | train roc: 0.824 | train f1: 0.6489536830357143\n",
      "batch idx 37: | train loss: 0.5849685072898865 | train accu: 0.695 | train roc: 0.856 | train f1: 0.6516742186385043\n",
      "batch idx 38: | train loss: 0.6915361881256104 | train accu: 0.609 | train roc: 0.824 | train f1: 0.5555733618233618\n",
      "batch idx 39: | train loss: 0.6959671974182129 | train accu: 0.586 | train roc: 0.783 | train f1: 0.5426933726874391\n",
      "batch idx 40: | train loss: 0.5973622798919678 | train accu: 0.672 | train roc: 0.836 | train f1: 0.6439505347593584\n",
      "batch idx 41: | train loss: 0.65511554479599 | train accu: 0.641 | train roc: 0.848 | train f1: 0.5902264719254375\n",
      "batch idx 42: | train loss: 0.5990355014801025 | train accu: 0.719 | train roc: 0.854 | train f1: 0.6938863562357538\n",
      "batch idx 43: | train loss: 0.6206119060516357 | train accu: 0.656 | train roc: 0.840 | train f1: 0.6238137693423598\n",
      "batch idx 44: | train loss: 0.6611902713775635 | train accu: 0.633 | train roc: 0.824 | train f1: 0.5922294539187227\n",
      "batch idx 45: | train loss: 0.5233362317085266 | train accu: 0.734 | train roc: 0.901 | train f1: 0.693790127195639\n",
      "batch idx 46: | train loss: 0.6626527905464172 | train accu: 0.602 | train roc: 0.825 | train f1: 0.5710751555082665\n",
      "batch idx 47: | train loss: 0.605617880821228 | train accu: 0.664 | train roc: 0.864 | train f1: 0.6381181318681319\n",
      "batch idx 48: | train loss: 0.5888971090316772 | train accu: 0.703 | train roc: 0.869 | train f1: 0.6909873558048231\n",
      "batch idx 49: | train loss: 0.6000206470489502 | train accu: 0.641 | train roc: 0.860 | train f1: 0.6218391296141187\n",
      "batch idx 50: | train loss: 0.5962347984313965 | train accu: 0.680 | train roc: 0.854 | train f1: 0.6664819739952718\n",
      "batch idx 51: | train loss: 0.5842180848121643 | train accu: 0.688 | train roc: 0.855 | train f1: 0.6743687509597502\n",
      "batch idx 52: | train loss: 0.5955214500427246 | train accu: 0.727 | train roc: 0.835 | train f1: 0.7109341017833841\n",
      "batch idx 53: | train loss: 0.6382697224617004 | train accu: 0.680 | train roc: 0.829 | train f1: 0.6680456459008617\n",
      "batch idx 54: | train loss: 0.621222734451294 | train accu: 0.703 | train roc: 0.787 | train f1: 0.6829280231829574\n",
      "batch idx 55: | train loss: 0.5950183272361755 | train accu: 0.641 | train roc: 0.849 | train f1: 0.5940660584886128\n",
      "batch idx 56: | train loss: 0.6570994853973389 | train accu: 0.594 | train roc: 0.856 | train f1: 0.5639214925100475\n",
      "batch idx 57: | train loss: 0.5536319613456726 | train accu: 0.727 | train roc: 0.864 | train f1: 0.7152355154659512\n",
      "batch idx 58: | train loss: 0.5406237244606018 | train accu: 0.750 | train roc: 0.888 | train f1: 0.7442274305555556\n",
      "batch idx 59: | train loss: 0.5230998396873474 | train accu: 0.727 | train roc: 0.895 | train f1: 0.7162888531856941\n",
      "batch idx 60: | train loss: 0.7020189762115479 | train accu: 0.641 | train roc: 0.819 | train f1: 0.6228472222222223\n",
      "batch idx 61: | train loss: 0.5777412056922913 | train accu: 0.703 | train roc: 0.866 | train f1: 0.6826114898511301\n",
      "batch idx 62: | train loss: 0.654656171798706 | train accu: 0.641 | train roc: 0.825 | train f1: 0.5983391608391608\n",
      "batch idx 63: | train loss: 0.6246063113212585 | train accu: 0.617 | train roc: 0.853 | train f1: 0.5684572477827052\n",
      "batch idx 64: | train loss: 0.6107632517814636 | train accu: 0.695 | train roc: 0.837 | train f1: 0.66085623065707\n",
      "batch idx 65: | train loss: 0.6215791702270508 | train accu: 0.633 | train roc: 0.844 | train f1: 0.5807186362059996\n",
      "batch idx 66: | train loss: 0.6180479526519775 | train accu: 0.688 | train roc: 0.829 | train f1: 0.6544173894431209\n",
      "batch idx 67: | train loss: 0.5169376730918884 | train accu: 0.766 | train roc: 0.900 | train f1: 0.752937095197806\n",
      "batch idx 68: | train loss: 0.5710166096687317 | train accu: 0.703 | train roc: 0.860 | train f1: 0.6926550316764133\n",
      "batch idx 69: | train loss: 0.5966620445251465 | train accu: 0.695 | train roc: 0.852 | train f1: 0.681917268237082\n",
      "batch idx 70: | train loss: 0.6040986776351929 | train accu: 0.664 | train roc: 0.852 | train f1: 0.6380462815288739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 71: | train loss: 0.6074802875518799 | train accu: 0.641 | train roc: 0.868 | train f1: 0.6171826893472906\n",
      "batch idx 72: | train loss: 0.6048340797424316 | train accu: 0.688 | train roc: 0.849 | train f1: 0.6736773757740773\n",
      "batch idx 73: | train loss: 0.6174636483192444 | train accu: 0.688 | train roc: 0.844 | train f1: 0.6816752772177419\n",
      "batch idx 74: | train loss: 0.6100317239761353 | train accu: 0.742 | train roc: 0.847 | train f1: 0.7347996760548297\n",
      "batch idx 75: | train loss: 0.6456020474433899 | train accu: 0.656 | train roc: 0.857 | train f1: 0.6469127463445645\n",
      "batch idx 76: | train loss: 0.6313872337341309 | train accu: 0.672 | train roc: 0.866 | train f1: 0.6690546772068511\n",
      "batch idx 77: | train loss: 0.5901423692703247 | train accu: 0.664 | train roc: 0.907 | train f1: 0.6462786181672503\n",
      "batch idx 78: | train loss: 0.677832305431366 | train accu: 0.641 | train roc: 0.793 | train f1: 0.6182996323529412\n",
      "batch idx 79: | train loss: 0.7062072157859802 | train accu: 0.633 | train roc: 0.818 | train f1: 0.592415199742786\n",
      "batch idx 80: | train loss: 0.6212483048439026 | train accu: 0.664 | train roc: 0.843 | train f1: 0.6217355315674891\n",
      "batch idx 81: | train loss: 0.704330563545227 | train accu: 0.609 | train roc: 0.812 | train f1: 0.5932765151515151\n",
      "batch idx 82: | train loss: 0.5986830592155457 | train accu: 0.711 | train roc: 0.846 | train f1: 0.6871603260869565\n",
      "batch idx 83: | train loss: 0.6412596106529236 | train accu: 0.641 | train roc: 0.842 | train f1: 0.619625806707575\n",
      "batch idx 84: | train loss: 0.6628578305244446 | train accu: 0.609 | train roc: 0.837 | train f1: 0.5715881371963362\n",
      "batch idx 85: | train loss: 0.6844044923782349 | train accu: 0.609 | train roc: 0.837 | train f1: 0.5673578246570947\n",
      "batch idx 86: | train loss: 0.6077062487602234 | train accu: 0.672 | train roc: 0.860 | train f1: 0.6359994172494171\n",
      "batch idx 87: | train loss: 0.7203152179718018 | train accu: 0.625 | train roc: 0.798 | train f1: 0.6294793316870126\n",
      "batch idx 88: | train loss: 0.6370237469673157 | train accu: 0.664 | train roc: 0.833 | train f1: 0.6302111996483988\n",
      "batch idx 89: | train loss: 0.5954825282096863 | train accu: 0.672 | train roc: 0.828 | train f1: 0.6235251056067588\n",
      "batch idx 90: | train loss: 0.671532154083252 | train accu: 0.578 | train roc: 0.860 | train f1: 0.5099180970457171\n",
      "batch idx 91: | train loss: 0.6249064803123474 | train accu: 0.648 | train roc: 0.864 | train f1: 0.6188567907130267\n",
      "batch idx 92: | train loss: 0.6108877658843994 | train accu: 0.672 | train roc: 0.830 | train f1: 0.6162651290248915\n",
      "batch idx 93: | train loss: 0.6654003858566284 | train accu: 0.672 | train roc: 0.838 | train f1: 0.6268317152335608\n",
      "batch idx 94: | train loss: 0.5572420358657837 | train accu: 0.672 | train roc: 0.856 | train f1: 0.6401120464894241\n",
      "batch idx 95: | train loss: 0.6200180649757385 | train accu: 0.664 | train roc: 0.854 | train f1: 0.6480877422203132\n",
      "batch idx 96: | train loss: 0.6260425448417664 | train accu: 0.656 | train roc: 0.850 | train f1: 0.6182919477256607\n",
      "batch idx 97: | train loss: 0.5794084668159485 | train accu: 0.688 | train roc: 0.878 | train f1: 0.6838822467854726\n",
      "batch idx 98: | train loss: 0.5595109462738037 | train accu: 0.711 | train roc: 0.867 | train f1: 0.6919407758869935\n",
      "batch idx 99: | train loss: 0.5132826566696167 | train accu: 0.703 | train roc: 0.893 | train f1: 0.6814882593093405\n",
      "batch idx 100: | train loss: 0.7037880420684814 | train accu: 0.578 | train roc: 0.813 | train f1: 0.5389513747777496\n",
      "batch idx 101: | train loss: 0.7107558250427246 | train accu: 0.680 | train roc: 0.823 | train f1: 0.6604289071680376\n",
      "batch idx 102: | train loss: 0.6754497289657593 | train accu: 0.703 | train roc: 0.837 | train f1: 0.6876672735694893\n",
      "batch idx 103: | train loss: 0.6240821480751038 | train accu: 0.711 | train roc: 0.847 | train f1: 0.704697217039801\n",
      "batch idx 104: | train loss: 0.5825390815734863 | train accu: 0.734 | train roc: 0.873 | train f1: 0.731286795626577\n",
      "batch idx 105: | train loss: 0.646332323551178 | train accu: 0.664 | train roc: 0.849 | train f1: 0.6471359194015445\n",
      "batch idx 106: | train loss: 0.7016961574554443 | train accu: 0.648 | train roc: 0.799 | train f1: 0.613143993534377\n",
      "batch idx 107: | train loss: 0.6823437213897705 | train accu: 0.586 | train roc: 0.856 | train f1: 0.5412496601305099\n",
      "batch idx 108: | train loss: 0.5809353590011597 | train accu: 0.656 | train roc: 0.864 | train f1: 0.6254430376332485\n",
      "batch idx 109: | train loss: 0.620309591293335 | train accu: 0.672 | train roc: 0.862 | train f1: 0.6314388599339257\n",
      "batch idx 110: | train loss: 0.6613860130310059 | train accu: 0.656 | train roc: 0.834 | train f1: 0.6036551941049604\n",
      "batch idx 111: | train loss: 0.5520854592323303 | train accu: 0.758 | train roc: 0.898 | train f1: 0.741355033059697\n",
      "batch idx 112: | train loss: 0.7195457816123962 | train accu: 0.570 | train roc: 0.808 | train f1: 0.5611859383526936\n",
      "batch idx 113: | train loss: 0.6431992650032043 | train accu: 0.672 | train roc: 0.834 | train f1: 0.6524906255981842\n",
      "batch idx 114: | train loss: 0.6202220916748047 | train accu: 0.672 | train roc: 0.832 | train f1: 0.676428869262921\n",
      "batch idx 115: | train loss: 0.5496268272399902 | train accu: 0.719 | train roc: 0.893 | train f1: 0.7113041976259514\n",
      "batch idx 116: | train loss: 0.5838302373886108 | train accu: 0.719 | train roc: 0.867 | train f1: 0.7038516255282367\n",
      "batch idx 117: | train loss: 0.6474193930625916 | train accu: 0.633 | train roc: 0.841 | train f1: 0.5998465401785714\n",
      "batch idx 118: | train loss: 0.6149943470954895 | train accu: 0.648 | train roc: 0.852 | train f1: 0.6185447454844006\n",
      "batch idx 119: | train loss: 0.49778828024864197 | train accu: 0.750 | train roc: 0.897 | train f1: 0.7196256038647343\n",
      "batch idx 120: | train loss: 0.5195633172988892 | train accu: 0.703 | train roc: 0.887 | train f1: 0.6502576657863849\n",
      "batch idx 121: | train loss: 0.6527020931243896 | train accu: 0.688 | train roc: 0.828 | train f1: 0.6439149416702233\n",
      "batch idx 122: | train loss: 0.618094801902771 | train accu: 0.680 | train roc: 0.832 | train f1: 0.6505722698600434\n",
      "batch idx 123: | train loss: 0.5989928841590881 | train accu: 0.703 | train roc: 0.851 | train f1: 0.6681142683837253\n",
      "batch idx 124: | train loss: 0.5976627469062805 | train accu: 0.727 | train roc: 0.840 | train f1: 0.719007648678591\n",
      "batch idx 125: | train loss: 0.6625542044639587 | train accu: 0.609 | train roc: 0.820 | train f1: 0.5657059110893992\n",
      "batch idx 126: | train loss: 0.5845649242401123 | train accu: 0.664 | train roc: 0.862 | train f1: 0.6467533073270013\n",
      "batch idx 127: | train loss: 0.623088538646698 | train accu: 0.664 | train roc: 0.849 | train f1: 0.6171770702962036\n",
      "batch idx 128: | train loss: 0.6259298324584961 | train accu: 0.648 | train roc: 0.858 | train f1: 0.6358173536338672\n",
      "batch idx 129: | train loss: 0.6064272522926331 | train accu: 0.695 | train roc: 0.869 | train f1: 0.6794181034482758\n",
      "batch idx 130: | train loss: 0.5884175896644592 | train accu: 0.703 | train roc: 0.882 | train f1: 0.6974373156342183\n",
      "batch idx 131: | train loss: 0.5298937559127808 | train accu: 0.781 | train roc: 0.895 | train f1: 0.7791666666666668\n",
      "batch idx 132: | train loss: 0.5719591379165649 | train accu: 0.703 | train roc: 0.876 | train f1: 0.6970012626262626\n",
      "batch idx 133: | train loss: 0.49223724007606506 | train accu: 0.727 | train roc: 0.926 | train f1: 0.7122820973990038\n",
      "batch idx 134: | train loss: 0.4892747402191162 | train accu: 0.781 | train roc: 0.883 | train f1: 0.770471885451505\n",
      "batch idx 135: | train loss: 0.6415331363677979 | train accu: 0.625 | train roc: 0.847 | train f1: 0.6059357287014772\n",
      "batch idx 136: | train loss: 0.581208348274231 | train accu: 0.680 | train roc: 0.841 | train f1: 0.6580116689767532\n",
      "batch idx 137: | train loss: 0.6164752244949341 | train accu: 0.648 | train roc: 0.847 | train f1: 0.6043142294835022\n",
      "batch idx 138: | train loss: 0.7238461375236511 | train accu: 0.617 | train roc: 0.799 | train f1: 0.5955151342451874\n",
      "batch idx 139: | train loss: 0.5619854927062988 | train accu: 0.688 | train roc: 0.857 | train f1: 0.6702626811594203\n",
      "batch idx 140: | train loss: 0.5290985107421875 | train accu: 0.734 | train roc: 0.889 | train f1: 0.722867724403927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 141: | train loss: 0.5984336733818054 | train accu: 0.656 | train roc: 0.863 | train f1: 0.6529928167721648\n",
      "batch idx 142: | train loss: 0.622446596622467 | train accu: 0.656 | train roc: 0.849 | train f1: 0.6401164367358478\n",
      "batch idx 143: | train loss: 0.5644274950027466 | train accu: 0.711 | train roc: 0.876 | train f1: 0.6947164967385555\n",
      "batch idx 144: | train loss: 0.5138830542564392 | train accu: 0.742 | train roc: 0.876 | train f1: 0.6991050642587094\n",
      "batch idx 145: | train loss: 0.6772159934043884 | train accu: 0.562 | train roc: 0.846 | train f1: 0.522317587334366\n",
      "batch idx 146: | train loss: 0.6039571166038513 | train accu: 0.648 | train roc: 0.854 | train f1: 0.6362598288621646\n",
      "batch idx 147: | train loss: 0.6610156893730164 | train accu: 0.680 | train roc: 0.809 | train f1: 0.6675848606488051\n",
      "batch idx 148: | train loss: 0.49540936946868896 | train accu: 0.711 | train roc: 0.921 | train f1: 0.6828265249222024\n",
      "batch idx 149: | train loss: 0.5505807995796204 | train accu: 0.719 | train roc: 0.881 | train f1: 0.6903709975369459\n",
      "batch idx 150: | train loss: 0.5714909434318542 | train accu: 0.680 | train roc: 0.860 | train f1: 0.6574652777777779\n",
      "batch idx 151: | train loss: 0.5629382133483887 | train accu: 0.711 | train roc: 0.869 | train f1: 0.6886344178082191\n",
      "batch idx 152: | train loss: 0.6051186919212341 | train accu: 0.680 | train roc: 0.863 | train f1: 0.6588423295454545\n",
      "batch idx 153: | train loss: 0.5324485898017883 | train accu: 0.711 | train roc: 0.869 | train f1: 0.6929186698717948\n",
      "batch idx 154: | train loss: 0.7129994034767151 | train accu: 0.578 | train roc: 0.869 | train f1: 0.5397796525657441\n",
      "batch idx 155: | train loss: 0.4991287589073181 | train accu: 0.758 | train roc: 0.892 | train f1: 0.7470861450640862\n",
      "batch idx 156: | train loss: 0.661890983581543 | train accu: 0.656 | train roc: 0.850 | train f1: 0.6515346908826094\n",
      "batch idx 157: | train loss: 0.49129849672317505 | train accu: 0.695 | train roc: 0.910 | train f1: 0.6742187125886756\n",
      "batch idx 158: | train loss: 0.655956506729126 | train accu: 0.609 | train roc: 0.818 | train f1: 0.5925604129153708\n",
      "batch idx 159: | train loss: 0.5147578120231628 | train accu: 0.734 | train roc: 0.898 | train f1: 0.7339482668067228\n",
      "batch idx 160: | train loss: 0.627972424030304 | train accu: 0.672 | train roc: 0.837 | train f1: 0.6623029726012906\n",
      "batch idx 161: | train loss: 0.5631110668182373 | train accu: 0.719 | train roc: 0.873 | train f1: 0.702199074074074\n",
      "batch idx 162: | train loss: 0.6938527822494507 | train accu: 0.578 | train roc: 0.831 | train f1: 0.5521822729988052\n",
      "batch idx 163: | train loss: 0.5960203409194946 | train accu: 0.680 | train roc: 0.856 | train f1: 0.656973942847071\n",
      "batch idx 164: | train loss: 0.5370389819145203 | train accu: 0.750 | train roc: 0.878 | train f1: 0.7426811594202898\n",
      "batch idx 165: | train loss: 0.5774863362312317 | train accu: 0.688 | train roc: 0.860 | train f1: 0.6627142022602889\n",
      "batch idx 166: | train loss: 0.5776998996734619 | train accu: 0.703 | train roc: 0.845 | train f1: 0.6614276699209325\n",
      "batch idx 167: | train loss: 0.5050666928291321 | train accu: 0.727 | train roc: 0.910 | train f1: 0.7110457955241329\n",
      "batch idx 168: | train loss: 0.5747479200363159 | train accu: 0.695 | train roc: 0.839 | train f1: 0.6661341149792237\n",
      "batch idx 169: | train loss: 0.5845091938972473 | train accu: 0.664 | train roc: 0.836 | train f1: 0.620442057942058\n",
      "batch idx 170: | train loss: 0.6741046905517578 | train accu: 0.609 | train roc: 0.821 | train f1: 0.5858675573338239\n",
      "batch idx 171: | train loss: 0.6198142170906067 | train accu: 0.648 | train roc: 0.830 | train f1: 0.608728287841191\n",
      "batch idx 172: | train loss: 0.5666847229003906 | train accu: 0.648 | train roc: 0.868 | train f1: 0.5983158891444689\n",
      "batch idx 173: | train loss: 0.5757296681404114 | train accu: 0.672 | train roc: 0.863 | train f1: 0.6312916149710504\n",
      "batch idx 174: | train loss: 0.5221322178840637 | train accu: 0.750 | train roc: 0.882 | train f1: 0.7205192415490727\n",
      "batch idx 175: | train loss: 0.6247162818908691 | train accu: 0.672 | train roc: 0.847 | train f1: 0.6346563235033063\n",
      "batch idx 176: | train loss: 0.5575018525123596 | train accu: 0.711 | train roc: 0.858 | train f1: 0.6808371839178862\n",
      "batch idx 177: | train loss: 0.6586530208587646 | train accu: 0.641 | train roc: 0.850 | train f1: 0.6237987656347601\n",
      "batch idx 178: | train loss: 0.6348277926445007 | train accu: 0.625 | train roc: 0.840 | train f1: 0.5917403010426265\n",
      "batch idx 179: | train loss: 0.49395981431007385 | train accu: 0.742 | train roc: 0.895 | train f1: 0.7242296128897594\n",
      "batch idx 180: | train loss: 0.5606221556663513 | train accu: 0.695 | train roc: 0.890 | train f1: 0.6866712603285714\n",
      "batch idx 181: | train loss: 0.5691331624984741 | train accu: 0.695 | train roc: 0.867 | train f1: 0.694295530051344\n",
      "batch idx 182: | train loss: 0.6154434680938721 | train accu: 0.680 | train roc: 0.861 | train f1: 0.6657564344005021\n",
      "batch idx 183: | train loss: 0.5763169527053833 | train accu: 0.719 | train roc: 0.841 | train f1: 0.6959918478260869\n",
      "batch idx 184: | train loss: 0.7152916789054871 | train accu: 0.602 | train roc: 0.798 | train f1: 0.5822237028892723\n",
      "batch idx 185: | train loss: 0.5796191096305847 | train accu: 0.727 | train roc: 0.865 | train f1: 0.688496797056517\n",
      "batch idx 186: | train loss: 0.5136124491691589 | train accu: 0.719 | train roc: 0.893 | train f1: 0.7122100359144983\n",
      "batch idx 187: | train loss: 0.5178500413894653 | train accu: 0.727 | train roc: 0.894 | train f1: 0.6906985495347564\n",
      "batch idx 188: | train loss: 0.6417880058288574 | train accu: 0.641 | train roc: 0.826 | train f1: 0.5986864697802199\n",
      "batch idx 189: | train loss: 0.5410975217819214 | train accu: 0.719 | train roc: 0.887 | train f1: 0.707617959486166\n",
      "batch idx 190: | train loss: 0.5633427500724792 | train accu: 0.734 | train roc: 0.888 | train f1: 0.7335262907459091\n",
      "batch idx 191: | train loss: 0.5404189825057983 | train accu: 0.734 | train roc: 0.889 | train f1: 0.7338756347072879\n",
      "batch idx 192: | train loss: 0.692375659942627 | train accu: 0.609 | train roc: 0.819 | train f1: 0.5868578767123287\n",
      "batch idx 193: | train loss: 0.6346653699874878 | train accu: 0.633 | train roc: 0.832 | train f1: 0.5882442496229261\n",
      "batch idx 194: | train loss: 0.551726758480072 | train accu: 0.688 | train roc: 0.893 | train f1: 0.6495655080213905\n",
      "batch idx 195: | train loss: 0.7145124077796936 | train accu: 0.625 | train roc: 0.826 | train f1: 0.590415092080051\n",
      "batch idx 196: | train loss: 0.5338190793991089 | train accu: 0.703 | train roc: 0.890 | train f1: 0.6546757622624835\n",
      "batch idx 197: | train loss: 0.6193315982818604 | train accu: 0.664 | train roc: 0.839 | train f1: 0.6381646683632509\n",
      "batch idx 198: | train loss: 0.49885857105255127 | train accu: 0.711 | train roc: 0.932 | train f1: 0.6925872008512222\n",
      "batch idx 199: | train loss: 0.5622011423110962 | train accu: 0.703 | train roc: 0.880 | train f1: 0.6754538127277825\n",
      "batch idx 200: | train loss: 0.7081115245819092 | train accu: 0.578 | train roc: 0.831 | train f1: 0.5528011718385984\n",
      "batch idx 201: | train loss: 0.5185112953186035 | train accu: 0.695 | train roc: 0.882 | train f1: 0.6627650561894378\n",
      "batch idx 202: | train loss: 0.5835317969322205 | train accu: 0.711 | train roc: 0.869 | train f1: 0.6844967067583048\n",
      "batch idx 203: | train loss: 0.5803259015083313 | train accu: 0.703 | train roc: 0.865 | train f1: 0.6718935648047526\n",
      "batch idx 204: | train loss: 0.5283329486846924 | train accu: 0.703 | train roc: 0.899 | train f1: 0.6861352495543672\n",
      "batch idx 205: | train loss: 0.5589112043380737 | train accu: 0.734 | train roc: 0.875 | train f1: 0.7233204691545453\n",
      "batch idx 206: | train loss: 0.5854591727256775 | train accu: 0.711 | train roc: 0.865 | train f1: 0.7095128676470588\n",
      "batch idx 207: | train loss: 0.5433488488197327 | train accu: 0.703 | train roc: 0.899 | train f1: 0.6905912769784173\n",
      "batch idx 208: | train loss: 0.6210780143737793 | train accu: 0.680 | train roc: 0.881 | train f1: 0.6660678475935828\n",
      "batch idx 209: | train loss: 0.5947751402854919 | train accu: 0.727 | train roc: 0.870 | train f1: 0.7265625\n",
      "batch idx 210: | train loss: 0.5582234263420105 | train accu: 0.734 | train roc: 0.896 | train f1: 0.7266489703989705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 211: | train loss: 0.6106320023536682 | train accu: 0.695 | train roc: 0.854 | train f1: 0.6808676421957671\n",
      "batch idx 212: | train loss: 0.6129406094551086 | train accu: 0.664 | train roc: 0.842 | train f1: 0.6531454392067959\n",
      "batch idx 213: | train loss: 0.6045274138450623 | train accu: 0.648 | train roc: 0.850 | train f1: 0.6326841490408264\n",
      "batch idx 214: | train loss: 0.6144751310348511 | train accu: 0.703 | train roc: 0.854 | train f1: 0.6887547348484848\n",
      "batch idx 215: | train loss: 0.6692363023757935 | train accu: 0.641 | train roc: 0.829 | train f1: 0.6147632129774988\n",
      "batch idx 216: | train loss: 0.5718383193016052 | train accu: 0.672 | train roc: 0.860 | train f1: 0.6419596006530848\n",
      "batch idx 217: | train loss: 0.5724655389785767 | train accu: 0.695 | train roc: 0.841 | train f1: 0.6616468702865761\n",
      "batch idx 218: | train loss: 0.6330844163894653 | train accu: 0.672 | train roc: 0.831 | train f1: 0.6449165059078852\n",
      "batch idx 219: | train loss: 0.6099568009376526 | train accu: 0.617 | train roc: 0.854 | train f1: 0.5714923469387754\n",
      "batch idx 220: | train loss: 0.5638614296913147 | train accu: 0.727 | train roc: 0.865 | train f1: 0.6900141812210778\n",
      "batch idx 221: | train loss: 0.5093501806259155 | train accu: 0.719 | train roc: 0.894 | train f1: 0.7016661140583553\n",
      "batch idx 222: | train loss: 0.6165609955787659 | train accu: 0.656 | train roc: 0.835 | train f1: 0.6194411421672942\n",
      "batch idx 223: | train loss: 0.5482633113861084 | train accu: 0.734 | train roc: 0.866 | train f1: 0.7126405423280424\n",
      "batch idx 224: | train loss: 0.6045263409614563 | train accu: 0.641 | train roc: 0.870 | train f1: 0.5971328596037898\n",
      "batch idx 225: | train loss: 0.4977787137031555 | train accu: 0.750 | train roc: 0.884 | train f1: 0.7219739984914515\n",
      "batch idx 226: | train loss: 0.5027837753295898 | train accu: 0.695 | train roc: 0.882 | train f1: 0.6454836268574573\n",
      "batch idx 227: | train loss: 0.5873069167137146 | train accu: 0.688 | train roc: 0.867 | train f1: 0.6500829720185947\n",
      "batch idx 228: | train loss: 0.5760061740875244 | train accu: 0.688 | train roc: 0.860 | train f1: 0.6560654024609598\n",
      "batch idx 229: | train loss: 0.6449644565582275 | train accu: 0.711 | train roc: 0.804 | train f1: 0.6756742179072277\n",
      "batch idx 230: | train loss: 0.6164036393165588 | train accu: 0.625 | train roc: 0.833 | train f1: 0.6011101191499358\n",
      "batch idx 231: | train loss: 0.5260793566703796 | train accu: 0.758 | train roc: 0.873 | train f1: 0.7478927705026142\n",
      "batch idx 232: | train loss: 0.5156323313713074 | train accu: 0.750 | train roc: 0.884 | train f1: 0.7304931836407378\n",
      "batch idx 233: | train loss: 0.6238017082214355 | train accu: 0.648 | train roc: 0.860 | train f1: 0.5962735276259866\n",
      "batch idx 234: | train loss: 0.5584415793418884 | train accu: 0.719 | train roc: 0.901 | train f1: 0.7053306061415715\n",
      "batch idx 235: | train loss: 0.5589193105697632 | train accu: 0.711 | train roc: 0.882 | train f1: 0.6973222026723785\n",
      "batch idx 236: | train loss: 0.6395840644836426 | train accu: 0.703 | train roc: 0.835 | train f1: 0.6989828418944273\n",
      "batch idx 237: | train loss: 0.5640684366226196 | train accu: 0.711 | train roc: 0.858 | train f1: 0.6982880904377881\n",
      "batch idx 238: | train loss: 0.5742071866989136 | train accu: 0.688 | train roc: 0.880 | train f1: 0.6564611486486487\n",
      "batch idx 239: | train loss: 0.6607892513275146 | train accu: 0.641 | train roc: 0.842 | train f1: 0.6158998252766453\n",
      "batch idx 240: | train loss: 0.5252578258514404 | train accu: 0.703 | train roc: 0.875 | train f1: 0.6601221537001898\n",
      "Epoch: 01 | Epoch Time: 2m 12s\n",
      "\tTrain Loss: 0.606 | Train Acc: 67.58 | Train rocauc: 0.8527539774578605 | Train f1: 0.6503506663266422%\n",
      "\t Val. Loss: 0.620 |  Val. Acc: 64.62 | Val. rocauc: 0.8519309017072969 | Val. f1: 0.6030149113248826%\n",
      "batch idx 0: | train loss: 0.6436759829521179 | train accu: 0.641 | train roc: 0.866 | train f1: 0.6177978892089262\n",
      "batch idx 1: | train loss: 0.5659299492835999 | train accu: 0.641 | train roc: 0.862 | train f1: 0.5840958358540028\n",
      "batch idx 2: | train loss: 0.4956384599208832 | train accu: 0.750 | train roc: 0.918 | train f1: 0.7372232444498069\n",
      "batch idx 3: | train loss: 0.5437000393867493 | train accu: 0.734 | train roc: 0.896 | train f1: 0.7297132554945054\n",
      "batch idx 4: | train loss: 0.4763055741786957 | train accu: 0.750 | train roc: 0.925 | train f1: 0.7449779293739969\n",
      "batch idx 5: | train loss: 0.6387186050415039 | train accu: 0.680 | train roc: 0.826 | train f1: 0.67279352846908\n",
      "batch idx 6: | train loss: 0.5465342402458191 | train accu: 0.719 | train roc: 0.882 | train f1: 0.7030973109626233\n",
      "batch idx 7: | train loss: 0.7339260578155518 | train accu: 0.586 | train roc: 0.804 | train f1: 0.5440129878105845\n",
      "batch idx 8: | train loss: 0.45512616634368896 | train accu: 0.742 | train roc: 0.906 | train f1: 0.7091224747474747\n",
      "batch idx 9: | train loss: 0.617479681968689 | train accu: 0.672 | train roc: 0.850 | train f1: 0.637166166764373\n",
      "batch idx 10: | train loss: 0.5491397380828857 | train accu: 0.633 | train roc: 0.882 | train f1: 0.5909416161217385\n",
      "batch idx 11: | train loss: 0.5670598745346069 | train accu: 0.664 | train roc: 0.888 | train f1: 0.612109375\n",
      "batch idx 12: | train loss: 0.5680897235870361 | train accu: 0.719 | train roc: 0.884 | train f1: 0.7108002463645087\n",
      "batch idx 13: | train loss: 0.6051167249679565 | train accu: 0.664 | train roc: 0.850 | train f1: 0.6544365488259543\n",
      "batch idx 14: | train loss: 0.5031864643096924 | train accu: 0.766 | train roc: 0.906 | train f1: 0.7457018061719966\n",
      "batch idx 15: | train loss: 0.5200455784797668 | train accu: 0.719 | train roc: 0.898 | train f1: 0.7034968535469108\n",
      "batch idx 16: | train loss: 0.49644455313682556 | train accu: 0.703 | train roc: 0.914 | train f1: 0.6910616066751478\n",
      "batch idx 17: | train loss: 0.55946946144104 | train accu: 0.750 | train roc: 0.887 | train f1: 0.7457125250668448\n",
      "batch idx 18: | train loss: 0.5712482333183289 | train accu: 0.703 | train roc: 0.898 | train f1: 0.6914462289403243\n",
      "batch idx 19: | train loss: 0.551902711391449 | train accu: 0.703 | train roc: 0.857 | train f1: 0.6919352079912424\n",
      "batch idx 20: | train loss: 0.48063498735427856 | train accu: 0.742 | train roc: 0.895 | train f1: 0.7154154150695367\n",
      "batch idx 21: | train loss: 0.5660823583602905 | train accu: 0.656 | train roc: 0.861 | train f1: 0.6024430990693379\n",
      "batch idx 22: | train loss: 0.5326189994812012 | train accu: 0.703 | train roc: 0.884 | train f1: 0.6822281079436036\n",
      "batch idx 23: | train loss: 0.6420778632164001 | train accu: 0.672 | train roc: 0.862 | train f1: 0.6345127971132529\n",
      "batch idx 24: | train loss: 0.5417804718017578 | train accu: 0.688 | train roc: 0.887 | train f1: 0.6390772082134322\n",
      "batch idx 25: | train loss: 0.5485793948173523 | train accu: 0.703 | train roc: 0.899 | train f1: 0.6982752732240437\n",
      "batch idx 26: | train loss: 0.5146470665931702 | train accu: 0.734 | train roc: 0.903 | train f1: 0.7309687748763523\n",
      "batch idx 27: | train loss: 0.5859723091125488 | train accu: 0.719 | train roc: 0.867 | train f1: 0.7184550056724532\n",
      "batch idx 28: | train loss: 0.6117895841598511 | train accu: 0.695 | train roc: 0.850 | train f1: 0.672726951357466\n",
      "batch idx 29: | train loss: 0.5131290555000305 | train accu: 0.711 | train roc: 0.895 | train f1: 0.680602933349941\n",
      "batch idx 30: | train loss: 0.5207291841506958 | train accu: 0.703 | train roc: 0.878 | train f1: 0.6631592042406973\n",
      "batch idx 31: | train loss: 0.5888797044754028 | train accu: 0.672 | train roc: 0.842 | train f1: 0.6307011673222611\n",
      "batch idx 32: | train loss: 0.50230473279953 | train accu: 0.734 | train roc: 0.871 | train f1: 0.7008152911632957\n",
      "batch idx 33: | train loss: 0.6159631013870239 | train accu: 0.633 | train roc: 0.842 | train f1: 0.5959872159090909\n",
      "batch idx 34: | train loss: 0.5314930081367493 | train accu: 0.734 | train roc: 0.866 | train f1: 0.7032499999999999\n",
      "batch idx 35: | train loss: 0.5012693405151367 | train accu: 0.695 | train roc: 0.907 | train f1: 0.6599152389883579\n",
      "batch idx 36: | train loss: 0.5336461067199707 | train accu: 0.727 | train roc: 0.849 | train f1: 0.6929824561403508\n",
      "batch idx 37: | train loss: 0.44154176115989685 | train accu: 0.812 | train roc: 0.909 | train f1: 0.8036774789029537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 38: | train loss: 0.5696861147880554 | train accu: 0.695 | train roc: 0.898 | train f1: 0.6736474419354603\n",
      "batch idx 39: | train loss: 0.6721664071083069 | train accu: 0.648 | train roc: 0.854 | train f1: 0.628418823455864\n",
      "batch idx 40: | train loss: 0.5255534052848816 | train accu: 0.742 | train roc: 0.893 | train f1: 0.7334146594684385\n",
      "batch idx 41: | train loss: 0.4659331440925598 | train accu: 0.750 | train roc: 0.913 | train f1: 0.7356750009370783\n",
      "batch idx 42: | train loss: 0.5757931470870972 | train accu: 0.672 | train roc: 0.879 | train f1: 0.6410280233025312\n",
      "batch idx 43: | train loss: 0.5607723593711853 | train accu: 0.711 | train roc: 0.879 | train f1: 0.6778058307926829\n",
      "batch idx 44: | train loss: 0.5932444930076599 | train accu: 0.688 | train roc: 0.857 | train f1: 0.6804998531717875\n",
      "batch idx 45: | train loss: 0.5335450172424316 | train accu: 0.703 | train roc: 0.887 | train f1: 0.6966401143790848\n",
      "batch idx 46: | train loss: 0.5549493432044983 | train accu: 0.727 | train roc: 0.889 | train f1: 0.7158846156584644\n",
      "batch idx 47: | train loss: 0.5336031317710876 | train accu: 0.688 | train roc: 0.877 | train f1: 0.6649337469362745\n",
      "batch idx 48: | train loss: 0.5154085159301758 | train accu: 0.727 | train roc: 0.915 | train f1: 0.7122444783834587\n",
      "batch idx 49: | train loss: 0.5307856798171997 | train accu: 0.727 | train roc: 0.882 | train f1: 0.7166594696199959\n",
      "batch idx 50: | train loss: 0.48439863324165344 | train accu: 0.781 | train roc: 0.895 | train f1: 0.7634213699165797\n",
      "batch idx 51: | train loss: 0.6050273180007935 | train accu: 0.688 | train roc: 0.842 | train f1: 0.6783728609437875\n",
      "batch idx 52: | train loss: 0.5130744576454163 | train accu: 0.742 | train roc: 0.860 | train f1: 0.7332654637159838\n",
      "batch idx 53: | train loss: 0.5150318741798401 | train accu: 0.719 | train roc: 0.862 | train f1: 0.684001649015236\n",
      "batch idx 54: | train loss: 0.46535709500312805 | train accu: 0.766 | train roc: 0.913 | train f1: 0.75954070008285\n",
      "batch idx 55: | train loss: 0.6077467799186707 | train accu: 0.711 | train roc: 0.824 | train f1: 0.6834660947712419\n",
      "batch idx 56: | train loss: 0.4876256287097931 | train accu: 0.742 | train roc: 0.889 | train f1: 0.7128494369635405\n",
      "batch idx 57: | train loss: 0.5449103713035583 | train accu: 0.711 | train roc: 0.880 | train f1: 0.6786658653846154\n",
      "batch idx 58: | train loss: 0.56000816822052 | train accu: 0.703 | train roc: 0.880 | train f1: 0.6899052402651201\n",
      "batch idx 59: | train loss: 0.6111142635345459 | train accu: 0.648 | train roc: 0.850 | train f1: 0.6292050603911528\n",
      "batch idx 60: | train loss: 0.5662868618965149 | train accu: 0.695 | train roc: 0.883 | train f1: 0.6752066536581182\n",
      "batch idx 61: | train loss: 0.6354659795761108 | train accu: 0.672 | train roc: 0.853 | train f1: 0.6582192641991124\n",
      "batch idx 62: | train loss: 0.6048621535301208 | train accu: 0.656 | train roc: 0.840 | train f1: 0.6428456072351421\n",
      "batch idx 63: | train loss: 0.4706520140171051 | train accu: 0.797 | train roc: 0.910 | train f1: 0.787720533033033\n",
      "batch idx 64: | train loss: 0.6004640460014343 | train accu: 0.680 | train roc: 0.887 | train f1: 0.6614152892561983\n",
      "batch idx 65: | train loss: 0.6009472012519836 | train accu: 0.672 | train roc: 0.847 | train f1: 0.6445985099337748\n",
      "batch idx 66: | train loss: 0.5880330801010132 | train accu: 0.719 | train roc: 0.886 | train f1: 0.7077106227106227\n",
      "batch idx 67: | train loss: 0.578334629535675 | train accu: 0.656 | train roc: 0.875 | train f1: 0.621532926068938\n",
      "batch idx 68: | train loss: 0.5429302453994751 | train accu: 0.695 | train roc: 0.892 | train f1: 0.6938541032982437\n",
      "batch idx 69: | train loss: 0.48169299960136414 | train accu: 0.797 | train roc: 0.900 | train f1: 0.79223755005005\n",
      "batch idx 70: | train loss: 0.5593164563179016 | train accu: 0.695 | train roc: 0.892 | train f1: 0.6895284913087003\n",
      "batch idx 71: | train loss: 0.6349746584892273 | train accu: 0.680 | train roc: 0.858 | train f1: 0.6582984161109161\n",
      "batch idx 72: | train loss: 0.636207640171051 | train accu: 0.688 | train roc: 0.830 | train f1: 0.6700668193413729\n",
      "batch idx 73: | train loss: 0.5926201939582825 | train accu: 0.672 | train roc: 0.885 | train f1: 0.6472934517258848\n",
      "batch idx 74: | train loss: 0.633704423904419 | train accu: 0.641 | train roc: 0.866 | train f1: 0.6185976647603485\n",
      "batch idx 75: | train loss: 0.5627351403236389 | train accu: 0.734 | train roc: 0.890 | train f1: 0.7318813998501499\n",
      "batch idx 76: | train loss: 0.5849778056144714 | train accu: 0.703 | train roc: 0.872 | train f1: 0.6962443487879953\n",
      "batch idx 77: | train loss: 0.6699622869491577 | train accu: 0.688 | train roc: 0.832 | train f1: 0.6818914591925538\n",
      "batch idx 78: | train loss: 0.577892005443573 | train accu: 0.719 | train roc: 0.878 | train f1: 0.7095661029484559\n",
      "batch idx 79: | train loss: 0.5388038158416748 | train accu: 0.727 | train roc: 0.890 | train f1: 0.7231969169246646\n",
      "batch idx 80: | train loss: 0.5374712347984314 | train accu: 0.727 | train roc: 0.893 | train f1: 0.7229285717520059\n",
      "batch idx 81: | train loss: 0.5498552322387695 | train accu: 0.719 | train roc: 0.881 | train f1: 0.6919887609649122\n",
      "batch idx 82: | train loss: 0.540942370891571 | train accu: 0.766 | train roc: 0.885 | train f1: 0.7493170228266148\n",
      "batch idx 83: | train loss: 0.5591816306114197 | train accu: 0.688 | train roc: 0.874 | train f1: 0.6530534839511589\n",
      "batch idx 84: | train loss: 0.5111451745033264 | train accu: 0.703 | train roc: 0.908 | train f1: 0.6719130299976747\n",
      "batch idx 85: | train loss: 0.5360922813415527 | train accu: 0.656 | train roc: 0.889 | train f1: 0.6232113768318037\n",
      "batch idx 86: | train loss: 0.6592438817024231 | train accu: 0.633 | train roc: 0.826 | train f1: 0.6014692473474801\n",
      "batch idx 87: | train loss: 0.5657479763031006 | train accu: 0.703 | train roc: 0.877 | train f1: 0.6906047077922078\n",
      "batch idx 88: | train loss: 0.5511860847473145 | train accu: 0.695 | train roc: 0.883 | train f1: 0.6473987913208097\n",
      "batch idx 89: | train loss: 0.5484068393707275 | train accu: 0.703 | train roc: 0.861 | train f1: 0.6894631821029847\n",
      "batch idx 90: | train loss: 0.6291695237159729 | train accu: 0.656 | train roc: 0.863 | train f1: 0.6477023193142812\n",
      "batch idx 91: | train loss: 0.5450625419616699 | train accu: 0.766 | train roc: 0.880 | train f1: 0.7625473484848485\n",
      "batch idx 92: | train loss: 0.5418388843536377 | train accu: 0.766 | train roc: 0.894 | train f1: 0.7642128075365153\n",
      "batch idx 93: | train loss: 0.6142127513885498 | train accu: 0.680 | train roc: 0.854 | train f1: 0.6685833289094159\n",
      "batch idx 94: | train loss: 0.5066651105880737 | train accu: 0.734 | train roc: 0.902 | train f1: 0.725597813025715\n",
      "batch idx 95: | train loss: 0.5946303009986877 | train accu: 0.680 | train roc: 0.850 | train f1: 0.6520020609869964\n",
      "batch idx 96: | train loss: 0.5578317642211914 | train accu: 0.688 | train roc: 0.863 | train f1: 0.6715016079276926\n",
      "batch idx 97: | train loss: 0.5274741053581238 | train accu: 0.742 | train roc: 0.890 | train f1: 0.7267781263320545\n",
      "batch idx 98: | train loss: 0.5619727969169617 | train accu: 0.711 | train roc: 0.884 | train f1: 0.6751346141332639\n",
      "batch idx 99: | train loss: 0.6215328574180603 | train accu: 0.680 | train roc: 0.840 | train f1: 0.6478599516031458\n",
      "batch idx 100: | train loss: 0.5856915712356567 | train accu: 0.672 | train roc: 0.869 | train f1: 0.6622353830645161\n",
      "batch idx 101: | train loss: 0.6507012844085693 | train accu: 0.648 | train roc: 0.855 | train f1: 0.6339783817304193\n",
      "batch idx 102: | train loss: 0.5905725359916687 | train accu: 0.719 | train roc: 0.866 | train f1: 0.7162960423197493\n",
      "batch idx 103: | train loss: 0.6178906559944153 | train accu: 0.711 | train roc: 0.866 | train f1: 0.7110617405968016\n",
      "batch idx 104: | train loss: 0.5734541416168213 | train accu: 0.750 | train roc: 0.861 | train f1: 0.7427379168450599\n",
      "batch idx 105: | train loss: 0.611700713634491 | train accu: 0.648 | train roc: 0.847 | train f1: 0.6339647690671397\n",
      "batch idx 106: | train loss: 0.5637025237083435 | train accu: 0.656 | train roc: 0.868 | train f1: 0.6204861284835143\n",
      "batch idx 107: | train loss: 0.5109401941299438 | train accu: 0.688 | train roc: 0.910 | train f1: 0.6617596726190476\n",
      "batch idx 108: | train loss: 0.6071235537528992 | train accu: 0.664 | train roc: 0.870 | train f1: 0.6439498001998003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 109: | train loss: 0.5792325735092163 | train accu: 0.742 | train roc: 0.854 | train f1: 0.7171026524644946\n",
      "batch idx 110: | train loss: 0.5324451327323914 | train accu: 0.688 | train roc: 0.880 | train f1: 0.665759154040404\n",
      "batch idx 111: | train loss: 0.5531772375106812 | train accu: 0.727 | train roc: 0.872 | train f1: 0.7103921058714748\n",
      "batch idx 112: | train loss: 0.5147844552993774 | train accu: 0.742 | train roc: 0.865 | train f1: 0.7177002644123343\n",
      "batch idx 113: | train loss: 0.6302530169487 | train accu: 0.641 | train roc: 0.845 | train f1: 0.6203343949044586\n",
      "batch idx 114: | train loss: 0.6487938165664673 | train accu: 0.617 | train roc: 0.837 | train f1: 0.563745843280275\n",
      "batch idx 115: | train loss: 0.557648777961731 | train accu: 0.719 | train roc: 0.883 | train f1: 0.7082290516501042\n",
      "batch idx 116: | train loss: 0.5709347128868103 | train accu: 0.727 | train roc: 0.868 | train f1: 0.7191883350388075\n",
      "batch idx 117: | train loss: 0.6871102452278137 | train accu: 0.641 | train roc: 0.837 | train f1: 0.6128419452887538\n",
      "batch idx 118: | train loss: 0.5397508144378662 | train accu: 0.711 | train roc: 0.878 | train f1: 0.6914820551788639\n",
      "batch idx 119: | train loss: 0.6454100608825684 | train accu: 0.602 | train roc: 0.841 | train f1: 0.567292264421625\n",
      "batch idx 120: | train loss: 0.49925780296325684 | train accu: 0.727 | train roc: 0.898 | train f1: 0.7065505777806191\n",
      "batch idx 121: | train loss: 0.5364980697631836 | train accu: 0.688 | train roc: 0.903 | train f1: 0.6571163862179488\n",
      "batch idx 122: | train loss: 0.5111876130104065 | train accu: 0.695 | train roc: 0.893 | train f1: 0.6653400424368733\n",
      "batch idx 123: | train loss: 0.6518176794052124 | train accu: 0.656 | train roc: 0.812 | train f1: 0.6317122593718338\n",
      "batch idx 124: | train loss: 0.5673084855079651 | train accu: 0.719 | train roc: 0.831 | train f1: 0.6880401136747802\n",
      "batch idx 125: | train loss: 0.6221092939376831 | train accu: 0.664 | train roc: 0.826 | train f1: 0.6360901233075436\n",
      "batch idx 126: | train loss: 0.5862088203430176 | train accu: 0.656 | train roc: 0.869 | train f1: 0.6081976232394366\n",
      "batch idx 127: | train loss: 0.6374238729476929 | train accu: 0.609 | train roc: 0.845 | train f1: 0.5614011501175931\n",
      "batch idx 128: | train loss: 0.5788629651069641 | train accu: 0.711 | train roc: 0.895 | train f1: 0.6977110403131768\n",
      "batch idx 129: | train loss: 0.6137950420379639 | train accu: 0.656 | train roc: 0.859 | train f1: 0.6402457524271845\n",
      "batch idx 130: | train loss: 0.5605107545852661 | train accu: 0.703 | train roc: 0.872 | train f1: 0.693359375\n",
      "batch idx 131: | train loss: 0.49501287937164307 | train accu: 0.781 | train roc: 0.916 | train f1: 0.7794187041833107\n",
      "batch idx 132: | train loss: 0.6583805680274963 | train accu: 0.664 | train roc: 0.849 | train f1: 0.6490720356979065\n",
      "batch idx 133: | train loss: 0.5065456628799438 | train accu: 0.711 | train roc: 0.901 | train f1: 0.6821129244015633\n",
      "batch idx 134: | train loss: 0.5399006605148315 | train accu: 0.711 | train roc: 0.885 | train f1: 0.6958339406685546\n",
      "batch idx 135: | train loss: 0.6281644701957703 | train accu: 0.672 | train roc: 0.872 | train f1: 0.6414588261287724\n",
      "batch idx 136: | train loss: 0.6559898853302002 | train accu: 0.656 | train roc: 0.852 | train f1: 0.6355657066388365\n",
      "batch idx 137: | train loss: 0.5075474977493286 | train accu: 0.719 | train roc: 0.912 | train f1: 0.7039288982319178\n",
      "batch idx 138: | train loss: 0.48748669028282166 | train accu: 0.773 | train roc: 0.920 | train f1: 0.7687807185006836\n",
      "batch idx 139: | train loss: 0.5988954901695251 | train accu: 0.727 | train roc: 0.861 | train f1: 0.7212238459879207\n",
      "batch idx 140: | train loss: 0.5470055341720581 | train accu: 0.711 | train roc: 0.882 | train f1: 0.6946211069996917\n",
      "batch idx 141: | train loss: 0.5510229468345642 | train accu: 0.688 | train roc: 0.878 | train f1: 0.6803072415865384\n",
      "batch idx 142: | train loss: 0.5842388272285461 | train accu: 0.672 | train roc: 0.856 | train f1: 0.6474276399491095\n",
      "batch idx 143: | train loss: 0.5515124797821045 | train accu: 0.688 | train roc: 0.878 | train f1: 0.6490214337071261\n",
      "batch idx 144: | train loss: 0.6384217739105225 | train accu: 0.641 | train roc: 0.840 | train f1: 0.5926027097902098\n",
      "batch idx 145: | train loss: 0.5255200862884521 | train accu: 0.703 | train roc: 0.890 | train f1: 0.6720981216272313\n",
      "batch idx 146: | train loss: 0.48426496982574463 | train accu: 0.750 | train roc: 0.912 | train f1: 0.7311829527718137\n",
      "batch idx 147: | train loss: 0.5694544315338135 | train accu: 0.688 | train roc: 0.848 | train f1: 0.6715876032282283\n",
      "batch idx 148: | train loss: 0.559739351272583 | train accu: 0.711 | train roc: 0.867 | train f1: 0.6882723595305832\n",
      "batch idx 149: | train loss: 0.47063857316970825 | train accu: 0.758 | train roc: 0.911 | train f1: 0.7492130672833649\n",
      "batch idx 150: | train loss: 0.5575220584869385 | train accu: 0.695 | train roc: 0.885 | train f1: 0.6847674288693579\n",
      "batch idx 151: | train loss: 0.5331234335899353 | train accu: 0.734 | train roc: 0.899 | train f1: 0.737305816040817\n",
      "batch idx 152: | train loss: 0.45812129974365234 | train accu: 0.773 | train roc: 0.926 | train f1: 0.760552903653916\n",
      "batch idx 153: | train loss: 0.48484474420547485 | train accu: 0.781 | train roc: 0.904 | train f1: 0.7695940218192541\n",
      "batch idx 154: | train loss: 0.6955182552337646 | train accu: 0.641 | train roc: 0.820 | train f1: 0.6297650709219857\n",
      "batch idx 155: | train loss: 0.6994460225105286 | train accu: 0.594 | train roc: 0.811 | train f1: 0.5386757425742574\n",
      "batch idx 156: | train loss: 0.6436930894851685 | train accu: 0.609 | train roc: 0.829 | train f1: 0.5624397154569568\n",
      "batch idx 157: | train loss: 0.5777968168258667 | train accu: 0.656 | train roc: 0.879 | train f1: 0.6232001606723521\n",
      "batch idx 158: | train loss: 0.6155686378479004 | train accu: 0.711 | train roc: 0.826 | train f1: 0.6841765556971435\n",
      "batch idx 159: | train loss: 0.588805615901947 | train accu: 0.688 | train roc: 0.849 | train f1: 0.6612079326923077\n",
      "batch idx 160: | train loss: 0.5667735934257507 | train accu: 0.711 | train roc: 0.852 | train f1: 0.6968838114241536\n",
      "batch idx 161: | train loss: 0.4828110933303833 | train accu: 0.703 | train roc: 0.914 | train f1: 0.6617160161606848\n",
      "batch idx 162: | train loss: 0.4821496903896332 | train accu: 0.781 | train roc: 0.910 | train f1: 0.7717862870890138\n",
      "batch idx 163: | train loss: 0.49017804861068726 | train accu: 0.758 | train roc: 0.920 | train f1: 0.753301380792896\n",
      "batch idx 164: | train loss: 0.5252488255500793 | train accu: 0.758 | train roc: 0.888 | train f1: 0.7410435692541857\n",
      "batch idx 165: | train loss: 0.5633997321128845 | train accu: 0.672 | train roc: 0.875 | train f1: 0.6454228940217391\n",
      "batch idx 166: | train loss: 0.5938931703567505 | train accu: 0.703 | train roc: 0.836 | train f1: 0.6871744791666667\n",
      "batch idx 167: | train loss: 0.5876923203468323 | train accu: 0.672 | train roc: 0.863 | train f1: 0.6403736965358785\n",
      "batch idx 168: | train loss: 0.5165339112281799 | train accu: 0.727 | train roc: 0.909 | train f1: 0.7127686581879129\n",
      "batch idx 169: | train loss: 0.5326024889945984 | train accu: 0.719 | train roc: 0.877 | train f1: 0.6945207595571616\n",
      "batch idx 170: | train loss: 0.7290570139884949 | train accu: 0.633 | train roc: 0.830 | train f1: 0.6175208417034954\n",
      "batch idx 171: | train loss: 0.5243449807167053 | train accu: 0.773 | train roc: 0.888 | train f1: 0.771099575150574\n",
      "batch idx 172: | train loss: 0.501514196395874 | train accu: 0.734 | train roc: 0.900 | train f1: 0.7294670928030305\n",
      "batch idx 173: | train loss: 0.583220362663269 | train accu: 0.703 | train roc: 0.868 | train f1: 0.6853434608125659\n",
      "batch idx 174: | train loss: 0.6474993228912354 | train accu: 0.672 | train roc: 0.836 | train f1: 0.657760840108401\n",
      "batch idx 175: | train loss: 0.6670106649398804 | train accu: 0.656 | train roc: 0.805 | train f1: 0.6478065150478797\n",
      "batch idx 176: | train loss: 0.4918649196624756 | train accu: 0.750 | train roc: 0.906 | train f1: 0.7284916139796277\n",
      "batch idx 177: | train loss: 0.6034581065177917 | train accu: 0.633 | train roc: 0.874 | train f1: 0.5894461213128976\n",
      "batch idx 178: | train loss: 0.5035190582275391 | train accu: 0.695 | train roc: 0.894 | train f1: 0.6545497555263646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 179: | train loss: 0.5058582425117493 | train accu: 0.711 | train roc: 0.894 | train f1: 0.6716162008281574\n",
      "batch idx 180: | train loss: 0.6031274199485779 | train accu: 0.594 | train roc: 0.850 | train f1: 0.5335881090454262\n",
      "batch idx 181: | train loss: 0.5133737921714783 | train accu: 0.688 | train roc: 0.881 | train f1: 0.6554657443410796\n",
      "batch idx 182: | train loss: 0.5930353403091431 | train accu: 0.695 | train roc: 0.855 | train f1: 0.6678453947368421\n",
      "batch idx 183: | train loss: 0.5303606390953064 | train accu: 0.734 | train roc: 0.880 | train f1: 0.7233416204131977\n",
      "batch idx 184: | train loss: 0.5928698182106018 | train accu: 0.727 | train roc: 0.852 | train f1: 0.7163106304639735\n",
      "batch idx 185: | train loss: 0.4218425750732422 | train accu: 0.789 | train roc: 0.938 | train f1: 0.7831835074327038\n",
      "batch idx 186: | train loss: 0.601362407207489 | train accu: 0.711 | train roc: 0.853 | train f1: 0.6990152994791667\n",
      "batch idx 187: | train loss: 0.6507884860038757 | train accu: 0.680 | train roc: 0.831 | train f1: 0.671135752688172\n",
      "batch idx 188: | train loss: 0.5919382572174072 | train accu: 0.719 | train roc: 0.868 | train f1: 0.7127406881313131\n",
      "batch idx 189: | train loss: 0.5231521129608154 | train accu: 0.719 | train roc: 0.888 | train f1: 0.7067646106329223\n",
      "batch idx 190: | train loss: 0.6407610774040222 | train accu: 0.656 | train roc: 0.842 | train f1: 0.629155585106383\n",
      "batch idx 191: | train loss: 0.5629821419715881 | train accu: 0.703 | train roc: 0.862 | train f1: 0.6560288757356876\n",
      "batch idx 192: | train loss: 0.5568583011627197 | train accu: 0.742 | train roc: 0.878 | train f1: 0.705670797413793\n",
      "batch idx 193: | train loss: 0.546625018119812 | train accu: 0.711 | train roc: 0.889 | train f1: 0.7058399314055488\n",
      "batch idx 194: | train loss: 0.5912370681762695 | train accu: 0.672 | train roc: 0.878 | train f1: 0.6708741169779693\n",
      "batch idx 195: | train loss: 0.6123332381248474 | train accu: 0.688 | train roc: 0.865 | train f1: 0.6853590398452348\n",
      "batch idx 196: | train loss: 0.6209017038345337 | train accu: 0.719 | train roc: 0.852 | train f1: 0.7161654135338347\n",
      "batch idx 197: | train loss: 0.5053035616874695 | train accu: 0.734 | train roc: 0.910 | train f1: 0.7237226436174992\n",
      "batch idx 198: | train loss: 0.6490691304206848 | train accu: 0.664 | train roc: 0.828 | train f1: 0.6408154121863799\n",
      "batch idx 199: | train loss: 0.5745600461959839 | train accu: 0.727 | train roc: 0.864 | train f1: 0.7109073200175591\n",
      "batch idx 200: | train loss: 0.6504443883895874 | train accu: 0.664 | train roc: 0.815 | train f1: 0.6270163043478262\n",
      "batch idx 201: | train loss: 0.5594943165779114 | train accu: 0.688 | train roc: 0.885 | train f1: 0.639796909350921\n",
      "batch idx 202: | train loss: 0.5435928702354431 | train accu: 0.703 | train roc: 0.875 | train f1: 0.6779386233660132\n",
      "batch idx 203: | train loss: 0.5451434850692749 | train accu: 0.719 | train roc: 0.880 | train f1: 0.6990391042780748\n",
      "batch idx 204: | train loss: 0.6124495267868042 | train accu: 0.633 | train roc: 0.845 | train f1: 0.5872981250601713\n",
      "batch idx 205: | train loss: 0.5401906967163086 | train accu: 0.688 | train roc: 0.902 | train f1: 0.66242447951533\n",
      "batch idx 206: | train loss: 0.4679587781429291 | train accu: 0.773 | train roc: 0.912 | train f1: 0.7668099130141242\n",
      "batch idx 207: | train loss: 0.5432536602020264 | train accu: 0.750 | train roc: 0.886 | train f1: 0.7404125644631974\n",
      "batch idx 208: | train loss: 0.6302645206451416 | train accu: 0.680 | train roc: 0.850 | train f1: 0.6755257914617745\n",
      "batch idx 209: | train loss: 0.5460317730903625 | train accu: 0.734 | train roc: 0.886 | train f1: 0.7292559208626167\n",
      "batch idx 210: | train loss: 0.614653468132019 | train accu: 0.703 | train roc: 0.870 | train f1: 0.6984070616883116\n",
      "batch idx 211: | train loss: 0.5710938572883606 | train accu: 0.680 | train roc: 0.869 | train f1: 0.6541024970095695\n",
      "batch idx 212: | train loss: 0.6845631003379822 | train accu: 0.609 | train roc: 0.837 | train f1: 0.5680872252747253\n",
      "batch idx 213: | train loss: 0.54228675365448 | train accu: 0.719 | train roc: 0.896 | train f1: 0.7143422433982072\n",
      "batch idx 214: | train loss: 0.5235652923583984 | train accu: 0.703 | train roc: 0.881 | train f1: 0.6887230701880728\n",
      "batch idx 215: | train loss: 0.578379213809967 | train accu: 0.664 | train roc: 0.839 | train f1: 0.6380709134615384\n",
      "batch idx 216: | train loss: 0.5724936723709106 | train accu: 0.711 | train roc: 0.873 | train f1: 0.7009191176470588\n",
      "batch idx 217: | train loss: 0.5368880033493042 | train accu: 0.734 | train roc: 0.900 | train f1: 0.726986592659796\n",
      "batch idx 218: | train loss: 0.473649799823761 | train accu: 0.688 | train roc: 0.904 | train f1: 0.6768233808674985\n",
      "batch idx 219: | train loss: 0.6672021746635437 | train accu: 0.609 | train roc: 0.825 | train f1: 0.5819876302008153\n",
      "batch idx 220: | train loss: 0.4557938277721405 | train accu: 0.789 | train roc: 0.904 | train f1: 0.7806197610068375\n",
      "batch idx 221: | train loss: 0.6948938369750977 | train accu: 0.617 | train roc: 0.825 | train f1: 0.5859617820945946\n",
      "batch idx 222: | train loss: 0.5317713022232056 | train accu: 0.695 | train roc: 0.890 | train f1: 0.643233590584134\n",
      "batch idx 223: | train loss: 0.6326597332954407 | train accu: 0.648 | train roc: 0.862 | train f1: 0.6326519971472273\n",
      "batch idx 224: | train loss: 0.7368102669715881 | train accu: 0.594 | train roc: 0.808 | train f1: 0.5733236309408185\n",
      "batch idx 225: | train loss: 0.5849545001983643 | train accu: 0.742 | train roc: 0.874 | train f1: 0.7379659803010501\n",
      "batch idx 226: | train loss: 0.647702693939209 | train accu: 0.641 | train roc: 0.865 | train f1: 0.6300118983477012\n",
      "batch idx 227: | train loss: 0.6391379237174988 | train accu: 0.711 | train roc: 0.861 | train f1: 0.703741991859873\n",
      "batch idx 228: | train loss: 0.5829354524612427 | train accu: 0.680 | train roc: 0.872 | train f1: 0.6719933712121211\n",
      "batch idx 229: | train loss: 0.5451622605323792 | train accu: 0.703 | train roc: 0.871 | train f1: 0.6665293461134454\n",
      "batch idx 230: | train loss: 0.6431596875190735 | train accu: 0.641 | train roc: 0.873 | train f1: 0.6253023498447814\n",
      "batch idx 231: | train loss: 0.5420997142791748 | train accu: 0.680 | train roc: 0.908 | train f1: 0.6530153508771931\n",
      "batch idx 232: | train loss: 0.5073725581169128 | train accu: 0.734 | train roc: 0.914 | train f1: 0.7226140873015873\n",
      "batch idx 233: | train loss: 0.624667227268219 | train accu: 0.680 | train roc: 0.831 | train f1: 0.6491137065118517\n",
      "batch idx 234: | train loss: 0.5956427454948425 | train accu: 0.727 | train roc: 0.864 | train f1: 0.715141643637679\n",
      "batch idx 235: | train loss: 0.56239914894104 | train accu: 0.734 | train roc: 0.887 | train f1: 0.7221354166666666\n",
      "batch idx 236: | train loss: 0.5737104415893555 | train accu: 0.672 | train roc: 0.872 | train f1: 0.6482545764154959\n",
      "batch idx 237: | train loss: 0.5668233036994934 | train accu: 0.727 | train roc: 0.892 | train f1: 0.72155913016601\n",
      "batch idx 238: | train loss: 0.6376069188117981 | train accu: 0.742 | train roc: 0.866 | train f1: 0.7349978240885621\n",
      "batch idx 239: | train loss: 0.5703271627426147 | train accu: 0.695 | train roc: 0.880 | train f1: 0.6823767023733673\n",
      "batch idx 240: | train loss: 0.5059840679168701 | train accu: 0.750 | train roc: 0.878 | train f1: 0.7421208007365031\n",
      "Epoch: 02 | Epoch Time: 2m 13s\n",
      "\tTrain Loss: 0.568 | Train Acc: 69.97 | Train rocauc: 0.8730807498072901 | Train f1: 0.6797009557639464%\n",
      "\t Val. Loss: 0.595 |  Val. Acc: 66.20 | Val. rocauc: 0.8538796341264258 | Val. f1: 0.6267982584093142%\n",
      "batch idx 0: | train loss: 0.5374089479446411 | train accu: 0.719 | train roc: 0.873 | train f1: 0.7009362660779308\n",
      "batch idx 1: | train loss: 0.5983536243438721 | train accu: 0.672 | train roc: 0.867 | train f1: 0.6293824371193322\n",
      "batch idx 2: | train loss: 0.5859941244125366 | train accu: 0.734 | train roc: 0.811 | train f1: 0.7065484522070756\n",
      "batch idx 3: | train loss: 0.5223591327667236 | train accu: 0.742 | train roc: 0.891 | train f1: 0.7183885498401628\n",
      "batch idx 4: | train loss: 0.5951915383338928 | train accu: 0.664 | train roc: 0.871 | train f1: 0.6620757831695332\n",
      "batch idx 5: | train loss: 0.5038402080535889 | train accu: 0.734 | train roc: 0.897 | train f1: 0.7251219275402048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 6: | train loss: 0.42570847272872925 | train accu: 0.820 | train roc: 0.922 | train f1: 0.8172683566433566\n",
      "batch idx 7: | train loss: 0.5803934335708618 | train accu: 0.711 | train roc: 0.879 | train f1: 0.7072859274563821\n",
      "batch idx 8: | train loss: 0.5508607029914856 | train accu: 0.742 | train roc: 0.878 | train f1: 0.7377735040869976\n",
      "batch idx 9: | train loss: 0.5071380734443665 | train accu: 0.781 | train roc: 0.888 | train f1: 0.7702809343434345\n",
      "batch idx 10: | train loss: 0.514122486114502 | train accu: 0.750 | train roc: 0.907 | train f1: 0.7396623717489859\n",
      "batch idx 11: | train loss: 0.5722194910049438 | train accu: 0.719 | train roc: 0.866 | train f1: 0.7034976420248096\n",
      "batch idx 12: | train loss: 0.5115107893943787 | train accu: 0.734 | train roc: 0.902 | train f1: 0.6986838825293638\n",
      "batch idx 13: | train loss: 0.4541555345058441 | train accu: 0.781 | train roc: 0.934 | train f1: 0.7751878246144785\n",
      "batch idx 14: | train loss: 0.5093557834625244 | train accu: 0.750 | train roc: 0.898 | train f1: 0.7462955097087378\n",
      "batch idx 15: | train loss: 0.5916876196861267 | train accu: 0.719 | train roc: 0.862 | train f1: 0.7136354337152211\n",
      "batch idx 16: | train loss: 0.6226904392242432 | train accu: 0.695 | train roc: 0.876 | train f1: 0.6738944015806682\n",
      "batch idx 17: | train loss: 0.6036518216133118 | train accu: 0.672 | train roc: 0.878 | train f1: 0.6678297924901186\n",
      "batch idx 18: | train loss: 0.5824335217475891 | train accu: 0.688 | train roc: 0.880 | train f1: 0.6559873032624557\n",
      "batch idx 19: | train loss: 0.43668147921562195 | train accu: 0.727 | train roc: 0.940 | train f1: 0.6826619642024747\n",
      "batch idx 20: | train loss: 0.4383496940135956 | train accu: 0.758 | train roc: 0.916 | train f1: 0.6959821428571429\n",
      "batch idx 21: | train loss: 0.5409214496612549 | train accu: 0.703 | train roc: 0.875 | train f1: 0.6623256785324605\n",
      "batch idx 22: | train loss: 0.5806577205657959 | train accu: 0.672 | train roc: 0.887 | train f1: 0.6265866769461923\n",
      "batch idx 23: | train loss: 0.46862947940826416 | train accu: 0.742 | train roc: 0.906 | train f1: 0.7175183426738918\n",
      "batch idx 24: | train loss: 0.505385160446167 | train accu: 0.742 | train roc: 0.907 | train f1: 0.7347882372444998\n",
      "batch idx 25: | train loss: 0.39459556341171265 | train accu: 0.820 | train roc: 0.938 | train f1: 0.8183223640229761\n",
      "batch idx 26: | train loss: 0.41549500823020935 | train accu: 0.781 | train roc: 0.941 | train f1: 0.7719991511035653\n",
      "batch idx 27: | train loss: 0.591991126537323 | train accu: 0.664 | train roc: 0.901 | train f1: 0.6496158507976227\n",
      "batch idx 28: | train loss: 0.5475545525550842 | train accu: 0.750 | train roc: 0.876 | train f1: 0.735345263180528\n",
      "batch idx 29: | train loss: 0.5859542489051819 | train accu: 0.680 | train roc: 0.856 | train f1: 0.668811194057846\n",
      "batch idx 30: | train loss: 0.6823570728302002 | train accu: 0.672 | train roc: 0.839 | train f1: 0.65234375\n",
      "batch idx 31: | train loss: 0.4921717941761017 | train accu: 0.781 | train roc: 0.913 | train f1: 0.7704676335191041\n",
      "batch idx 32: | train loss: 0.5939528346061707 | train accu: 0.703 | train roc: 0.861 | train f1: 0.6966198544115495\n",
      "batch idx 33: | train loss: 0.5145642161369324 | train accu: 0.766 | train roc: 0.895 | train f1: 0.7603908096926715\n",
      "batch idx 34: | train loss: 0.5808655023574829 | train accu: 0.742 | train roc: 0.868 | train f1: 0.7361741092358182\n",
      "batch idx 35: | train loss: 0.6115500926971436 | train accu: 0.672 | train roc: 0.883 | train f1: 0.6515344428190877\n",
      "batch idx 36: | train loss: 0.6000377535820007 | train accu: 0.719 | train roc: 0.897 | train f1: 0.702248244263258\n",
      "batch idx 37: | train loss: 0.5112988352775574 | train accu: 0.750 | train roc: 0.893 | train f1: 0.7332018811798223\n",
      "batch idx 38: | train loss: 0.526727557182312 | train accu: 0.742 | train roc: 0.860 | train f1: 0.7267362270741143\n",
      "batch idx 39: | train loss: 0.5466972589492798 | train accu: 0.711 | train roc: 0.886 | train f1: 0.6925223214285714\n",
      "batch idx 40: | train loss: 0.5650485157966614 | train accu: 0.688 | train roc: 0.856 | train f1: 0.6409826684107258\n",
      "batch idx 41: | train loss: 0.5275024175643921 | train accu: 0.719 | train roc: 0.885 | train f1: 0.6805985150226876\n",
      "batch idx 42: | train loss: 0.4381799101829529 | train accu: 0.758 | train roc: 0.900 | train f1: 0.7240636923868935\n",
      "batch idx 43: | train loss: 0.43838751316070557 | train accu: 0.758 | train roc: 0.925 | train f1: 0.7336803087735924\n",
      "batch idx 44: | train loss: 0.5308172702789307 | train accu: 0.695 | train roc: 0.895 | train f1: 0.6648314514617693\n",
      "batch idx 45: | train loss: 0.5605873465538025 | train accu: 0.695 | train roc: 0.862 | train f1: 0.683768915165653\n",
      "batch idx 46: | train loss: 0.5882874131202698 | train accu: 0.703 | train roc: 0.893 | train f1: 0.69079773388943\n",
      "batch idx 47: | train loss: 0.5987877249717712 | train accu: 0.734 | train roc: 0.869 | train f1: 0.7259291943521595\n",
      "batch idx 48: | train loss: 0.6976101994514465 | train accu: 0.641 | train roc: 0.813 | train f1: 0.6237122114346053\n",
      "batch idx 49: | train loss: 0.5007318258285522 | train accu: 0.727 | train roc: 0.908 | train f1: 0.6973859396200814\n",
      "batch idx 50: | train loss: 0.5769818425178528 | train accu: 0.695 | train roc: 0.860 | train f1: 0.6753524118358778\n",
      "batch idx 51: | train loss: 0.5135451555252075 | train accu: 0.727 | train roc: 0.893 | train f1: 0.7020969047433296\n",
      "batch idx 52: | train loss: 0.5412645936012268 | train accu: 0.703 | train roc: 0.895 | train f1: 0.6758112407358097\n",
      "batch idx 53: | train loss: 0.48332223296165466 | train accu: 0.750 | train roc: 0.923 | train f1: 0.7303706416822614\n",
      "batch idx 54: | train loss: 0.5007535219192505 | train accu: 0.750 | train roc: 0.892 | train f1: 0.7220801324932027\n",
      "batch idx 55: | train loss: 0.5781728625297546 | train accu: 0.695 | train roc: 0.864 | train f1: 0.6918618955449312\n",
      "batch idx 56: | train loss: 0.659308671951294 | train accu: 0.672 | train roc: 0.846 | train f1: 0.6690423067712938\n",
      "batch idx 57: | train loss: 0.4856339991092682 | train accu: 0.734 | train roc: 0.909 | train f1: 0.7251811594202898\n",
      "batch idx 58: | train loss: 0.5410850048065186 | train accu: 0.734 | train roc: 0.893 | train f1: 0.7317325367647058\n",
      "batch idx 59: | train loss: 0.5182892084121704 | train accu: 0.719 | train roc: 0.893 | train f1: 0.7105458624351959\n",
      "batch idx 60: | train loss: 0.5994110107421875 | train accu: 0.711 | train roc: 0.844 | train f1: 0.7016858552631579\n",
      "batch idx 61: | train loss: 0.4963877499103546 | train accu: 0.664 | train roc: 0.904 | train f1: 0.6538128097922737\n",
      "batch idx 62: | train loss: 0.6246346235275269 | train accu: 0.672 | train roc: 0.842 | train f1: 0.6581397246454217\n",
      "batch idx 63: | train loss: 0.5985708832740784 | train accu: 0.688 | train roc: 0.854 | train f1: 0.6587021555197421\n",
      "batch idx 64: | train loss: 0.5904916524887085 | train accu: 0.648 | train roc: 0.877 | train f1: 0.6142397148200094\n",
      "batch idx 65: | train loss: 0.500487208366394 | train accu: 0.773 | train roc: 0.887 | train f1: 0.764550028074413\n",
      "batch idx 66: | train loss: 0.5186688303947449 | train accu: 0.727 | train roc: 0.899 | train f1: 0.7193980544309491\n",
      "batch idx 67: | train loss: 0.6163221001625061 | train accu: 0.656 | train roc: 0.840 | train f1: 0.6465593030690537\n",
      "batch idx 68: | train loss: 0.5197790861129761 | train accu: 0.680 | train roc: 0.880 | train f1: 0.6567830150299183\n",
      "batch idx 69: | train loss: 0.4228920638561249 | train accu: 0.781 | train roc: 0.933 | train f1: 0.7610739685765087\n",
      "batch idx 70: | train loss: 0.5163376331329346 | train accu: 0.750 | train roc: 0.901 | train f1: 0.7407681750551537\n",
      "batch idx 71: | train loss: 0.5639391541481018 | train accu: 0.711 | train roc: 0.865 | train f1: 0.695940961977398\n",
      "batch idx 72: | train loss: 0.4683796465396881 | train accu: 0.719 | train roc: 0.920 | train f1: 0.7105386354048471\n",
      "batch idx 73: | train loss: 0.5944371819496155 | train accu: 0.727 | train roc: 0.876 | train f1: 0.710366796969331\n",
      "batch idx 74: | train loss: 0.5738094449043274 | train accu: 0.672 | train roc: 0.877 | train f1: 0.6673520834797273\n",
      "batch idx 75: | train loss: 0.5894867777824402 | train accu: 0.703 | train roc: 0.869 | train f1: 0.6957037487892352\n",
      "batch idx 76: | train loss: 0.502125084400177 | train accu: 0.766 | train roc: 0.902 | train f1: 0.7651457340678975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 77: | train loss: 0.4996533691883087 | train accu: 0.758 | train roc: 0.883 | train f1: 0.7500904268145647\n",
      "batch idx 78: | train loss: 0.5635194182395935 | train accu: 0.742 | train roc: 0.865 | train f1: 0.7328509852216748\n",
      "batch idx 79: | train loss: 0.5787677764892578 | train accu: 0.633 | train roc: 0.901 | train f1: 0.6083029398762158\n",
      "batch idx 80: | train loss: 0.522854208946228 | train accu: 0.727 | train roc: 0.883 | train f1: 0.7029634757383967\n",
      "batch idx 81: | train loss: 0.49080029129981995 | train accu: 0.742 | train roc: 0.877 | train f1: 0.7275720526720322\n",
      "batch idx 82: | train loss: 0.5613107085227966 | train accu: 0.727 | train roc: 0.878 | train f1: 0.7232830413633985\n",
      "batch idx 83: | train loss: 0.5220333337783813 | train accu: 0.719 | train roc: 0.891 | train f1: 0.697696314102564\n",
      "batch idx 84: | train loss: 0.5728065371513367 | train accu: 0.680 | train roc: 0.883 | train f1: 0.6770726625069845\n",
      "batch idx 85: | train loss: 0.592415452003479 | train accu: 0.672 | train roc: 0.867 | train f1: 0.6693742245657568\n",
      "batch idx 86: | train loss: 0.5471341013908386 | train accu: 0.688 | train roc: 0.878 | train f1: 0.6744607148480554\n",
      "batch idx 87: | train loss: 0.4533926248550415 | train accu: 0.734 | train roc: 0.933 | train f1: 0.7307390355546093\n",
      "batch idx 88: | train loss: 0.5642597079277039 | train accu: 0.742 | train roc: 0.869 | train f1: 0.7338525777913363\n",
      "batch idx 89: | train loss: 0.6047767400741577 | train accu: 0.688 | train roc: 0.866 | train f1: 0.6742421628727902\n",
      "batch idx 90: | train loss: 0.5593711733818054 | train accu: 0.719 | train roc: 0.862 | train f1: 0.702077077077077\n",
      "batch idx 91: | train loss: 0.6034560203552246 | train accu: 0.703 | train roc: 0.874 | train f1: 0.6952259731487735\n",
      "batch idx 92: | train loss: 0.6020638346672058 | train accu: 0.688 | train roc: 0.855 | train f1: 0.6722405538302277\n",
      "batch idx 93: | train loss: 0.5809412598609924 | train accu: 0.672 | train roc: 0.870 | train f1: 0.6611979166666667\n",
      "batch idx 94: | train loss: 0.5101132988929749 | train accu: 0.727 | train roc: 0.896 | train f1: 0.6962619837758113\n",
      "batch idx 95: | train loss: 0.5606523156166077 | train accu: 0.672 | train roc: 0.885 | train f1: 0.6615957068311195\n",
      "batch idx 96: | train loss: 0.6007817387580872 | train accu: 0.688 | train roc: 0.874 | train f1: 0.6796091390746333\n",
      "batch idx 97: | train loss: 0.4834716022014618 | train accu: 0.773 | train roc: 0.884 | train f1: 0.7649051750614251\n",
      "batch idx 98: | train loss: 0.4775620102882385 | train accu: 0.727 | train roc: 0.926 | train f1: 0.7130430754817239\n",
      "batch idx 99: | train loss: 0.4830133020877838 | train accu: 0.734 | train roc: 0.910 | train f1: 0.7113935492339267\n",
      "batch idx 100: | train loss: 0.5342715978622437 | train accu: 0.711 | train roc: 0.892 | train f1: 0.7024893810679611\n",
      "batch idx 101: | train loss: 0.46321675181388855 | train accu: 0.805 | train roc: 0.902 | train f1: 0.8033268229166667\n",
      "batch idx 102: | train loss: 0.6114615797996521 | train accu: 0.695 | train roc: 0.855 | train f1: 0.6822337403288201\n",
      "batch idx 103: | train loss: 0.5088230967521667 | train accu: 0.719 | train roc: 0.881 | train f1: 0.6844778517999066\n",
      "batch idx 104: | train loss: 0.6062703728675842 | train accu: 0.680 | train roc: 0.874 | train f1: 0.6667360740938166\n",
      "batch idx 105: | train loss: 0.4831725060939789 | train accu: 0.719 | train roc: 0.919 | train f1: 0.7002342907227616\n",
      "batch idx 106: | train loss: 0.42779460549354553 | train accu: 0.766 | train roc: 0.919 | train f1: 0.749817944004525\n",
      "batch idx 107: | train loss: 0.4880654513835907 | train accu: 0.711 | train roc: 0.920 | train f1: 0.6879063373072065\n",
      "batch idx 108: | train loss: 0.4355242848396301 | train accu: 0.797 | train roc: 0.918 | train f1: 0.779574592074592\n",
      "batch idx 109: | train loss: 0.5759501457214355 | train accu: 0.711 | train roc: 0.869 | train f1: 0.7022519631531259\n",
      "batch idx 110: | train loss: 0.5009863376617432 | train accu: 0.750 | train roc: 0.906 | train f1: 0.7457157155242757\n",
      "batch idx 111: | train loss: 0.5416216850280762 | train accu: 0.727 | train roc: 0.881 | train f1: 0.722761151461538\n",
      "batch idx 112: | train loss: 0.5663632750511169 | train accu: 0.750 | train roc: 0.891 | train f1: 0.7423508111512143\n",
      "batch idx 113: | train loss: 0.5011767745018005 | train accu: 0.766 | train roc: 0.902 | train f1: 0.7522199698622274\n",
      "batch idx 114: | train loss: 0.5268352627754211 | train accu: 0.719 | train roc: 0.878 | train f1: 0.7015142882187939\n",
      "batch idx 115: | train loss: 0.49134209752082825 | train accu: 0.711 | train roc: 0.904 | train f1: 0.7032163553063382\n",
      "batch idx 116: | train loss: 0.4595997631549835 | train accu: 0.781 | train roc: 0.905 | train f1: 0.776096503509558\n",
      "batch idx 117: | train loss: 0.45381960272789 | train accu: 0.742 | train roc: 0.901 | train f1: 0.6943304507337527\n",
      "batch idx 118: | train loss: 0.6614629626274109 | train accu: 0.656 | train roc: 0.854 | train f1: 0.6405701494307401\n",
      "batch idx 119: | train loss: 0.6137080788612366 | train accu: 0.688 | train roc: 0.845 | train f1: 0.6761898411569465\n",
      "batch idx 120: | train loss: 0.47417932748794556 | train accu: 0.734 | train roc: 0.919 | train f1: 0.7181195590866102\n",
      "batch idx 121: | train loss: 0.5808187127113342 | train accu: 0.688 | train roc: 0.877 | train f1: 0.6857769423558897\n",
      "batch idx 122: | train loss: 0.6447150707244873 | train accu: 0.695 | train roc: 0.861 | train f1: 0.6932844932844933\n",
      "batch idx 123: | train loss: 0.5545671582221985 | train accu: 0.719 | train roc: 0.898 | train f1: 0.71967528998779\n",
      "batch idx 124: | train loss: 0.6043885350227356 | train accu: 0.719 | train roc: 0.846 | train f1: 0.7097794292038897\n",
      "batch idx 125: | train loss: 0.49968621134757996 | train accu: 0.758 | train roc: 0.905 | train f1: 0.7554294734933935\n",
      "batch idx 126: | train loss: 0.5308107733726501 | train accu: 0.703 | train roc: 0.899 | train f1: 0.6951854266987694\n",
      "batch idx 127: | train loss: 0.558444082736969 | train accu: 0.734 | train roc: 0.876 | train f1: 0.710968671288144\n",
      "batch idx 128: | train loss: 0.5403523445129395 | train accu: 0.688 | train roc: 0.901 | train f1: 0.6627914186507937\n",
      "batch idx 129: | train loss: 0.5158184766769409 | train accu: 0.695 | train roc: 0.893 | train f1: 0.6544676039369436\n",
      "batch idx 130: | train loss: 0.6818381547927856 | train accu: 0.609 | train roc: 0.850 | train f1: 0.5794615454640033\n",
      "batch idx 131: | train loss: 0.5420007109642029 | train accu: 0.734 | train roc: 0.894 | train f1: 0.7302973723787163\n",
      "batch idx 132: | train loss: 0.5381413698196411 | train accu: 0.719 | train roc: 0.884 | train f1: 0.7173074033259867\n",
      "batch idx 133: | train loss: 0.6196220517158508 | train accu: 0.688 | train roc: 0.855 | train f1: 0.6839988758132416\n",
      "batch idx 134: | train loss: 0.49879026412963867 | train accu: 0.695 | train roc: 0.897 | train f1: 0.6709849486515369\n",
      "batch idx 135: | train loss: 0.5347152352333069 | train accu: 0.719 | train roc: 0.878 | train f1: 0.6994907407407407\n",
      "batch idx 136: | train loss: 0.4820948839187622 | train accu: 0.758 | train roc: 0.903 | train f1: 0.7413367296692029\n",
      "batch idx 137: | train loss: 0.5768779516220093 | train accu: 0.711 | train roc: 0.872 | train f1: 0.6848214285714287\n",
      "batch idx 138: | train loss: 0.45396938920021057 | train accu: 0.758 | train roc: 0.930 | train f1: 0.7489173547029302\n",
      "batch idx 139: | train loss: 0.6035611629486084 | train accu: 0.625 | train roc: 0.864 | train f1: 0.6081771823241923\n",
      "batch idx 140: | train loss: 0.5961272120475769 | train accu: 0.695 | train roc: 0.857 | train f1: 0.6834905460265246\n",
      "batch idx 141: | train loss: 0.4718117415904999 | train accu: 0.734 | train roc: 0.919 | train f1: 0.7162973200899551\n",
      "batch idx 142: | train loss: 0.6681858897209167 | train accu: 0.680 | train roc: 0.847 | train f1: 0.6633409693754522\n",
      "batch idx 143: | train loss: 0.5919936299324036 | train accu: 0.766 | train roc: 0.859 | train f1: 0.7511788558663559\n",
      "batch idx 144: | train loss: 0.5437234044075012 | train accu: 0.742 | train roc: 0.882 | train f1: 0.7385432205437432\n",
      "batch idx 145: | train loss: 0.4891800880432129 | train accu: 0.742 | train roc: 0.901 | train f1: 0.730214006423684\n",
      "batch idx 146: | train loss: 0.5691772699356079 | train accu: 0.703 | train roc: 0.861 | train f1: 0.6822562554352123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 147: | train loss: 0.5605822205543518 | train accu: 0.727 | train roc: 0.894 | train f1: 0.7133275493510628\n",
      "batch idx 148: | train loss: 0.4932960569858551 | train accu: 0.758 | train roc: 0.855 | train f1: 0.7410166715391531\n",
      "batch idx 149: | train loss: 0.4991525411605835 | train accu: 0.734 | train roc: 0.910 | train f1: 0.7176307624113476\n",
      "batch idx 150: | train loss: 0.5111368298530579 | train accu: 0.734 | train roc: 0.892 | train f1: 0.7251173071443835\n",
      "batch idx 151: | train loss: 0.5436308979988098 | train accu: 0.734 | train roc: 0.876 | train f1: 0.7109334625322998\n",
      "batch idx 152: | train loss: 0.49769940972328186 | train accu: 0.750 | train roc: 0.887 | train f1: 0.7351349430062062\n",
      "batch idx 153: | train loss: 0.5504583120346069 | train accu: 0.695 | train roc: 0.880 | train f1: 0.6773793522785458\n",
      "batch idx 154: | train loss: 0.4165370762348175 | train accu: 0.820 | train roc: 0.920 | train f1: 0.8120258652066306\n",
      "batch idx 155: | train loss: 0.5930152535438538 | train accu: 0.734 | train roc: 0.882 | train f1: 0.7293485339864629\n",
      "batch idx 156: | train loss: 0.5232025980949402 | train accu: 0.719 | train roc: 0.879 | train f1: 0.69220289408867\n",
      "batch idx 157: | train loss: 0.570059597492218 | train accu: 0.672 | train roc: 0.880 | train f1: 0.6438410615171137\n",
      "batch idx 158: | train loss: 0.5289759635925293 | train accu: 0.719 | train roc: 0.882 | train f1: 0.7030670334994462\n",
      "batch idx 159: | train loss: 0.4581862986087799 | train accu: 0.781 | train roc: 0.918 | train f1: 0.7761762698758667\n",
      "batch idx 160: | train loss: 0.5683282017707825 | train accu: 0.734 | train roc: 0.884 | train f1: 0.7286018215880102\n",
      "batch idx 161: | train loss: 0.465908944606781 | train accu: 0.797 | train roc: 0.906 | train f1: 0.7919496143527833\n",
      "batch idx 162: | train loss: 0.5453561544418335 | train accu: 0.719 | train roc: 0.885 | train f1: 0.7039634382754343\n",
      "batch idx 163: | train loss: 0.5332607626914978 | train accu: 0.727 | train roc: 0.882 | train f1: 0.7169912870342378\n",
      "batch idx 164: | train loss: 0.6260323524475098 | train accu: 0.672 | train roc: 0.869 | train f1: 0.6467285903423683\n",
      "batch idx 165: | train loss: 0.6130772829055786 | train accu: 0.672 | train roc: 0.830 | train f1: 0.6628551136363636\n",
      "batch idx 166: | train loss: 0.5318424701690674 | train accu: 0.750 | train roc: 0.900 | train f1: 0.7425347222222222\n",
      "batch idx 167: | train loss: 0.539661169052124 | train accu: 0.719 | train roc: 0.891 | train f1: 0.7162099191866528\n",
      "batch idx 168: | train loss: 0.5311344265937805 | train accu: 0.719 | train roc: 0.888 | train f1: 0.7067544667686319\n",
      "batch idx 169: | train loss: 0.5370610356330872 | train accu: 0.680 | train roc: 0.875 | train f1: 0.6487547438330172\n",
      "batch idx 170: | train loss: 0.5729696154594421 | train accu: 0.695 | train roc: 0.889 | train f1: 0.6572572665429808\n",
      "batch idx 171: | train loss: 0.5632899403572083 | train accu: 0.703 | train roc: 0.879 | train f1: 0.6696238191632929\n",
      "batch idx 172: | train loss: 0.5230836868286133 | train accu: 0.703 | train roc: 0.903 | train f1: 0.6838804408482144\n",
      "batch idx 173: | train loss: 0.5163455605506897 | train accu: 0.734 | train roc: 0.900 | train f1: 0.7235818191650443\n",
      "batch idx 174: | train loss: 0.5992820858955383 | train accu: 0.664 | train roc: 0.865 | train f1: 0.6340716575091575\n",
      "batch idx 175: | train loss: 0.5215520858764648 | train accu: 0.703 | train roc: 0.875 | train f1: 0.6832862115411558\n",
      "batch idx 176: | train loss: 0.5349277257919312 | train accu: 0.695 | train roc: 0.900 | train f1: 0.6816150939542485\n",
      "batch idx 177: | train loss: 0.46831274032592773 | train accu: 0.750 | train roc: 0.879 | train f1: 0.7385292658730158\n",
      "batch idx 178: | train loss: 0.5614143013954163 | train accu: 0.688 | train roc: 0.861 | train f1: 0.6461978714590074\n",
      "batch idx 179: | train loss: 0.540188193321228 | train accu: 0.680 | train roc: 0.884 | train f1: 0.6560804110438165\n",
      "batch idx 180: | train loss: 0.4836518168449402 | train accu: 0.703 | train roc: 0.913 | train f1: 0.6591023352930199\n",
      "batch idx 181: | train loss: 0.49307599663734436 | train accu: 0.758 | train roc: 0.905 | train f1: 0.7465992037159921\n",
      "batch idx 182: | train loss: 0.5688382387161255 | train accu: 0.711 | train roc: 0.871 | train f1: 0.6799977176549687\n",
      "batch idx 183: | train loss: 0.5010563135147095 | train accu: 0.750 | train roc: 0.893 | train f1: 0.7373046875000001\n",
      "batch idx 184: | train loss: 0.526466965675354 | train accu: 0.742 | train roc: 0.880 | train f1: 0.7301240516429017\n",
      "batch idx 185: | train loss: 0.5381418466567993 | train accu: 0.711 | train roc: 0.883 | train f1: 0.6978537328730177\n",
      "batch idx 186: | train loss: 0.6369761228561401 | train accu: 0.688 | train roc: 0.853 | train f1: 0.6746023367117118\n",
      "batch idx 187: | train loss: 0.4707460403442383 | train accu: 0.766 | train roc: 0.919 | train f1: 0.7614001551418439\n",
      "batch idx 188: | train loss: 0.6045746207237244 | train accu: 0.641 | train roc: 0.888 | train f1: 0.6257318796688875\n",
      "batch idx 189: | train loss: 0.6322857141494751 | train accu: 0.680 | train roc: 0.887 | train f1: 0.6802385265700484\n",
      "batch idx 190: | train loss: 0.516740083694458 | train accu: 0.695 | train roc: 0.908 | train f1: 0.6817835365853658\n",
      "batch idx 191: | train loss: 0.5816251039505005 | train accu: 0.703 | train roc: 0.871 | train f1: 0.6930414698457336\n",
      "batch idx 192: | train loss: 0.4396427273750305 | train accu: 0.820 | train roc: 0.927 | train f1: 0.8167948163702239\n",
      "batch idx 193: | train loss: 0.42207100987434387 | train accu: 0.734 | train roc: 0.915 | train f1: 0.7181792803970224\n",
      "batch idx 194: | train loss: 0.5381700396537781 | train accu: 0.727 | train roc: 0.897 | train f1: 0.7103183938400517\n",
      "batch idx 195: | train loss: 0.649197518825531 | train accu: 0.664 | train roc: 0.878 | train f1: 0.6412760416666667\n",
      "batch idx 196: | train loss: 0.5590755939483643 | train accu: 0.711 | train roc: 0.860 | train f1: 0.6840331611686031\n",
      "batch idx 197: | train loss: 0.5195237994194031 | train accu: 0.719 | train roc: 0.872 | train f1: 0.7027541035353535\n",
      "batch idx 198: | train loss: 0.5915841460227966 | train accu: 0.711 | train roc: 0.845 | train f1: 0.6823480339105339\n",
      "batch idx 199: | train loss: 0.5773054361343384 | train accu: 0.727 | train roc: 0.883 | train f1: 0.7184228756157636\n",
      "batch idx 200: | train loss: 0.6022239923477173 | train accu: 0.742 | train roc: 0.881 | train f1: 0.7336977905569008\n",
      "batch idx 201: | train loss: 0.42485538125038147 | train accu: 0.789 | train roc: 0.924 | train f1: 0.771197195515795\n",
      "batch idx 202: | train loss: 0.569537878036499 | train accu: 0.688 | train roc: 0.851 | train f1: 0.6455267228065686\n",
      "batch idx 203: | train loss: 0.6500690579414368 | train accu: 0.656 | train roc: 0.820 | train f1: 0.6078133405056483\n",
      "batch idx 204: | train loss: 0.6303901076316833 | train accu: 0.688 | train roc: 0.849 | train f1: 0.6396381578947368\n",
      "batch idx 205: | train loss: 0.6178872585296631 | train accu: 0.664 | train roc: 0.865 | train f1: 0.6321594996729888\n",
      "batch idx 206: | train loss: 0.6195279359817505 | train accu: 0.672 | train roc: 0.876 | train f1: 0.651160869701755\n",
      "batch idx 207: | train loss: 0.5792206525802612 | train accu: 0.711 | train roc: 0.850 | train f1: 0.685535858178888\n",
      "batch idx 208: | train loss: 0.5881214737892151 | train accu: 0.742 | train roc: 0.883 | train f1: 0.7231994212779451\n",
      "batch idx 209: | train loss: 0.6080543398857117 | train accu: 0.648 | train roc: 0.864 | train f1: 0.6465807712145367\n",
      "batch idx 210: | train loss: 0.5589223504066467 | train accu: 0.703 | train roc: 0.875 | train f1: 0.6866112138200426\n",
      "batch idx 211: | train loss: 0.490214079618454 | train accu: 0.742 | train roc: 0.905 | train f1: 0.7234245436617134\n",
      "batch idx 212: | train loss: 0.5138779282569885 | train accu: 0.742 | train roc: 0.897 | train f1: 0.7310746528040423\n",
      "batch idx 213: | train loss: 0.5084899663925171 | train accu: 0.719 | train roc: 0.916 | train f1: 0.7096976902173914\n",
      "batch idx 214: | train loss: 0.5162821412086487 | train accu: 0.703 | train roc: 0.911 | train f1: 0.6819578629437795\n",
      "batch idx 215: | train loss: 0.5850005745887756 | train accu: 0.727 | train roc: 0.871 | train f1: 0.7162068338366139\n",
      "batch idx 216: | train loss: 0.5191056132316589 | train accu: 0.719 | train roc: 0.876 | train f1: 0.707161283557047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 217: | train loss: 0.4789619743824005 | train accu: 0.742 | train roc: 0.906 | train f1: 0.7246473116384712\n",
      "batch idx 218: | train loss: 0.6116453409194946 | train accu: 0.695 | train roc: 0.869 | train f1: 0.6832212273582687\n",
      "batch idx 219: | train loss: 0.5208355784416199 | train accu: 0.758 | train roc: 0.905 | train f1: 0.7514245977502868\n",
      "batch idx 220: | train loss: 0.4661950170993805 | train accu: 0.781 | train roc: 0.897 | train f1: 0.7773222117794486\n",
      "batch idx 221: | train loss: 0.60245680809021 | train accu: 0.648 | train roc: 0.862 | train f1: 0.6316730242566511\n",
      "batch idx 222: | train loss: 0.48790937662124634 | train accu: 0.773 | train roc: 0.897 | train f1: 0.763033536585366\n",
      "batch idx 223: | train loss: 0.4947451055049896 | train accu: 0.719 | train roc: 0.899 | train f1: 0.6885989010989011\n",
      "batch idx 224: | train loss: 0.6108207702636719 | train accu: 0.680 | train roc: 0.861 | train f1: 0.6610362465111643\n",
      "batch idx 225: | train loss: 0.5377004146575928 | train accu: 0.727 | train roc: 0.891 | train f1: 0.712633876173709\n",
      "batch idx 226: | train loss: 0.5767454504966736 | train accu: 0.648 | train roc: 0.899 | train f1: 0.6296479367779712\n",
      "batch idx 227: | train loss: 0.4751594364643097 | train accu: 0.742 | train roc: 0.920 | train f1: 0.7213427068159458\n",
      "batch idx 228: | train loss: 0.5482668280601501 | train accu: 0.727 | train roc: 0.873 | train f1: 0.7116071428571428\n",
      "batch idx 229: | train loss: 0.5826110243797302 | train accu: 0.672 | train roc: 0.849 | train f1: 0.6670942845223196\n",
      "batch idx 230: | train loss: 0.5551854968070984 | train accu: 0.719 | train roc: 0.893 | train f1: 0.7093560606060607\n",
      "batch idx 231: | train loss: 0.5476726293563843 | train accu: 0.781 | train roc: 0.874 | train f1: 0.7753476991758241\n",
      "batch idx 232: | train loss: 0.49059876799583435 | train accu: 0.695 | train roc: 0.911 | train f1: 0.6693976078702614\n",
      "batch idx 233: | train loss: 0.4402075409889221 | train accu: 0.781 | train roc: 0.916 | train f1: 0.7692771849593496\n",
      "batch idx 234: | train loss: 0.5171202421188354 | train accu: 0.711 | train roc: 0.907 | train f1: 0.6973554539844171\n",
      "batch idx 235: | train loss: 0.6018654108047485 | train accu: 0.688 | train roc: 0.891 | train f1: 0.6735308499288761\n",
      "batch idx 236: | train loss: 0.5902860760688782 | train accu: 0.695 | train roc: 0.861 | train f1: 0.6879787505269995\n",
      "batch idx 237: | train loss: 0.5104856491088867 | train accu: 0.750 | train roc: 0.885 | train f1: 0.74316829004329\n",
      "batch idx 238: | train loss: 0.5254654288291931 | train accu: 0.766 | train roc: 0.901 | train f1: 0.7572834645669291\n",
      "batch idx 239: | train loss: 0.5278803706169128 | train accu: 0.719 | train roc: 0.875 | train f1: 0.7190191110227875\n",
      "batch idx 240: | train loss: 0.670484185218811 | train accu: 0.656 | train roc: 0.826 | train f1: 0.6284090909090909\n",
      "Epoch: 03 | Epoch Time: 2m 13s\n",
      "\tTrain Loss: 0.542 | Train Acc: 71.83 | Train rocauc: 0.8848248914356975 | Train f1: 0.702368476701272%\n",
      "\t Val. Loss: 0.597 |  Val. Acc: 68.39 | Val. rocauc: 0.8553232854834375 | Val. f1: 0.6714983742797231%\n",
      "batch idx 0: | train loss: 0.4581283628940582 | train accu: 0.750 | train roc: 0.921 | train f1: 0.7297219669117646\n",
      "batch idx 1: | train loss: 0.49216902256011963 | train accu: 0.750 | train roc: 0.899 | train f1: 0.7395322104302728\n",
      "batch idx 2: | train loss: 0.46159622073173523 | train accu: 0.758 | train roc: 0.925 | train f1: 0.7523078149127322\n",
      "batch idx 3: | train loss: 0.49382221698760986 | train accu: 0.742 | train roc: 0.892 | train f1: 0.7315804164935604\n",
      "batch idx 4: | train loss: 0.4999944567680359 | train accu: 0.750 | train roc: 0.900 | train f1: 0.7373505717255717\n",
      "batch idx 5: | train loss: 0.4077503979206085 | train accu: 0.789 | train roc: 0.932 | train f1: 0.7808168859649123\n",
      "batch idx 6: | train loss: 0.5181754231452942 | train accu: 0.727 | train roc: 0.904 | train f1: 0.7247596153846153\n",
      "batch idx 7: | train loss: 0.4851795434951782 | train accu: 0.766 | train roc: 0.895 | train f1: 0.7580682410346298\n",
      "batch idx 8: | train loss: 0.5655596256256104 | train accu: 0.727 | train roc: 0.842 | train f1: 0.6989597787542399\n",
      "batch idx 9: | train loss: 0.5083901882171631 | train accu: 0.734 | train roc: 0.870 | train f1: 0.7227012118316466\n",
      "batch idx 10: | train loss: 0.5634603500366211 | train accu: 0.703 | train roc: 0.876 | train f1: 0.6785629734848485\n",
      "batch idx 11: | train loss: 0.5224092602729797 | train accu: 0.688 | train roc: 0.910 | train f1: 0.6500129291029222\n",
      "batch idx 12: | train loss: 0.4423244297504425 | train accu: 0.750 | train roc: 0.933 | train f1: 0.7271269624791987\n",
      "batch idx 13: | train loss: 0.47529664635658264 | train accu: 0.734 | train roc: 0.890 | train f1: 0.7103522783886695\n",
      "batch idx 14: | train loss: 0.4859536588191986 | train accu: 0.750 | train roc: 0.915 | train f1: 0.7383113401610645\n",
      "batch idx 15: | train loss: 0.4842640161514282 | train accu: 0.766 | train roc: 0.912 | train f1: 0.7591382704317133\n",
      "batch idx 16: | train loss: 0.51045823097229 | train accu: 0.703 | train roc: 0.897 | train f1: 0.698555188301282\n",
      "batch idx 17: | train loss: 0.4568800926208496 | train accu: 0.781 | train roc: 0.926 | train f1: 0.7804667721518989\n",
      "batch idx 18: | train loss: 0.5084877014160156 | train accu: 0.719 | train roc: 0.888 | train f1: 0.7041376801552106\n",
      "batch idx 19: | train loss: 0.4379430115222931 | train accu: 0.758 | train roc: 0.930 | train f1: 0.7492180705984663\n",
      "batch idx 20: | train loss: 0.5127913355827332 | train accu: 0.727 | train roc: 0.900 | train f1: 0.7043458668678739\n",
      "batch idx 21: | train loss: 0.4576092064380646 | train accu: 0.789 | train roc: 0.921 | train f1: 0.7826089140744314\n",
      "batch idx 22: | train loss: 0.4847416877746582 | train accu: 0.734 | train roc: 0.911 | train f1: 0.726874266431925\n",
      "batch idx 23: | train loss: 0.49609464406967163 | train accu: 0.750 | train roc: 0.913 | train f1: 0.7434374092624855\n",
      "batch idx 24: | train loss: 0.4464976489543915 | train accu: 0.766 | train roc: 0.919 | train f1: 0.7492025029708853\n",
      "batch idx 25: | train loss: 0.4950419068336487 | train accu: 0.750 | train roc: 0.898 | train f1: 0.7350738289347569\n",
      "batch idx 26: | train loss: 0.4405924677848816 | train accu: 0.773 | train roc: 0.918 | train f1: 0.7597041275406229\n",
      "batch idx 27: | train loss: 0.5035757422447205 | train accu: 0.742 | train roc: 0.892 | train f1: 0.7391859634400798\n",
      "batch idx 28: | train loss: 0.4755787253379822 | train accu: 0.773 | train roc: 0.925 | train f1: 0.770173631703804\n",
      "batch idx 29: | train loss: 0.49389517307281494 | train accu: 0.758 | train roc: 0.909 | train f1: 0.7540322034051474\n",
      "batch idx 30: | train loss: 0.4548414349555969 | train accu: 0.773 | train roc: 0.920 | train f1: 0.7685887464513186\n",
      "batch idx 31: | train loss: 0.49344632029533386 | train accu: 0.766 | train roc: 0.901 | train f1: 0.7497087692400193\n",
      "batch idx 32: | train loss: 0.4830106794834137 | train accu: 0.750 | train roc: 0.915 | train f1: 0.7372822090792839\n",
      "batch idx 33: | train loss: 0.4482662081718445 | train accu: 0.797 | train roc: 0.918 | train f1: 0.7924879979297544\n",
      "batch idx 34: | train loss: 0.49527767300605774 | train accu: 0.750 | train roc: 0.917 | train f1: 0.745068602300995\n",
      "batch idx 35: | train loss: 0.7264533638954163 | train accu: 0.641 | train roc: 0.844 | train f1: 0.6197013923576423\n",
      "batch idx 36: | train loss: 0.4575795531272888 | train accu: 0.766 | train roc: 0.921 | train f1: 0.7618042283803155\n",
      "batch idx 37: | train loss: 0.4665520191192627 | train accu: 0.727 | train roc: 0.913 | train f1: 0.7197875783135468\n",
      "batch idx 38: | train loss: 0.5481786727905273 | train accu: 0.727 | train roc: 0.878 | train f1: 0.7157586034766268\n",
      "batch idx 39: | train loss: 0.4885106086730957 | train accu: 0.789 | train roc: 0.873 | train f1: 0.7789027314511354\n",
      "batch idx 40: | train loss: 0.4714195728302002 | train accu: 0.758 | train roc: 0.913 | train f1: 0.7291521990740741\n",
      "batch idx 41: | train loss: 0.47679415345191956 | train accu: 0.742 | train roc: 0.908 | train f1: 0.7328306322529011\n",
      "batch idx 42: | train loss: 0.541792094707489 | train accu: 0.703 | train roc: 0.902 | train f1: 0.688379321436563\n",
      "batch idx 43: | train loss: 0.5590134859085083 | train accu: 0.688 | train roc: 0.884 | train f1: 0.667703373015873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 44: | train loss: 0.5451882481575012 | train accu: 0.734 | train roc: 0.885 | train f1: 0.7247570784384795\n",
      "batch idx 45: | train loss: 0.659453272819519 | train accu: 0.641 | train roc: 0.825 | train f1: 0.6307031250000001\n",
      "batch idx 46: | train loss: 0.6251614093780518 | train accu: 0.680 | train roc: 0.866 | train f1: 0.6756905241935485\n",
      "batch idx 47: | train loss: 0.5799912810325623 | train accu: 0.719 | train roc: 0.875 | train f1: 0.7056414662084765\n",
      "batch idx 48: | train loss: 0.5297915935516357 | train accu: 0.773 | train roc: 0.875 | train f1: 0.7619582636566331\n",
      "batch idx 49: | train loss: 0.5552845597267151 | train accu: 0.664 | train roc: 0.873 | train f1: 0.6422615361628737\n",
      "batch idx 50: | train loss: 0.5301243662834167 | train accu: 0.680 | train roc: 0.898 | train f1: 0.647051282051282\n",
      "batch idx 51: | train loss: 0.6028410792350769 | train accu: 0.672 | train roc: 0.841 | train f1: 0.6288244912790699\n",
      "batch idx 52: | train loss: 0.5337679386138916 | train accu: 0.656 | train roc: 0.906 | train f1: 0.6305482654338155\n",
      "batch idx 53: | train loss: 0.45683446526527405 | train accu: 0.773 | train roc: 0.894 | train f1: 0.7512550320461888\n",
      "batch idx 54: | train loss: 0.4669043719768524 | train accu: 0.773 | train roc: 0.900 | train f1: 0.760953164160401\n",
      "batch idx 55: | train loss: 0.502799391746521 | train accu: 0.688 | train roc: 0.878 | train f1: 0.6646920787545787\n",
      "batch idx 56: | train loss: 0.43944230675697327 | train accu: 0.742 | train roc: 0.926 | train f1: 0.7302080079141935\n",
      "batch idx 57: | train loss: 0.4734657406806946 | train accu: 0.750 | train roc: 0.918 | train f1: 0.7454676611498259\n",
      "batch idx 58: | train loss: 0.546846330165863 | train accu: 0.711 | train roc: 0.888 | train f1: 0.6864800338842337\n",
      "batch idx 59: | train loss: 0.5325596332550049 | train accu: 0.789 | train roc: 0.896 | train f1: 0.7786495263367725\n",
      "batch idx 60: | train loss: 0.49226006865501404 | train accu: 0.789 | train roc: 0.910 | train f1: 0.785051921583851\n",
      "batch idx 61: | train loss: 0.5353295207023621 | train accu: 0.727 | train roc: 0.877 | train f1: 0.7124357876712328\n",
      "batch idx 62: | train loss: 0.5074248313903809 | train accu: 0.742 | train roc: 0.902 | train f1: 0.7417324406737471\n",
      "batch idx 63: | train loss: 0.4627037048339844 | train accu: 0.781 | train roc: 0.914 | train f1: 0.7783175724256455\n",
      "batch idx 64: | train loss: 0.4214530289173126 | train accu: 0.812 | train roc: 0.896 | train f1: 0.8072384981882795\n",
      "batch idx 65: | train loss: 0.587324857711792 | train accu: 0.703 | train roc: 0.870 | train f1: 0.6825061002661934\n",
      "batch idx 66: | train loss: 0.5240299701690674 | train accu: 0.727 | train roc: 0.875 | train f1: 0.6913477251028202\n",
      "batch idx 67: | train loss: 0.4739919900894165 | train accu: 0.750 | train roc: 0.911 | train f1: 0.7248882637121037\n",
      "batch idx 68: | train loss: 0.5946349501609802 | train accu: 0.680 | train roc: 0.881 | train f1: 0.6572958653036778\n",
      "batch idx 69: | train loss: 0.567643404006958 | train accu: 0.742 | train roc: 0.899 | train f1: 0.7318890181340969\n",
      "batch idx 70: | train loss: 0.5005342960357666 | train accu: 0.734 | train roc: 0.908 | train f1: 0.7224745427379462\n",
      "batch idx 71: | train loss: 0.5257756114006042 | train accu: 0.750 | train roc: 0.891 | train f1: 0.7465462781761563\n",
      "batch idx 72: | train loss: 0.5643600225448608 | train accu: 0.750 | train roc: 0.877 | train f1: 0.7419862689393939\n",
      "batch idx 73: | train loss: 0.5243691205978394 | train accu: 0.742 | train roc: 0.874 | train f1: 0.738554725168756\n",
      "batch idx 74: | train loss: 0.6359503865242004 | train accu: 0.641 | train roc: 0.870 | train f1: 0.6062861008112015\n",
      "batch idx 75: | train loss: 0.45279985666275024 | train accu: 0.766 | train roc: 0.927 | train f1: 0.7600689666537578\n",
      "batch idx 76: | train loss: 0.5334933996200562 | train accu: 0.742 | train roc: 0.896 | train f1: 0.715635809896225\n",
      "batch idx 77: | train loss: 0.5466493368148804 | train accu: 0.703 | train roc: 0.892 | train f1: 0.6837880097915918\n",
      "batch idx 78: | train loss: 0.4736839234828949 | train accu: 0.734 | train roc: 0.911 | train f1: 0.7148461538461538\n",
      "batch idx 79: | train loss: 0.5839142799377441 | train accu: 0.703 | train roc: 0.878 | train f1: 0.6808052327789169\n",
      "batch idx 80: | train loss: 0.44765153527259827 | train accu: 0.805 | train roc: 0.916 | train f1: 0.7899304315355391\n",
      "batch idx 81: | train loss: 0.6088907718658447 | train accu: 0.688 | train roc: 0.877 | train f1: 0.6875566918305244\n",
      "batch idx 82: | train loss: 0.5135282874107361 | train accu: 0.680 | train roc: 0.896 | train f1: 0.6649559921763868\n",
      "batch idx 83: | train loss: 0.5210939645767212 | train accu: 0.781 | train roc: 0.890 | train f1: 0.7712053571428572\n",
      "batch idx 84: | train loss: 0.5248458981513977 | train accu: 0.711 | train roc: 0.893 | train f1: 0.7036380765177357\n",
      "batch idx 85: | train loss: 0.5917418599128723 | train accu: 0.727 | train roc: 0.873 | train f1: 0.719676041320483\n",
      "batch idx 86: | train loss: 0.4960426986217499 | train accu: 0.742 | train roc: 0.905 | train f1: 0.7210200119474313\n",
      "batch idx 87: | train loss: 0.6654344201087952 | train accu: 0.617 | train roc: 0.888 | train f1: 0.5839837356792144\n",
      "batch idx 88: | train loss: 0.5547707080841064 | train accu: 0.680 | train roc: 0.891 | train f1: 0.6461385836385837\n",
      "batch idx 89: | train loss: 0.5380754470825195 | train accu: 0.734 | train roc: 0.888 | train f1: 0.7130779848171153\n",
      "batch idx 90: | train loss: 0.505809485912323 | train accu: 0.742 | train roc: 0.893 | train f1: 0.7267979048964219\n",
      "batch idx 91: | train loss: 0.4646224081516266 | train accu: 0.781 | train roc: 0.915 | train f1: 0.7774370706809521\n",
      "batch idx 92: | train loss: 0.5968325734138489 | train accu: 0.672 | train roc: 0.851 | train f1: 0.6596746522861152\n",
      "batch idx 93: | train loss: 0.47680604457855225 | train accu: 0.734 | train roc: 0.910 | train f1: 0.7181449440350389\n",
      "batch idx 94: | train loss: 0.4852170944213867 | train accu: 0.758 | train roc: 0.912 | train f1: 0.7438894921303862\n",
      "batch idx 95: | train loss: 0.6404684782028198 | train accu: 0.703 | train roc: 0.853 | train f1: 0.6829646657413835\n",
      "batch idx 96: | train loss: 0.44385984539985657 | train accu: 0.789 | train roc: 0.909 | train f1: 0.7719963121118012\n",
      "batch idx 97: | train loss: 0.4508538246154785 | train accu: 0.719 | train roc: 0.904 | train f1: 0.6990442439862543\n",
      "batch idx 98: | train loss: 0.509626030921936 | train accu: 0.711 | train roc: 0.898 | train f1: 0.6957146471949105\n",
      "batch idx 99: | train loss: 0.4320092797279358 | train accu: 0.797 | train roc: 0.932 | train f1: 0.7882533276135524\n",
      "batch idx 100: | train loss: 0.5615895986557007 | train accu: 0.711 | train roc: 0.885 | train f1: 0.6748326286116983\n",
      "batch idx 101: | train loss: 0.4719931185245514 | train accu: 0.750 | train roc: 0.909 | train f1: 0.7416910535117056\n",
      "batch idx 102: | train loss: 0.5661046504974365 | train accu: 0.695 | train roc: 0.873 | train f1: 0.675873390144887\n",
      "batch idx 103: | train loss: 0.5186927914619446 | train accu: 0.688 | train roc: 0.910 | train f1: 0.6724878246753248\n",
      "batch idx 104: | train loss: 0.5488983392715454 | train accu: 0.719 | train roc: 0.895 | train f1: 0.712917578980294\n",
      "batch idx 105: | train loss: 0.5652086734771729 | train accu: 0.727 | train roc: 0.886 | train f1: 0.7263685555206011\n",
      "batch idx 106: | train loss: 0.41620272397994995 | train accu: 0.805 | train roc: 0.945 | train f1: 0.8026353296455182\n",
      "batch idx 107: | train loss: 0.6046952605247498 | train accu: 0.695 | train roc: 0.860 | train f1: 0.6790707910252212\n",
      "batch idx 108: | train loss: 0.5349909663200378 | train accu: 0.727 | train roc: 0.876 | train f1: 0.720763996388029\n",
      "batch idx 109: | train loss: 0.47482043504714966 | train accu: 0.734 | train roc: 0.914 | train f1: 0.7252872369878184\n",
      "batch idx 110: | train loss: 0.5007458925247192 | train accu: 0.734 | train roc: 0.901 | train f1: 0.7261974927205347\n",
      "batch idx 111: | train loss: 0.4743870496749878 | train accu: 0.773 | train roc: 0.893 | train f1: 0.7563839394123362\n",
      "batch idx 112: | train loss: 0.5052294135093689 | train accu: 0.750 | train roc: 0.892 | train f1: 0.7366952537593985\n",
      "batch idx 113: | train loss: 0.5767726302146912 | train accu: 0.672 | train roc: 0.873 | train f1: 0.6348030249281275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 114: | train loss: 0.5892453193664551 | train accu: 0.703 | train roc: 0.826 | train f1: 0.690165626047603\n",
      "batch idx 115: | train loss: 0.470944344997406 | train accu: 0.750 | train roc: 0.909 | train f1: 0.7475039821690503\n",
      "batch idx 116: | train loss: 0.5098384022712708 | train accu: 0.742 | train roc: 0.913 | train f1: 0.7289708646616542\n",
      "batch idx 117: | train loss: 0.5981770157814026 | train accu: 0.656 | train roc: 0.874 | train f1: 0.6381174865779645\n",
      "batch idx 118: | train loss: 0.5390107035636902 | train accu: 0.766 | train roc: 0.892 | train f1: 0.756036895253225\n",
      "batch idx 119: | train loss: 0.5079920887947083 | train accu: 0.766 | train roc: 0.905 | train f1: 0.7655551912098075\n",
      "batch idx 120: | train loss: 0.5625738501548767 | train accu: 0.695 | train roc: 0.913 | train f1: 0.6913247473870956\n",
      "batch idx 121: | train loss: 0.5510715246200562 | train accu: 0.750 | train roc: 0.891 | train f1: 0.7416266925680874\n",
      "batch idx 122: | train loss: 0.5150070190429688 | train accu: 0.766 | train roc: 0.888 | train f1: 0.7545838100686499\n",
      "batch idx 123: | train loss: 0.48942849040031433 | train accu: 0.695 | train roc: 0.906 | train f1: 0.6580414117132867\n",
      "batch idx 124: | train loss: 0.5483567714691162 | train accu: 0.727 | train roc: 0.865 | train f1: 0.696766774891775\n",
      "batch idx 125: | train loss: 0.5188170075416565 | train accu: 0.734 | train roc: 0.910 | train f1: 0.7114993501492248\n",
      "batch idx 126: | train loss: 0.5881133675575256 | train accu: 0.719 | train roc: 0.890 | train f1: 0.7033582089552238\n",
      "batch idx 127: | train loss: 0.5481452941894531 | train accu: 0.719 | train roc: 0.881 | train f1: 0.684688241810413\n",
      "batch idx 128: | train loss: 0.4533078670501709 | train accu: 0.781 | train roc: 0.920 | train f1: 0.7667425383351589\n",
      "batch idx 129: | train loss: 0.5036393404006958 | train accu: 0.750 | train roc: 0.916 | train f1: 0.7488356370192308\n",
      "batch idx 130: | train loss: 0.38748109340667725 | train accu: 0.805 | train roc: 0.940 | train f1: 0.7957213359557109\n",
      "batch idx 131: | train loss: 0.636689305305481 | train accu: 0.719 | train roc: 0.869 | train f1: 0.7239466867918902\n",
      "batch idx 132: | train loss: 0.45428624749183655 | train accu: 0.789 | train roc: 0.922 | train f1: 0.7875673343767757\n",
      "batch idx 133: | train loss: 0.45852866768836975 | train accu: 0.797 | train roc: 0.905 | train f1: 0.7963634672619047\n",
      "batch idx 134: | train loss: 0.48299458622932434 | train accu: 0.742 | train roc: 0.921 | train f1: 0.7298672027290448\n",
      "batch idx 135: | train loss: 0.5535885691642761 | train accu: 0.711 | train roc: 0.903 | train f1: 0.6976201367488444\n",
      "batch idx 136: | train loss: 0.5934575796127319 | train accu: 0.672 | train roc: 0.874 | train f1: 0.6354287160208214\n",
      "batch idx 137: | train loss: 0.4752565324306488 | train accu: 0.734 | train roc: 0.911 | train f1: 0.7022010132224998\n",
      "batch idx 138: | train loss: 0.5998042225837708 | train accu: 0.633 | train roc: 0.870 | train f1: 0.5954826423576423\n",
      "batch idx 139: | train loss: 0.5937349796295166 | train accu: 0.688 | train roc: 0.849 | train f1: 0.6613756197901696\n",
      "batch idx 140: | train loss: 0.5558435320854187 | train accu: 0.711 | train roc: 0.879 | train f1: 0.6885620437664084\n",
      "batch idx 141: | train loss: 0.4925878047943115 | train accu: 0.758 | train roc: 0.915 | train f1: 0.7459983668623374\n",
      "batch idx 142: | train loss: 0.4806520342826843 | train accu: 0.781 | train roc: 0.923 | train f1: 0.7730731355042016\n",
      "batch idx 143: | train loss: 0.5663859844207764 | train accu: 0.719 | train roc: 0.883 | train f1: 0.7064254679144384\n",
      "batch idx 144: | train loss: 0.5619901418685913 | train accu: 0.742 | train roc: 0.882 | train f1: 0.7339661376837534\n",
      "batch idx 145: | train loss: 0.5523348450660706 | train accu: 0.711 | train roc: 0.911 | train f1: 0.7062802650827746\n",
      "batch idx 146: | train loss: 0.41443416476249695 | train accu: 0.789 | train roc: 0.937 | train f1: 0.7769006718718058\n",
      "batch idx 147: | train loss: 0.5569586753845215 | train accu: 0.766 | train roc: 0.896 | train f1: 0.7609655264265045\n",
      "batch idx 148: | train loss: 0.47704005241394043 | train accu: 0.750 | train roc: 0.902 | train f1: 0.7317975838087956\n",
      "batch idx 149: | train loss: 0.5683690905570984 | train accu: 0.727 | train roc: 0.871 | train f1: 0.7174504047046182\n",
      "batch idx 150: | train loss: 0.5192892551422119 | train accu: 0.711 | train roc: 0.877 | train f1: 0.6819287447988904\n",
      "batch idx 151: | train loss: 0.5035577416419983 | train accu: 0.742 | train roc: 0.910 | train f1: 0.7296280625402966\n",
      "batch idx 152: | train loss: 0.5836013555526733 | train accu: 0.656 | train roc: 0.877 | train f1: 0.6490363798191032\n",
      "batch idx 153: | train loss: 0.4242940843105316 | train accu: 0.820 | train roc: 0.905 | train f1: 0.8121744311759791\n",
      "batch idx 154: | train loss: 0.5313690304756165 | train accu: 0.711 | train roc: 0.920 | train f1: 0.6947970488871225\n",
      "batch idx 155: | train loss: 0.4930644929409027 | train accu: 0.719 | train roc: 0.913 | train f1: 0.697287326388889\n",
      "batch idx 156: | train loss: 0.4716270864009857 | train accu: 0.773 | train roc: 0.917 | train f1: 0.7612612832318817\n",
      "batch idx 157: | train loss: 0.569782555103302 | train accu: 0.664 | train roc: 0.882 | train f1: 0.6532335069444446\n",
      "batch idx 158: | train loss: 0.4231517016887665 | train accu: 0.773 | train roc: 0.928 | train f1: 0.7515191646471551\n",
      "batch idx 159: | train loss: 0.5217999219894409 | train accu: 0.727 | train roc: 0.897 | train f1: 0.7045177547233468\n",
      "batch idx 160: | train loss: 0.587920069694519 | train accu: 0.688 | train roc: 0.873 | train f1: 0.6633553340517242\n",
      "batch idx 161: | train loss: 0.48467984795570374 | train accu: 0.773 | train roc: 0.909 | train f1: 0.7546811740890689\n",
      "batch idx 162: | train loss: 0.42664027214050293 | train accu: 0.773 | train roc: 0.926 | train f1: 0.7610111005930935\n",
      "batch idx 163: | train loss: 0.49457883834838867 | train accu: 0.773 | train roc: 0.903 | train f1: 0.764492354643846\n",
      "batch idx 164: | train loss: 0.5214442014694214 | train accu: 0.742 | train roc: 0.894 | train f1: 0.7352720960595029\n",
      "batch idx 165: | train loss: 0.5889610648155212 | train accu: 0.703 | train roc: 0.856 | train f1: 0.6860505535656137\n",
      "batch idx 166: | train loss: 0.4656338691711426 | train accu: 0.750 | train roc: 0.895 | train f1: 0.7401599223145275\n",
      "batch idx 167: | train loss: 0.46221521496772766 | train accu: 0.773 | train roc: 0.909 | train f1: 0.7446836890243902\n",
      "batch idx 168: | train loss: 0.5242486000061035 | train accu: 0.727 | train roc: 0.895 | train f1: 0.7131184895833333\n",
      "batch idx 169: | train loss: 0.6052960157394409 | train accu: 0.664 | train roc: 0.878 | train f1: 0.6478217112830111\n",
      "batch idx 170: | train loss: 0.4759966731071472 | train accu: 0.766 | train roc: 0.904 | train f1: 0.7583088179651141\n",
      "batch idx 171: | train loss: 0.5526336431503296 | train accu: 0.648 | train roc: 0.889 | train f1: 0.6236979166666667\n",
      "batch idx 172: | train loss: 0.5320466756820679 | train accu: 0.742 | train roc: 0.903 | train f1: 0.7350643382352942\n",
      "batch idx 173: | train loss: 0.408613920211792 | train accu: 0.820 | train roc: 0.941 | train f1: 0.8144475854605164\n",
      "batch idx 174: | train loss: 0.5109182596206665 | train accu: 0.734 | train roc: 0.909 | train f1: 0.7325970262096775\n",
      "batch idx 175: | train loss: 0.5212821364402771 | train accu: 0.742 | train roc: 0.895 | train f1: 0.7340758087633088\n",
      "batch idx 176: | train loss: 0.42041853070259094 | train accu: 0.773 | train roc: 0.941 | train f1: 0.7684027777777778\n",
      "batch idx 177: | train loss: 0.46509677171707153 | train accu: 0.766 | train roc: 0.904 | train f1: 0.7570090899610679\n",
      "batch idx 178: | train loss: 0.5376448631286621 | train accu: 0.742 | train roc: 0.870 | train f1: 0.7243942377082614\n",
      "batch idx 179: | train loss: 0.46717962622642517 | train accu: 0.742 | train roc: 0.900 | train f1: 0.7217394986449863\n",
      "batch idx 180: | train loss: 0.5156108140945435 | train accu: 0.766 | train roc: 0.908 | train f1: 0.7569849275328183\n",
      "batch idx 181: | train loss: 0.6147827506065369 | train accu: 0.664 | train roc: 0.830 | train f1: 0.6450411113998293\n",
      "batch idx 182: | train loss: 0.46230950951576233 | train accu: 0.773 | train roc: 0.905 | train f1: 0.7453471178192752\n",
      "batch idx 183: | train loss: 0.4902767837047577 | train accu: 0.742 | train roc: 0.929 | train f1: 0.7370474279161207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 184: | train loss: 0.5194953083992004 | train accu: 0.680 | train roc: 0.901 | train f1: 0.6506923811544991\n",
      "batch idx 185: | train loss: 0.45370545983314514 | train accu: 0.773 | train roc: 0.932 | train f1: 0.7666164169026763\n",
      "batch idx 186: | train loss: 0.5184860229492188 | train accu: 0.742 | train roc: 0.859 | train f1: 0.7466261108760051\n",
      "batch idx 187: | train loss: 0.5567883849143982 | train accu: 0.727 | train roc: 0.889 | train f1: 0.725292248337689\n",
      "batch idx 188: | train loss: 0.49478861689567566 | train accu: 0.727 | train roc: 0.899 | train f1: 0.7175138533674339\n",
      "batch idx 189: | train loss: 0.43352270126342773 | train accu: 0.727 | train roc: 0.935 | train f1: 0.6909473623918896\n",
      "batch idx 190: | train loss: 0.5110863447189331 | train accu: 0.727 | train roc: 0.853 | train f1: 0.6992797298384706\n",
      "batch idx 191: | train loss: 0.5210874676704407 | train accu: 0.727 | train roc: 0.912 | train f1: 0.705016121031746\n",
      "batch idx 192: | train loss: 0.4587893486022949 | train accu: 0.719 | train roc: 0.907 | train f1: 0.682958761415525\n",
      "batch idx 193: | train loss: 0.6363304853439331 | train accu: 0.695 | train roc: 0.858 | train f1: 0.6758483284618195\n",
      "batch idx 194: | train loss: 0.4573898911476135 | train accu: 0.727 | train roc: 0.913 | train f1: 0.7179386961634302\n",
      "batch idx 195: | train loss: 0.5482533574104309 | train accu: 0.727 | train roc: 0.883 | train f1: 0.7244188804554079\n",
      "batch idx 196: | train loss: 0.4474495053291321 | train accu: 0.836 | train roc: 0.926 | train f1: 0.8328410334107592\n",
      "batch idx 197: | train loss: 0.5367923974990845 | train accu: 0.734 | train roc: 0.906 | train f1: 0.7224612332359939\n",
      "batch idx 198: | train loss: 0.5976520776748657 | train accu: 0.695 | train roc: 0.865 | train f1: 0.6937030149053252\n",
      "batch idx 199: | train loss: 0.42423826456069946 | train accu: 0.812 | train roc: 0.926 | train f1: 0.8114499327956989\n",
      "batch idx 200: | train loss: 0.5588552355766296 | train accu: 0.711 | train roc: 0.875 | train f1: 0.7058409414879177\n",
      "batch idx 201: | train loss: 0.538618803024292 | train accu: 0.719 | train roc: 0.909 | train f1: 0.7126667490118578\n",
      "batch idx 202: | train loss: 0.5120468139648438 | train accu: 0.727 | train roc: 0.898 | train f1: 0.7100225225225225\n",
      "batch idx 203: | train loss: 0.5891263484954834 | train accu: 0.648 | train roc: 0.865 | train f1: 0.6052677249166974\n",
      "batch idx 204: | train loss: 0.48420700430870056 | train accu: 0.703 | train roc: 0.879 | train f1: 0.6739216657767189\n",
      "batch idx 205: | train loss: 0.5743717551231384 | train accu: 0.750 | train roc: 0.891 | train f1: 0.7483827334744766\n",
      "batch idx 206: | train loss: 0.5183777809143066 | train accu: 0.727 | train roc: 0.908 | train f1: 0.7095767020335986\n",
      "batch idx 207: | train loss: 0.4773443937301636 | train accu: 0.734 | train roc: 0.883 | train f1: 0.6946072560215449\n",
      "batch idx 208: | train loss: 0.5913605690002441 | train accu: 0.656 | train roc: 0.892 | train f1: 0.6461365492544815\n",
      "batch idx 209: | train loss: 0.4801003634929657 | train accu: 0.797 | train roc: 0.885 | train f1: 0.786734905267896\n",
      "batch idx 210: | train loss: 0.5446428060531616 | train accu: 0.711 | train roc: 0.886 | train f1: 0.7087002361673413\n",
      "batch idx 211: | train loss: 0.46651381254196167 | train accu: 0.758 | train roc: 0.924 | train f1: 0.7548438204940221\n",
      "batch idx 212: | train loss: 0.48600688576698303 | train accu: 0.766 | train roc: 0.897 | train f1: 0.7589682162649143\n",
      "batch idx 213: | train loss: 0.6249148845672607 | train accu: 0.688 | train roc: 0.839 | train f1: 0.6757622593738813\n",
      "batch idx 214: | train loss: 0.5925070643424988 | train accu: 0.688 | train roc: 0.866 | train f1: 0.682781954887218\n",
      "batch idx 215: | train loss: 0.5925345420837402 | train accu: 0.672 | train roc: 0.861 | train f1: 0.652418831168831\n",
      "batch idx 216: | train loss: 0.5124883651733398 | train accu: 0.742 | train roc: 0.903 | train f1: 0.7202660512606902\n",
      "batch idx 217: | train loss: 0.4362984001636505 | train accu: 0.789 | train roc: 0.938 | train f1: 0.7690493871258836\n",
      "batch idx 218: | train loss: 0.49831655621528625 | train accu: 0.727 | train roc: 0.900 | train f1: 0.7068703491977366\n",
      "batch idx 219: | train loss: 0.5522046089172363 | train accu: 0.680 | train roc: 0.892 | train f1: 0.6689912900188323\n",
      "batch idx 220: | train loss: 0.4612478017807007 | train accu: 0.750 | train roc: 0.906 | train f1: 0.7259286394413881\n",
      "batch idx 221: | train loss: 0.4264858067035675 | train accu: 0.781 | train roc: 0.921 | train f1: 0.7706648819930071\n",
      "batch idx 222: | train loss: 0.46429896354675293 | train accu: 0.750 | train roc: 0.907 | train f1: 0.7444830388909336\n",
      "batch idx 223: | train loss: 0.5270231366157532 | train accu: 0.750 | train roc: 0.905 | train f1: 0.748114513596165\n",
      "batch idx 224: | train loss: 0.6200135350227356 | train accu: 0.672 | train roc: 0.838 | train f1: 0.6376028907238549\n",
      "batch idx 225: | train loss: 0.5786232948303223 | train accu: 0.719 | train roc: 0.870 | train f1: 0.7159733976115001\n",
      "batch idx 226: | train loss: 0.5203534960746765 | train accu: 0.719 | train roc: 0.886 | train f1: 0.697164522577421\n",
      "batch idx 227: | train loss: 0.4299166798591614 | train accu: 0.766 | train roc: 0.906 | train f1: 0.7533011550538278\n",
      "batch idx 228: | train loss: 0.5560916662216187 | train accu: 0.742 | train roc: 0.890 | train f1: 0.7315182803761705\n",
      "batch idx 229: | train loss: 0.41430526971817017 | train accu: 0.781 | train roc: 0.917 | train f1: 0.7571065437569235\n",
      "batch idx 230: | train loss: 0.4388416111469269 | train accu: 0.773 | train roc: 0.899 | train f1: 0.7612259234501882\n",
      "batch idx 231: | train loss: 0.4920792579650879 | train accu: 0.695 | train roc: 0.902 | train f1: 0.6635167331560284\n",
      "batch idx 232: | train loss: 0.3406373858451843 | train accu: 0.797 | train roc: 0.959 | train f1: 0.7803581356560415\n",
      "batch idx 233: | train loss: 0.5589084029197693 | train accu: 0.727 | train roc: 0.869 | train f1: 0.7135239109848486\n",
      "batch idx 234: | train loss: 0.5270639061927795 | train accu: 0.750 | train roc: 0.871 | train f1: 0.739958664021164\n",
      "batch idx 235: | train loss: 0.49977365136146545 | train accu: 0.734 | train roc: 0.907 | train f1: 0.709359335839599\n",
      "batch idx 236: | train loss: 0.4955204129219055 | train accu: 0.742 | train roc: 0.914 | train f1: 0.7326836734693878\n",
      "batch idx 237: | train loss: 0.43040230870246887 | train accu: 0.812 | train roc: 0.929 | train f1: 0.8072586202413147\n",
      "batch idx 238: | train loss: 0.5776254534721375 | train accu: 0.703 | train roc: 0.867 | train f1: 0.6855585393165229\n",
      "batch idx 239: | train loss: 0.474607914686203 | train accu: 0.758 | train roc: 0.897 | train f1: 0.7374616956077631\n",
      "batch idx 240: | train loss: 0.473941832780838 | train accu: 0.734 | train roc: 0.921 | train f1: 0.7235795454545455\n",
      "Epoch: 04 | Epoch Time: 2m 14s\n",
      "\tTrain Loss: 0.514 | Train Acc: 73.47 | Train rocauc: 0.8965673937697303 | Train f1: 0.7204405696266886%\n",
      "\t Val. Loss: 0.619 |  Val. Acc: 66.97 | Val. rocauc: 0.8487169259337708 | Val. f1: 0.6465325829912515%\n",
      "batch idx 0: | train loss: 0.48009657859802246 | train accu: 0.719 | train roc: 0.927 | train f1: 0.7031934623760299\n",
      "batch idx 1: | train loss: 0.4577035903930664 | train accu: 0.750 | train roc: 0.894 | train f1: 0.7252402683752418\n",
      "batch idx 2: | train loss: 0.4796443581581116 | train accu: 0.766 | train roc: 0.908 | train f1: 0.7457913421896474\n",
      "batch idx 3: | train loss: 0.4253637194633484 | train accu: 0.789 | train roc: 0.928 | train f1: 0.7748396766377006\n",
      "batch idx 4: | train loss: 0.43990689516067505 | train accu: 0.773 | train roc: 0.926 | train f1: 0.7586790320265726\n",
      "batch idx 5: | train loss: 0.5302905440330505 | train accu: 0.688 | train roc: 0.872 | train f1: 0.6640742481203008\n",
      "batch idx 6: | train loss: 0.37742581963539124 | train accu: 0.844 | train roc: 0.947 | train f1: 0.8429834873233241\n",
      "batch idx 7: | train loss: 0.4774639904499054 | train accu: 0.797 | train roc: 0.922 | train f1: 0.7962221867325944\n",
      "batch idx 8: | train loss: 0.3926337957382202 | train accu: 0.836 | train roc: 0.926 | train f1: 0.8336189516129033\n",
      "batch idx 9: | train loss: 0.43647539615631104 | train accu: 0.781 | train roc: 0.922 | train f1: 0.7766682330827068\n",
      "batch idx 10: | train loss: 0.560998797416687 | train accu: 0.711 | train roc: 0.889 | train f1: 0.6995933305200547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 11: | train loss: 0.5052547454833984 | train accu: 0.734 | train roc: 0.925 | train f1: 0.7223660714285715\n",
      "batch idx 12: | train loss: 0.39660245180130005 | train accu: 0.781 | train roc: 0.928 | train f1: 0.7676873059006211\n",
      "batch idx 13: | train loss: 0.5216965675354004 | train accu: 0.727 | train roc: 0.901 | train f1: 0.7126677119165479\n",
      "batch idx 14: | train loss: 0.5364985466003418 | train accu: 0.727 | train roc: 0.911 | train f1: 0.7203458536536615\n",
      "batch idx 15: | train loss: 0.48108771443367004 | train accu: 0.789 | train roc: 0.896 | train f1: 0.7769454661051711\n",
      "batch idx 16: | train loss: 0.5330414772033691 | train accu: 0.750 | train roc: 0.913 | train f1: 0.7517387068021923\n",
      "batch idx 17: | train loss: 0.5723127722740173 | train accu: 0.758 | train roc: 0.899 | train f1: 0.7483634492767415\n",
      "batch idx 18: | train loss: 0.6368551254272461 | train accu: 0.648 | train roc: 0.883 | train f1: 0.6407609554248493\n",
      "batch idx 19: | train loss: 0.5350262522697449 | train accu: 0.711 | train roc: 0.897 | train f1: 0.6970847653413443\n",
      "batch idx 20: | train loss: 0.5148293972015381 | train accu: 0.758 | train roc: 0.910 | train f1: 0.7508793270574982\n",
      "batch idx 21: | train loss: 0.513608455657959 | train accu: 0.766 | train roc: 0.908 | train f1: 0.7655841236102028\n",
      "batch idx 22: | train loss: 0.46512284874916077 | train accu: 0.820 | train roc: 0.936 | train f1: 0.8166354118230175\n",
      "batch idx 23: | train loss: 0.48443886637687683 | train accu: 0.750 | train roc: 0.923 | train f1: 0.741692546583851\n",
      "batch idx 24: | train loss: 0.5071095824241638 | train accu: 0.750 | train roc: 0.906 | train f1: 0.7378153084150327\n",
      "batch idx 25: | train loss: 0.36588627099990845 | train accu: 0.867 | train roc: 0.949 | train f1: 0.8643860251590514\n",
      "batch idx 26: | train loss: 0.4392036199569702 | train accu: 0.766 | train roc: 0.938 | train f1: 0.7596153846153846\n",
      "batch idx 27: | train loss: 0.4822399616241455 | train accu: 0.773 | train roc: 0.906 | train f1: 0.7651274370918171\n",
      "batch idx 28: | train loss: 0.42430394887924194 | train accu: 0.766 | train roc: 0.928 | train f1: 0.7609846443965518\n",
      "batch idx 29: | train loss: 0.3184639811515808 | train accu: 0.844 | train roc: 0.949 | train f1: 0.835580624450283\n",
      "batch idx 30: | train loss: 0.4545671343803406 | train accu: 0.758 | train roc: 0.914 | train f1: 0.7283949557387057\n",
      "batch idx 31: | train loss: 0.5286169648170471 | train accu: 0.781 | train roc: 0.916 | train f1: 0.7734708392603129\n",
      "batch idx 32: | train loss: 0.5012891292572021 | train accu: 0.734 | train roc: 0.907 | train f1: 0.7201576291271659\n",
      "batch idx 33: | train loss: 0.5227813124656677 | train accu: 0.742 | train roc: 0.907 | train f1: 0.7170973557692308\n",
      "batch idx 34: | train loss: 0.5239534974098206 | train accu: 0.758 | train roc: 0.906 | train f1: 0.7535958359821997\n",
      "batch idx 35: | train loss: 0.5459634065628052 | train accu: 0.695 | train roc: 0.869 | train f1: 0.6739783653846154\n",
      "batch idx 36: | train loss: 0.49651870131492615 | train accu: 0.734 | train roc: 0.892 | train f1: 0.7286195728291316\n",
      "batch idx 37: | train loss: 0.46783363819122314 | train accu: 0.797 | train roc: 0.929 | train f1: 0.7958439860164603\n",
      "batch idx 38: | train loss: 0.49638137221336365 | train accu: 0.773 | train roc: 0.908 | train f1: 0.7714634146341464\n",
      "batch idx 39: | train loss: 0.5340644121170044 | train accu: 0.742 | train roc: 0.898 | train f1: 0.73955584457103\n",
      "batch idx 40: | train loss: 0.5279127955436707 | train accu: 0.719 | train roc: 0.892 | train f1: 0.7159544245647969\n",
      "batch idx 41: | train loss: 0.466360867023468 | train accu: 0.727 | train roc: 0.926 | train f1: 0.7159421247357294\n",
      "batch idx 42: | train loss: 0.5610657930374146 | train accu: 0.750 | train roc: 0.899 | train f1: 0.7533059845559844\n",
      "batch idx 43: | train loss: 0.4561938941478729 | train accu: 0.734 | train roc: 0.938 | train f1: 0.7239538433908046\n",
      "batch idx 44: | train loss: 0.534694492816925 | train accu: 0.750 | train roc: 0.904 | train f1: 0.7287584139678448\n",
      "batch idx 45: | train loss: 0.5362960696220398 | train accu: 0.750 | train roc: 0.898 | train f1: 0.7368376958071614\n",
      "batch idx 46: | train loss: 0.5003010034561157 | train accu: 0.742 | train roc: 0.907 | train f1: 0.7357648729924287\n",
      "batch idx 47: | train loss: 0.5167839527130127 | train accu: 0.727 | train roc: 0.910 | train f1: 0.7173878205128205\n",
      "batch idx 48: | train loss: 0.451186865568161 | train accu: 0.773 | train roc: 0.921 | train f1: 0.7724651702786378\n",
      "batch idx 49: | train loss: 0.4914250373840332 | train accu: 0.758 | train roc: 0.917 | train f1: 0.7557490818634494\n",
      "batch idx 50: | train loss: 0.3840119242668152 | train accu: 0.812 | train roc: 0.940 | train f1: 0.7968667475407671\n",
      "batch idx 51: | train loss: 0.5522251129150391 | train accu: 0.711 | train roc: 0.893 | train f1: 0.6897615131578947\n",
      "batch idx 52: | train loss: 0.4896951913833618 | train accu: 0.719 | train roc: 0.909 | train f1: 0.6810949612403101\n",
      "batch idx 53: | train loss: 0.4176886975765228 | train accu: 0.758 | train roc: 0.934 | train f1: 0.7275027316433565\n",
      "batch idx 54: | train loss: 0.506452202796936 | train accu: 0.711 | train roc: 0.891 | train f1: 0.6512340328467153\n",
      "batch idx 55: | train loss: 0.4353700876235962 | train accu: 0.789 | train roc: 0.923 | train f1: 0.7774931524931525\n",
      "batch idx 56: | train loss: 0.5756410956382751 | train accu: 0.734 | train roc: 0.890 | train f1: 0.7224417739147136\n",
      "batch idx 57: | train loss: 0.4349139332771301 | train accu: 0.828 | train roc: 0.919 | train f1: 0.8193268566570432\n",
      "batch idx 58: | train loss: 0.40580135583877563 | train accu: 0.820 | train roc: 0.887 | train f1: 0.8031527849365375\n",
      "batch idx 59: | train loss: 0.535005509853363 | train accu: 0.742 | train roc: 0.879 | train f1: 0.7267307692307693\n",
      "batch idx 60: | train loss: 0.5966746211051941 | train accu: 0.688 | train roc: 0.880 | train f1: 0.6727637235449735\n",
      "batch idx 61: | train loss: 0.44432714581489563 | train accu: 0.742 | train roc: 0.939 | train f1: 0.732266016871865\n",
      "batch idx 62: | train loss: 0.5205978751182556 | train accu: 0.695 | train roc: 0.916 | train f1: 0.6708859298029556\n",
      "batch idx 63: | train loss: 0.427491158246994 | train accu: 0.742 | train roc: 0.936 | train f1: 0.7319743918746191\n",
      "batch idx 64: | train loss: 0.5123389363288879 | train accu: 0.719 | train roc: 0.899 | train f1: 0.6974904575711027\n",
      "batch idx 65: | train loss: 0.4833495616912842 | train accu: 0.836 | train roc: 0.906 | train f1: 0.8330393647786198\n",
      "batch idx 66: | train loss: 0.42018505930900574 | train accu: 0.773 | train roc: 0.938 | train f1: 0.763463611671147\n",
      "batch idx 67: | train loss: 0.4717925190925598 | train accu: 0.797 | train roc: 0.918 | train f1: 0.794859022556391\n",
      "batch idx 68: | train loss: 0.441026508808136 | train accu: 0.812 | train roc: 0.936 | train f1: 0.8117047922888949\n",
      "batch idx 69: | train loss: 0.4443593919277191 | train accu: 0.766 | train roc: 0.924 | train f1: 0.7630617777566856\n",
      "batch idx 70: | train loss: 0.4094759523868561 | train accu: 0.789 | train roc: 0.919 | train f1: 0.7722488113113113\n",
      "batch idx 71: | train loss: 0.44493162631988525 | train accu: 0.789 | train roc: 0.914 | train f1: 0.7846441786456386\n",
      "batch idx 72: | train loss: 0.4784197509288788 | train accu: 0.734 | train roc: 0.914 | train f1: 0.7211964661103839\n",
      "batch idx 73: | train loss: 0.3618702292442322 | train accu: 0.812 | train roc: 0.943 | train f1: 0.8007859848484847\n",
      "batch idx 74: | train loss: 0.5240593552589417 | train accu: 0.734 | train roc: 0.879 | train f1: 0.717053511866257\n",
      "batch idx 75: | train loss: 0.4620477557182312 | train accu: 0.766 | train roc: 0.907 | train f1: 0.746392332489561\n",
      "batch idx 76: | train loss: 0.4417669177055359 | train accu: 0.734 | train roc: 0.905 | train f1: 0.6955890287769784\n",
      "batch idx 77: | train loss: 0.4392494261264801 | train accu: 0.734 | train roc: 0.931 | train f1: 0.7294642857142857\n",
      "batch idx 78: | train loss: 0.5873650908470154 | train accu: 0.727 | train roc: 0.878 | train f1: 0.7257763231586\n",
      "batch idx 79: | train loss: 0.5251330137252808 | train accu: 0.742 | train roc: 0.889 | train f1: 0.7351732778127282\n",
      "batch idx 80: | train loss: 0.5077391266822815 | train accu: 0.766 | train roc: 0.899 | train f1: 0.7593482905982907\n",
      "batch idx 81: | train loss: 0.4813522398471832 | train accu: 0.750 | train roc: 0.914 | train f1: 0.7387705939884839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 82: | train loss: 0.4897913634777069 | train accu: 0.758 | train roc: 0.916 | train f1: 0.7572244673237816\n",
      "batch idx 83: | train loss: 0.4449706971645355 | train accu: 0.828 | train roc: 0.928 | train f1: 0.8257431315549476\n",
      "batch idx 84: | train loss: 0.42794522643089294 | train accu: 0.789 | train roc: 0.928 | train f1: 0.7848121279761905\n",
      "batch idx 85: | train loss: 0.44691866636276245 | train accu: 0.742 | train roc: 0.926 | train f1: 0.7183342086834734\n",
      "batch idx 86: | train loss: 0.5146911144256592 | train accu: 0.789 | train roc: 0.894 | train f1: 0.7742956349206349\n",
      "batch idx 87: | train loss: 0.39830559492111206 | train accu: 0.789 | train roc: 0.936 | train f1: 0.776309258993494\n",
      "batch idx 88: | train loss: 0.4327946603298187 | train accu: 0.820 | train roc: 0.915 | train f1: 0.8108938079542163\n",
      "batch idx 89: | train loss: 0.5167926549911499 | train accu: 0.695 | train roc: 0.890 | train f1: 0.6723559864723657\n",
      "batch idx 90: | train loss: 0.547295093536377 | train accu: 0.703 | train roc: 0.900 | train f1: 0.6725493468153563\n",
      "batch idx 91: | train loss: 0.48193442821502686 | train accu: 0.727 | train roc: 0.917 | train f1: 0.7102929312750741\n",
      "batch idx 92: | train loss: 0.48286446928977966 | train accu: 0.727 | train roc: 0.905 | train f1: 0.7159143518518518\n",
      "batch idx 93: | train loss: 0.5105196833610535 | train accu: 0.711 | train roc: 0.894 | train f1: 0.698743618674164\n",
      "batch idx 94: | train loss: 0.46242237091064453 | train accu: 0.773 | train roc: 0.916 | train f1: 0.7716351688836147\n",
      "batch idx 95: | train loss: 0.5242866277694702 | train accu: 0.719 | train roc: 0.907 | train f1: 0.7071215935427156\n",
      "batch idx 96: | train loss: 0.5543109774589539 | train accu: 0.688 | train roc: 0.891 | train f1: 0.6778308550569213\n",
      "batch idx 97: | train loss: 0.4323289096355438 | train accu: 0.758 | train roc: 0.935 | train f1: 0.7383731969469065\n",
      "batch idx 98: | train loss: 0.4857899248600006 | train accu: 0.727 | train roc: 0.909 | train f1: 0.7072642993979201\n",
      "batch idx 99: | train loss: 0.44706282019615173 | train accu: 0.750 | train roc: 0.925 | train f1: 0.7405759197615924\n",
      "batch idx 100: | train loss: 0.43358278274536133 | train accu: 0.758 | train roc: 0.924 | train f1: 0.732105898373744\n",
      "batch idx 101: | train loss: 0.40376031398773193 | train accu: 0.789 | train roc: 0.940 | train f1: 0.7830461774553572\n",
      "batch idx 102: | train loss: 0.4802778661251068 | train accu: 0.758 | train roc: 0.930 | train f1: 0.7555327654682275\n",
      "batch idx 103: | train loss: 0.5108271241188049 | train accu: 0.750 | train roc: 0.911 | train f1: 0.752234040414484\n",
      "batch idx 104: | train loss: 0.48061004281044006 | train accu: 0.828 | train roc: 0.934 | train f1: 0.8296909395254984\n",
      "batch idx 105: | train loss: 0.3969820439815521 | train accu: 0.758 | train roc: 0.935 | train f1: 0.7466331845238096\n",
      "batch idx 106: | train loss: 0.5585281252861023 | train accu: 0.695 | train roc: 0.902 | train f1: 0.6805888143891017\n",
      "batch idx 107: | train loss: 0.5152469277381897 | train accu: 0.727 | train roc: 0.901 | train f1: 0.7043840985637142\n",
      "batch idx 108: | train loss: 0.49106526374816895 | train accu: 0.742 | train roc: 0.912 | train f1: 0.7220070522261244\n",
      "batch idx 109: | train loss: 0.37982890009880066 | train accu: 0.812 | train roc: 0.940 | train f1: 0.7937163576555024\n",
      "batch idx 110: | train loss: 0.44347625970840454 | train accu: 0.758 | train roc: 0.917 | train f1: 0.7280026455026455\n",
      "batch idx 111: | train loss: 0.5067617297172546 | train accu: 0.727 | train roc: 0.884 | train f1: 0.6997001898429454\n",
      "batch idx 112: | train loss: 0.36698222160339355 | train accu: 0.836 | train roc: 0.931 | train f1: 0.8169331442072779\n",
      "batch idx 113: | train loss: 0.48339301347732544 | train accu: 0.727 | train roc: 0.910 | train f1: 0.715096334586466\n",
      "batch idx 114: | train loss: 0.44631117582321167 | train accu: 0.812 | train roc: 0.927 | train f1: 0.8115112994350282\n",
      "batch idx 115: | train loss: 0.3724658787250519 | train accu: 0.852 | train roc: 0.935 | train f1: 0.8495565546383648\n",
      "batch idx 116: | train loss: 0.551068127155304 | train accu: 0.766 | train roc: 0.890 | train f1: 0.7603307573029212\n",
      "batch idx 117: | train loss: 0.5346428155899048 | train accu: 0.719 | train roc: 0.907 | train f1: 0.7048034222968496\n",
      "batch idx 118: | train loss: 0.5109955072402954 | train accu: 0.719 | train roc: 0.895 | train f1: 0.6978312702922078\n",
      "batch idx 119: | train loss: 0.49963685870170593 | train accu: 0.742 | train roc: 0.892 | train f1: 0.7254514395762643\n",
      "batch idx 120: | train loss: 0.4570849537849426 | train accu: 0.773 | train roc: 0.916 | train f1: 0.754853489903424\n",
      "batch idx 121: | train loss: 0.5022098422050476 | train accu: 0.695 | train roc: 0.910 | train f1: 0.6623195485622768\n",
      "batch idx 122: | train loss: 0.41077718138694763 | train accu: 0.805 | train roc: 0.926 | train f1: 0.7836480750763322\n",
      "batch idx 123: | train loss: 0.4383144974708557 | train accu: 0.750 | train roc: 0.904 | train f1: 0.7146803310673431\n",
      "batch idx 124: | train loss: 0.4825611412525177 | train accu: 0.758 | train roc: 0.899 | train f1: 0.7448369565217391\n",
      "batch idx 125: | train loss: 0.48096397519111633 | train accu: 0.727 | train roc: 0.896 | train f1: 0.704799138316295\n",
      "batch idx 126: | train loss: 0.41255247592926025 | train accu: 0.766 | train roc: 0.938 | train f1: 0.7604924160929432\n",
      "batch idx 127: | train loss: 0.5008249282836914 | train accu: 0.773 | train roc: 0.902 | train f1: 0.7744380530973451\n",
      "batch idx 128: | train loss: 0.49521368741989136 | train accu: 0.758 | train roc: 0.905 | train f1: 0.7560784941996123\n",
      "batch idx 129: | train loss: 0.5032937526702881 | train accu: 0.766 | train roc: 0.884 | train f1: 0.7561946902654867\n",
      "batch idx 130: | train loss: 0.5672683715820312 | train accu: 0.664 | train roc: 0.874 | train f1: 0.6364162432719751\n",
      "batch idx 131: | train loss: 0.4528198540210724 | train accu: 0.805 | train roc: 0.919 | train f1: 0.8037447217134717\n",
      "batch idx 132: | train loss: 0.4536281228065491 | train accu: 0.766 | train roc: 0.921 | train f1: 0.7566247119690448\n",
      "batch idx 133: | train loss: 0.5183683037757874 | train accu: 0.750 | train roc: 0.896 | train f1: 0.7442146711441417\n",
      "batch idx 134: | train loss: 0.4828512370586395 | train accu: 0.750 | train roc: 0.916 | train f1: 0.7510909106937164\n",
      "batch idx 135: | train loss: 0.4504650831222534 | train accu: 0.812 | train roc: 0.923 | train f1: 0.810244877601991\n",
      "batch idx 136: | train loss: 0.4615435302257538 | train accu: 0.773 | train roc: 0.920 | train f1: 0.7701121606600636\n",
      "batch idx 137: | train loss: 0.525300920009613 | train accu: 0.742 | train roc: 0.899 | train f1: 0.7375372023809524\n",
      "batch idx 138: | train loss: 0.4876573085784912 | train accu: 0.734 | train roc: 0.901 | train f1: 0.7238090902542101\n",
      "batch idx 139: | train loss: 0.5062089562416077 | train accu: 0.750 | train roc: 0.907 | train f1: 0.7439393692046494\n",
      "batch idx 140: | train loss: 0.5028680562973022 | train accu: 0.727 | train roc: 0.894 | train f1: 0.7203198877068558\n",
      "batch idx 141: | train loss: 0.4787406325340271 | train accu: 0.766 | train roc: 0.918 | train f1: 0.7458381116207952\n",
      "batch idx 142: | train loss: 0.5976464748382568 | train accu: 0.664 | train roc: 0.865 | train f1: 0.6489433651603957\n",
      "batch idx 143: | train loss: 0.4992188811302185 | train accu: 0.758 | train roc: 0.894 | train f1: 0.7517706141376355\n",
      "batch idx 144: | train loss: 0.5458149909973145 | train accu: 0.688 | train roc: 0.886 | train f1: 0.6809596032446374\n",
      "batch idx 145: | train loss: 0.4564962685108185 | train accu: 0.750 | train roc: 0.918 | train f1: 0.7429154143409188\n",
      "batch idx 146: | train loss: 0.3714929521083832 | train accu: 0.836 | train roc: 0.944 | train f1: 0.834206571310116\n",
      "batch idx 147: | train loss: 0.5044685006141663 | train accu: 0.727 | train roc: 0.903 | train f1: 0.712564182906121\n",
      "batch idx 148: | train loss: 0.469531774520874 | train accu: 0.711 | train roc: 0.917 | train f1: 0.6868102006688963\n",
      "batch idx 149: | train loss: 0.62709641456604 | train accu: 0.688 | train roc: 0.872 | train f1: 0.6768278295669047\n",
      "batch idx 150: | train loss: 0.5156334042549133 | train accu: 0.742 | train roc: 0.892 | train f1: 0.7416419908806389\n",
      "batch idx 151: | train loss: 0.5271035432815552 | train accu: 0.695 | train roc: 0.900 | train f1: 0.6759349120082816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 152: | train loss: 0.5270892977714539 | train accu: 0.750 | train roc: 0.903 | train f1: 0.7305076215127984\n",
      "batch idx 153: | train loss: 0.45883703231811523 | train accu: 0.781 | train roc: 0.905 | train f1: 0.7490851963932805\n",
      "batch idx 154: | train loss: 0.3975779414176941 | train accu: 0.797 | train roc: 0.925 | train f1: 0.7799836601307191\n",
      "batch idx 155: | train loss: 0.48022088408470154 | train accu: 0.727 | train roc: 0.917 | train f1: 0.7133826894423159\n",
      "batch idx 156: | train loss: 0.44628089666366577 | train accu: 0.766 | train roc: 0.929 | train f1: 0.7512516408401102\n",
      "batch idx 157: | train loss: 0.4985222816467285 | train accu: 0.766 | train roc: 0.908 | train f1: 0.7548651183341917\n",
      "batch idx 158: | train loss: 0.5000792741775513 | train accu: 0.711 | train roc: 0.902 | train f1: 0.7060424498746867\n",
      "batch idx 159: | train loss: 0.4544568359851837 | train accu: 0.750 | train roc: 0.919 | train f1: 0.7441307977736549\n",
      "batch idx 160: | train loss: 0.7284483313560486 | train accu: 0.656 | train roc: 0.842 | train f1: 0.6528299418604652\n",
      "batch idx 161: | train loss: 0.4009650647640228 | train accu: 0.789 | train roc: 0.940 | train f1: 0.7873301337359793\n",
      "batch idx 162: | train loss: 0.3849784731864929 | train accu: 0.820 | train roc: 0.918 | train f1: 0.8041880707762558\n",
      "batch idx 163: | train loss: 0.46919551491737366 | train accu: 0.742 | train roc: 0.906 | train f1: 0.7252824576812521\n",
      "batch idx 164: | train loss: 0.46320921182632446 | train accu: 0.727 | train roc: 0.915 | train f1: 0.6946256942636466\n",
      "batch idx 165: | train loss: 0.4763682782649994 | train accu: 0.750 | train roc: 0.908 | train f1: 0.7304028912012644\n",
      "batch idx 166: | train loss: 0.5613867044448853 | train accu: 0.688 | train roc: 0.899 | train f1: 0.6675899244833069\n",
      "batch idx 167: | train loss: 0.49418190121650696 | train accu: 0.758 | train roc: 0.900 | train f1: 0.7461768064784052\n",
      "batch idx 168: | train loss: 0.5476285219192505 | train accu: 0.703 | train roc: 0.897 | train f1: 0.696720253254103\n",
      "batch idx 169: | train loss: 0.4459597170352936 | train accu: 0.766 | train roc: 0.923 | train f1: 0.7617372332125241\n",
      "batch idx 170: | train loss: 0.5290156006813049 | train accu: 0.734 | train roc: 0.898 | train f1: 0.7286098819024196\n",
      "batch idx 171: | train loss: 0.47786620259284973 | train accu: 0.773 | train roc: 0.931 | train f1: 0.766444326747507\n",
      "batch idx 172: | train loss: 0.47392529249191284 | train accu: 0.781 | train roc: 0.913 | train f1: 0.7732513836528436\n",
      "batch idx 173: | train loss: 0.4600277841091156 | train accu: 0.781 | train roc: 0.911 | train f1: 0.771164334315376\n",
      "batch idx 174: | train loss: 0.45134437084198 | train accu: 0.789 | train roc: 0.917 | train f1: 0.7718831333140543\n",
      "batch idx 175: | train loss: 0.5240638256072998 | train accu: 0.703 | train roc: 0.911 | train f1: 0.6783702213279678\n",
      "batch idx 176: | train loss: 0.387504518032074 | train accu: 0.797 | train roc: 0.929 | train f1: 0.7776692708333333\n",
      "batch idx 177: | train loss: 0.565116286277771 | train accu: 0.711 | train roc: 0.888 | train f1: 0.7031713811768815\n",
      "batch idx 178: | train loss: 0.5222563743591309 | train accu: 0.766 | train roc: 0.881 | train f1: 0.7591508438818566\n",
      "batch idx 179: | train loss: 0.39729246497154236 | train accu: 0.836 | train roc: 0.943 | train f1: 0.8349700354424191\n",
      "batch idx 180: | train loss: 0.36491015553474426 | train accu: 0.836 | train roc: 0.940 | train f1: 0.8308531746031746\n",
      "batch idx 181: | train loss: 0.506829023361206 | train accu: 0.766 | train roc: 0.905 | train f1: 0.7589473992502344\n",
      "batch idx 182: | train loss: 0.46973076462745667 | train accu: 0.766 | train roc: 0.918 | train f1: 0.7614765535523209\n",
      "batch idx 183: | train loss: 0.4316401183605194 | train accu: 0.773 | train roc: 0.931 | train f1: 0.76908964726934\n",
      "batch idx 184: | train loss: 0.527010977268219 | train accu: 0.711 | train roc: 0.895 | train f1: 0.6995847902097903\n",
      "batch idx 185: | train loss: 0.47000277042388916 | train accu: 0.758 | train roc: 0.894 | train f1: 0.7319524636547663\n",
      "batch idx 186: | train loss: 0.4903133511543274 | train accu: 0.742 | train roc: 0.900 | train f1: 0.7191197073474471\n",
      "batch idx 187: | train loss: 0.5061599612236023 | train accu: 0.766 | train roc: 0.897 | train f1: 0.7629415760869566\n",
      "batch idx 188: | train loss: 0.4795786440372467 | train accu: 0.797 | train roc: 0.883 | train f1: 0.778987693050193\n",
      "batch idx 189: | train loss: 0.477088063955307 | train accu: 0.742 | train roc: 0.903 | train f1: 0.7247439490254272\n",
      "batch idx 190: | train loss: 0.4510433077812195 | train accu: 0.773 | train roc: 0.916 | train f1: 0.7663970508337286\n",
      "batch idx 191: | train loss: 0.41400009393692017 | train accu: 0.797 | train roc: 0.927 | train f1: 0.7842271017408802\n",
      "batch idx 192: | train loss: 0.5332516431808472 | train accu: 0.719 | train roc: 0.912 | train f1: 0.7143356643356642\n",
      "batch idx 193: | train loss: 0.45713159441947937 | train accu: 0.781 | train roc: 0.912 | train f1: 0.7740139163372859\n",
      "batch idx 194: | train loss: 0.46220114827156067 | train accu: 0.781 | train roc: 0.929 | train f1: 0.7808313887593441\n",
      "batch idx 195: | train loss: 0.3478682041168213 | train accu: 0.844 | train roc: 0.949 | train f1: 0.8318917410714286\n",
      "batch idx 196: | train loss: 0.5138512849807739 | train accu: 0.781 | train roc: 0.893 | train f1: 0.7788825757575758\n",
      "batch idx 197: | train loss: 0.5202092528343201 | train accu: 0.688 | train roc: 0.883 | train f1: 0.6545761670761671\n",
      "batch idx 198: | train loss: 0.41873347759246826 | train accu: 0.797 | train roc: 0.920 | train f1: 0.7784049506718156\n",
      "batch idx 199: | train loss: 0.4120350778102875 | train accu: 0.805 | train roc: 0.935 | train f1: 0.7967672564558682\n",
      "batch idx 200: | train loss: 0.49329429864883423 | train accu: 0.758 | train roc: 0.911 | train f1: 0.7426853516202108\n",
      "batch idx 201: | train loss: 0.49389880895614624 | train accu: 0.734 | train roc: 0.901 | train f1: 0.7298607183257919\n",
      "batch idx 202: | train loss: 0.48152676224708557 | train accu: 0.773 | train roc: 0.902 | train f1: 0.7691964285714286\n",
      "batch idx 203: | train loss: 0.6192708015441895 | train accu: 0.734 | train roc: 0.868 | train f1: 0.7335405540720961\n",
      "batch idx 204: | train loss: 0.4940289258956909 | train accu: 0.742 | train roc: 0.885 | train f1: 0.7298255174120016\n",
      "batch idx 205: | train loss: 0.4819967448711395 | train accu: 0.750 | train roc: 0.913 | train f1: 0.7388206845238096\n",
      "batch idx 206: | train loss: 0.4618619978427887 | train accu: 0.781 | train roc: 0.922 | train f1: 0.7761302761042127\n",
      "batch idx 207: | train loss: 0.4693995416164398 | train accu: 0.727 | train roc: 0.896 | train f1: 0.7046027131782946\n",
      "batch idx 208: | train loss: 0.4188247323036194 | train accu: 0.766 | train roc: 0.920 | train f1: 0.7542989417989419\n",
      "batch idx 209: | train loss: 0.567809522151947 | train accu: 0.711 | train roc: 0.850 | train f1: 0.66609477124183\n",
      "batch idx 210: | train loss: 0.5269957184791565 | train accu: 0.695 | train roc: 0.929 | train f1: 0.6674817063200065\n",
      "batch idx 211: | train loss: 0.5400180816650391 | train accu: 0.719 | train roc: 0.877 | train f1: 0.6875\n",
      "batch idx 212: | train loss: 0.5299453735351562 | train accu: 0.695 | train roc: 0.890 | train f1: 0.6680167892452374\n",
      "batch idx 213: | train loss: 0.5579768419265747 | train accu: 0.703 | train roc: 0.890 | train f1: 0.6838857014580026\n",
      "batch idx 214: | train loss: 0.47109106183052063 | train accu: 0.750 | train roc: 0.915 | train f1: 0.7472747093023255\n",
      "batch idx 215: | train loss: 0.4722685217857361 | train accu: 0.742 | train roc: 0.920 | train f1: 0.7420939036381514\n",
      "batch idx 216: | train loss: 0.4990271329879761 | train accu: 0.758 | train roc: 0.898 | train f1: 0.7554371796862867\n",
      "batch idx 217: | train loss: 0.5428529381752014 | train accu: 0.719 | train roc: 0.885 | train f1: 0.7130343614718615\n",
      "batch idx 218: | train loss: 0.5007777810096741 | train accu: 0.789 | train roc: 0.903 | train f1: 0.7858656602070772\n",
      "batch idx 219: | train loss: 0.5041925311088562 | train accu: 0.781 | train roc: 0.847 | train f1: 0.7712558049535604\n",
      "batch idx 220: | train loss: 0.46133601665496826 | train accu: 0.727 | train roc: 0.931 | train f1: 0.709728126825469\n",
      "batch idx 221: | train loss: 0.5280817747116089 | train accu: 0.773 | train roc: 0.857 | train f1: 0.7521891429803665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 222: | train loss: 0.3828570246696472 | train accu: 0.781 | train roc: 0.934 | train f1: 0.7565518465909091\n",
      "batch idx 223: | train loss: 0.5068293213844299 | train accu: 0.750 | train roc: 0.900 | train f1: 0.7428868898883891\n",
      "batch idx 224: | train loss: 0.38458847999572754 | train accu: 0.812 | train roc: 0.927 | train f1: 0.7978414035946029\n",
      "batch idx 225: | train loss: 0.5654535293579102 | train accu: 0.703 | train roc: 0.871 | train f1: 0.6783869864179047\n",
      "batch idx 226: | train loss: 0.465587854385376 | train accu: 0.727 | train roc: 0.907 | train f1: 0.6921337841969382\n",
      "batch idx 227: | train loss: 0.4516223073005676 | train accu: 0.773 | train roc: 0.926 | train f1: 0.7700430052403735\n",
      "batch idx 228: | train loss: 0.5901066660881042 | train accu: 0.719 | train roc: 0.858 | train f1: 0.7056899641577061\n",
      "batch idx 229: | train loss: 0.45934247970581055 | train accu: 0.805 | train roc: 0.918 | train f1: 0.8026514938521517\n",
      "batch idx 230: | train loss: 0.45462626218795776 | train accu: 0.789 | train roc: 0.929 | train f1: 0.7862929894179895\n",
      "batch idx 231: | train loss: 0.4459186792373657 | train accu: 0.773 | train roc: 0.910 | train f1: 0.7595159151193633\n",
      "batch idx 232: | train loss: 0.5177215337753296 | train accu: 0.703 | train roc: 0.902 | train f1: 0.6845822839894818\n",
      "batch idx 233: | train loss: 0.4258500039577484 | train accu: 0.750 | train roc: 0.938 | train f1: 0.7350339400091788\n",
      "batch idx 234: | train loss: 0.4808591604232788 | train accu: 0.758 | train roc: 0.904 | train f1: 0.7484957750582751\n",
      "batch idx 235: | train loss: 0.4570077657699585 | train accu: 0.766 | train roc: 0.921 | train f1: 0.7568415706488781\n",
      "batch idx 236: | train loss: 0.518668532371521 | train accu: 0.781 | train roc: 0.889 | train f1: 0.7798446723730814\n",
      "batch idx 237: | train loss: 0.46909621357917786 | train accu: 0.773 | train roc: 0.914 | train f1: 0.7699718831747329\n",
      "batch idx 238: | train loss: 0.5488995909690857 | train accu: 0.734 | train roc: 0.888 | train f1: 0.7317997652549064\n",
      "batch idx 239: | train loss: 0.5649256110191345 | train accu: 0.711 | train roc: 0.874 | train f1: 0.6964812595761628\n",
      "batch idx 240: | train loss: 0.390895813703537 | train accu: 0.805 | train roc: 0.946 | train f1: 0.7948760679584543\n",
      "Epoch: 05 | Epoch Time: 2m 13s\n",
      "\tTrain Loss: 0.482 | Train Acc: 75.55 | Train rocauc: 0.9094094218183975 | Train f1: 0.7434225597345724%\n",
      "\t Val. Loss: 0.633 |  Val. Acc: 68.25 | Val. rocauc: 0.8509433375463604 | Val. f1: 0.6692724570749471%\n",
      "batch idx 0: | train loss: 0.5280479788780212 | train accu: 0.734 | train roc: 0.907 | train f1: 0.724297130135946\n",
      "batch idx 1: | train loss: 0.3988034725189209 | train accu: 0.766 | train roc: 0.948 | train f1: 0.7605624079528719\n",
      "batch idx 2: | train loss: 0.4048694670200348 | train accu: 0.789 | train roc: 0.938 | train f1: 0.7850417811355311\n",
      "batch idx 3: | train loss: 0.5130955576896667 | train accu: 0.727 | train roc: 0.895 | train f1: 0.7197165194481212\n",
      "batch idx 4: | train loss: 0.3508200943470001 | train accu: 0.828 | train roc: 0.945 | train f1: 0.8186995620894588\n",
      "batch idx 5: | train loss: 0.3839450180530548 | train accu: 0.859 | train roc: 0.944 | train f1: 0.8591272438974717\n",
      "batch idx 6: | train loss: 0.37558379769325256 | train accu: 0.797 | train roc: 0.955 | train f1: 0.7898380098215625\n",
      "batch idx 7: | train loss: 0.4000712037086487 | train accu: 0.789 | train roc: 0.952 | train f1: 0.7803056027164685\n",
      "batch idx 8: | train loss: 0.4686538875102997 | train accu: 0.734 | train roc: 0.931 | train f1: 0.6960166408096927\n",
      "batch idx 9: | train loss: 0.48586317896842957 | train accu: 0.758 | train roc: 0.898 | train f1: 0.749324069416499\n",
      "batch idx 10: | train loss: 0.45539259910583496 | train accu: 0.812 | train roc: 0.931 | train f1: 0.8103596461949265\n",
      "batch idx 11: | train loss: 0.49940231442451477 | train accu: 0.766 | train roc: 0.914 | train f1: 0.7619331983805668\n",
      "batch idx 12: | train loss: 0.45137548446655273 | train accu: 0.758 | train roc: 0.921 | train f1: 0.7503664759822848\n",
      "batch idx 13: | train loss: 0.5069699287414551 | train accu: 0.727 | train roc: 0.899 | train f1: 0.7251025883838385\n",
      "batch idx 14: | train loss: 0.45881927013397217 | train accu: 0.750 | train roc: 0.923 | train f1: 0.7438882303399326\n",
      "batch idx 15: | train loss: 0.4083939492702484 | train accu: 0.789 | train roc: 0.936 | train f1: 0.7778191695044547\n",
      "batch idx 16: | train loss: 0.45837461948394775 | train accu: 0.812 | train roc: 0.915 | train f1: 0.808007538569425\n",
      "batch idx 17: | train loss: 0.408654123544693 | train accu: 0.805 | train roc: 0.938 | train f1: 0.8022434364370747\n",
      "batch idx 18: | train loss: 0.4137120544910431 | train accu: 0.734 | train roc: 0.944 | train f1: 0.7184452746152225\n",
      "batch idx 19: | train loss: 0.3901519477367401 | train accu: 0.789 | train roc: 0.947 | train f1: 0.7796093001676245\n",
      "batch idx 20: | train loss: 0.3734385073184967 | train accu: 0.789 | train roc: 0.948 | train f1: 0.7741857405849281\n",
      "batch idx 21: | train loss: 0.3750458359718323 | train accu: 0.797 | train roc: 0.942 | train f1: 0.7896421933896411\n",
      "batch idx 22: | train loss: 0.39562278985977173 | train accu: 0.773 | train roc: 0.935 | train f1: 0.7702958545622973\n",
      "batch idx 23: | train loss: 0.38771143555641174 | train accu: 0.797 | train roc: 0.946 | train f1: 0.7916930393952453\n",
      "batch idx 24: | train loss: 0.4117269515991211 | train accu: 0.766 | train roc: 0.928 | train f1: 0.7629160119794578\n",
      "batch idx 25: | train loss: 0.5107389688491821 | train accu: 0.781 | train roc: 0.908 | train f1: 0.779429154110746\n",
      "batch idx 26: | train loss: 0.5347844362258911 | train accu: 0.781 | train roc: 0.901 | train f1: 0.778373015873016\n",
      "batch idx 27: | train loss: 0.3025858700275421 | train accu: 0.836 | train roc: 0.962 | train f1: 0.8324049888990466\n",
      "batch idx 28: | train loss: 0.5646206140518188 | train accu: 0.727 | train roc: 0.871 | train f1: 0.7071898889154324\n",
      "batch idx 29: | train loss: 0.36264777183532715 | train accu: 0.805 | train roc: 0.934 | train f1: 0.7907804168964884\n",
      "batch idx 30: | train loss: 0.3896443247795105 | train accu: 0.820 | train roc: 0.940 | train f1: 0.8168088457661291\n",
      "batch idx 31: | train loss: 0.3831193447113037 | train accu: 0.805 | train roc: 0.930 | train f1: 0.8020872249896223\n",
      "batch idx 32: | train loss: 0.47356802225112915 | train accu: 0.766 | train roc: 0.901 | train f1: 0.765533862053301\n",
      "batch idx 33: | train loss: 0.4989103078842163 | train accu: 0.758 | train roc: 0.909 | train f1: 0.7550917517856708\n",
      "batch idx 34: | train loss: 0.4243563115596771 | train accu: 0.766 | train roc: 0.929 | train f1: 0.7539415479342664\n",
      "batch idx 35: | train loss: 0.4304939806461334 | train accu: 0.805 | train roc: 0.938 | train f1: 0.7993303571428572\n",
      "batch idx 36: | train loss: 0.5158272385597229 | train accu: 0.719 | train roc: 0.915 | train f1: 0.7079592203782863\n",
      "batch idx 37: | train loss: 0.42439621686935425 | train accu: 0.789 | train roc: 0.925 | train f1: 0.7769403127383678\n",
      "batch idx 38: | train loss: 0.5817287564277649 | train accu: 0.703 | train roc: 0.880 | train f1: 0.6883291273200913\n",
      "batch idx 39: | train loss: 0.5258212685585022 | train accu: 0.719 | train roc: 0.891 | train f1: 0.7114050434362934\n",
      "batch idx 40: | train loss: 0.46340930461883545 | train accu: 0.766 | train roc: 0.923 | train f1: 0.7588969648024766\n",
      "batch idx 41: | train loss: 0.37915316224098206 | train accu: 0.852 | train roc: 0.954 | train f1: 0.8517556662087913\n",
      "batch idx 42: | train loss: 0.47818201780319214 | train accu: 0.773 | train roc: 0.917 | train f1: 0.7674395161290323\n",
      "batch idx 43: | train loss: 0.36262205243110657 | train accu: 0.844 | train roc: 0.933 | train f1: 0.8400062656641604\n",
      "batch idx 44: | train loss: 0.35274866223335266 | train accu: 0.805 | train roc: 0.940 | train f1: 0.7897047305764411\n",
      "batch idx 45: | train loss: 0.4050307273864746 | train accu: 0.812 | train roc: 0.914 | train f1: 0.7992687092986015\n",
      "batch idx 46: | train loss: 0.5217282772064209 | train accu: 0.734 | train roc: 0.899 | train f1: 0.7204200183179357\n",
      "batch idx 47: | train loss: 0.4051823318004608 | train accu: 0.758 | train roc: 0.949 | train f1: 0.7325595238095237\n",
      "batch idx 48: | train loss: 0.5167657136917114 | train accu: 0.711 | train roc: 0.888 | train f1: 0.6843487394957983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 49: | train loss: 0.5526480674743652 | train accu: 0.750 | train roc: 0.884 | train f1: 0.7411855376325516\n",
      "batch idx 50: | train loss: 0.514997661113739 | train accu: 0.789 | train roc: 0.890 | train f1: 0.7872556987900914\n",
      "batch idx 51: | train loss: 0.5215384364128113 | train accu: 0.781 | train roc: 0.914 | train f1: 0.7842671251348436\n",
      "batch idx 52: | train loss: 0.378592312335968 | train accu: 0.852 | train roc: 0.944 | train f1: 0.851278913486669\n",
      "batch idx 53: | train loss: 0.5211778283119202 | train accu: 0.781 | train roc: 0.901 | train f1: 0.7790276759530792\n",
      "batch idx 54: | train loss: 0.4427436888217926 | train accu: 0.758 | train roc: 0.932 | train f1: 0.7573418090062112\n",
      "batch idx 55: | train loss: 0.44135236740112305 | train accu: 0.773 | train roc: 0.941 | train f1: 0.7637286389897857\n",
      "batch idx 56: | train loss: 0.4947296977043152 | train accu: 0.750 | train roc: 0.903 | train f1: 0.74046875\n",
      "batch idx 57: | train loss: 0.423003613948822 | train accu: 0.773 | train roc: 0.921 | train f1: 0.7676882869799442\n",
      "batch idx 58: | train loss: 0.3623272180557251 | train accu: 0.805 | train roc: 0.956 | train f1: 0.8000494671463481\n",
      "batch idx 59: | train loss: 0.4246485233306885 | train accu: 0.773 | train roc: 0.921 | train f1: 0.7667586331460856\n",
      "batch idx 60: | train loss: 0.48778480291366577 | train accu: 0.750 | train roc: 0.915 | train f1: 0.746382799428805\n",
      "batch idx 61: | train loss: 0.4392353296279907 | train accu: 0.812 | train roc: 0.926 | train f1: 0.8131725886635743\n",
      "batch idx 62: | train loss: 0.3116413652896881 | train accu: 0.859 | train roc: 0.958 | train f1: 0.8507887687774527\n",
      "batch idx 63: | train loss: 0.4366876184940338 | train accu: 0.766 | train roc: 0.927 | train f1: 0.7551354895104895\n",
      "batch idx 64: | train loss: 0.39419886469841003 | train accu: 0.836 | train roc: 0.948 | train f1: 0.8355848696757788\n",
      "batch idx 65: | train loss: 0.46794670820236206 | train accu: 0.758 | train roc: 0.920 | train f1: 0.7440049724157956\n",
      "batch idx 66: | train loss: 0.3744013011455536 | train accu: 0.812 | train roc: 0.941 | train f1: 0.8074479817660466\n",
      "batch idx 67: | train loss: 0.46713975071907043 | train accu: 0.812 | train roc: 0.918 | train f1: 0.8085144599998921\n",
      "batch idx 68: | train loss: 0.5784317255020142 | train accu: 0.727 | train roc: 0.903 | train f1: 0.7258765389906661\n",
      "batch idx 69: | train loss: 0.5154544711112976 | train accu: 0.750 | train roc: 0.898 | train f1: 0.7497919660672716\n",
      "batch idx 70: | train loss: 0.37725889682769775 | train accu: 0.742 | train roc: 0.930 | train f1: 0.7155998490945674\n",
      "batch idx 71: | train loss: 0.48872804641723633 | train accu: 0.758 | train roc: 0.908 | train f1: 0.7462121212121212\n",
      "batch idx 72: | train loss: 0.5527253150939941 | train accu: 0.742 | train roc: 0.890 | train f1: 0.7269598155467721\n",
      "batch idx 73: | train loss: 0.38079211115837097 | train accu: 0.781 | train roc: 0.936 | train f1: 0.7531877386600324\n",
      "batch idx 74: | train loss: 0.34282806515693665 | train accu: 0.812 | train roc: 0.933 | train f1: 0.7994256213123547\n",
      "batch idx 75: | train loss: 0.39602530002593994 | train accu: 0.781 | train roc: 0.943 | train f1: 0.7666749498531413\n",
      "batch idx 76: | train loss: 0.4662288725376129 | train accu: 0.773 | train roc: 0.904 | train f1: 0.7546233579638753\n",
      "batch idx 77: | train loss: 0.5379684567451477 | train accu: 0.750 | train roc: 0.878 | train f1: 0.7397954374057314\n",
      "batch idx 78: | train loss: 0.4015146493911743 | train accu: 0.773 | train roc: 0.927 | train f1: 0.7648909012290244\n",
      "batch idx 79: | train loss: 0.35143426060676575 | train accu: 0.820 | train roc: 0.948 | train f1: 0.8098909201784534\n",
      "batch idx 80: | train loss: 0.33615896105766296 | train accu: 0.852 | train roc: 0.965 | train f1: 0.8494083180147058\n",
      "batch idx 81: | train loss: 0.4678301215171814 | train accu: 0.781 | train roc: 0.914 | train f1: 0.7756320962994113\n",
      "batch idx 82: | train loss: 0.4014463722705841 | train accu: 0.812 | train roc: 0.919 | train f1: 0.8000526807438304\n",
      "batch idx 83: | train loss: 0.41431567072868347 | train accu: 0.789 | train roc: 0.931 | train f1: 0.761045104823022\n",
      "batch idx 84: | train loss: 0.3837856650352478 | train accu: 0.773 | train roc: 0.938 | train f1: 0.7547449521023346\n",
      "batch idx 85: | train loss: 0.38269391655921936 | train accu: 0.789 | train roc: 0.938 | train f1: 0.7831538979192632\n",
      "batch idx 86: | train loss: 0.5357743501663208 | train accu: 0.766 | train roc: 0.887 | train f1: 0.7496675252312869\n",
      "batch idx 87: | train loss: 0.38186317682266235 | train accu: 0.812 | train roc: 0.933 | train f1: 0.7959899561573633\n",
      "batch idx 88: | train loss: 0.4597392976284027 | train accu: 0.727 | train roc: 0.925 | train f1: 0.6971447470348026\n",
      "batch idx 89: | train loss: 0.45020994544029236 | train accu: 0.781 | train roc: 0.909 | train f1: 0.7728228519668737\n",
      "batch idx 90: | train loss: 0.48940229415893555 | train accu: 0.742 | train roc: 0.889 | train f1: 0.7265049611292963\n",
      "batch idx 91: | train loss: 0.5101057291030884 | train accu: 0.734 | train roc: 0.912 | train f1: 0.7255416993977482\n",
      "batch idx 92: | train loss: 0.4037863612174988 | train accu: 0.820 | train roc: 0.942 | train f1: 0.8198166052169957\n",
      "batch idx 93: | train loss: 0.4926542341709137 | train accu: 0.773 | train roc: 0.907 | train f1: 0.7686626849557265\n",
      "batch idx 94: | train loss: 0.4248684048652649 | train accu: 0.805 | train roc: 0.922 | train f1: 0.8002733451536643\n",
      "batch idx 95: | train loss: 0.5145821571350098 | train accu: 0.734 | train roc: 0.916 | train f1: 0.7310948924353207\n",
      "batch idx 96: | train loss: 0.454550564289093 | train accu: 0.750 | train roc: 0.921 | train f1: 0.7361517826607389\n",
      "batch idx 97: | train loss: 0.38929909467697144 | train accu: 0.797 | train roc: 0.934 | train f1: 0.7870853365384616\n",
      "batch idx 98: | train loss: 0.4619957506656647 | train accu: 0.758 | train roc: 0.931 | train f1: 0.7445625975965782\n",
      "batch idx 99: | train loss: 0.40618979930877686 | train accu: 0.789 | train roc: 0.934 | train f1: 0.7698863636363638\n",
      "batch idx 100: | train loss: 0.46328702569007874 | train accu: 0.773 | train roc: 0.910 | train f1: 0.7600707526216247\n",
      "batch idx 101: | train loss: 0.40937986969947815 | train accu: 0.812 | train roc: 0.898 | train f1: 0.7943186649659864\n",
      "batch idx 102: | train loss: 0.4218710660934448 | train accu: 0.766 | train roc: 0.924 | train f1: 0.7619866964827168\n",
      "batch idx 103: | train loss: 0.4674661457538605 | train accu: 0.750 | train roc: 0.924 | train f1: 0.7426002358490567\n",
      "batch idx 104: | train loss: 0.49761226773262024 | train accu: 0.781 | train roc: 0.918 | train f1: 0.7789347422521216\n",
      "batch idx 105: | train loss: 0.3860182464122772 | train accu: 0.805 | train roc: 0.937 | train f1: 0.796396841794569\n",
      "batch idx 106: | train loss: 0.4354645907878876 | train accu: 0.758 | train roc: 0.920 | train f1: 0.7448270017466446\n",
      "batch idx 107: | train loss: 0.4104195535182953 | train accu: 0.781 | train roc: 0.936 | train f1: 0.7768110795454545\n",
      "batch idx 108: | train loss: 0.4001532196998596 | train accu: 0.828 | train roc: 0.945 | train f1: 0.8232547752621386\n",
      "batch idx 109: | train loss: 0.38519179821014404 | train accu: 0.766 | train roc: 0.931 | train f1: 0.7530458351223701\n",
      "batch idx 110: | train loss: 0.4387887418270111 | train accu: 0.742 | train roc: 0.902 | train f1: 0.7272143385352917\n",
      "batch idx 111: | train loss: 0.5915259122848511 | train accu: 0.680 | train roc: 0.868 | train f1: 0.6543996710526315\n",
      "batch idx 112: | train loss: 0.38843265175819397 | train accu: 0.812 | train roc: 0.941 | train f1: 0.7966469515065913\n",
      "batch idx 113: | train loss: 0.42279133200645447 | train accu: 0.758 | train roc: 0.931 | train f1: 0.7333484169261357\n",
      "batch idx 114: | train loss: 0.5201116800308228 | train accu: 0.719 | train roc: 0.907 | train f1: 0.6965060763888888\n",
      "batch idx 115: | train loss: 0.42527905106544495 | train accu: 0.766 | train roc: 0.933 | train f1: 0.751541806336061\n",
      "batch idx 116: | train loss: 0.5230706930160522 | train accu: 0.695 | train roc: 0.919 | train f1: 0.6815452876238431\n",
      "batch idx 117: | train loss: 0.43037378787994385 | train accu: 0.844 | train roc: 0.921 | train f1: 0.8421296985639601\n",
      "batch idx 118: | train loss: 0.4405279755592346 | train accu: 0.805 | train roc: 0.914 | train f1: 0.803869766505636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 119: | train loss: 0.4155066907405853 | train accu: 0.789 | train roc: 0.942 | train f1: 0.7864774816176471\n",
      "batch idx 120: | train loss: 0.5265995860099792 | train accu: 0.727 | train roc: 0.863 | train f1: 0.7082142857142857\n",
      "batch idx 121: | train loss: 0.3831344246864319 | train accu: 0.805 | train roc: 0.934 | train f1: 0.7958469105758126\n",
      "batch idx 122: | train loss: 0.41346174478530884 | train accu: 0.812 | train roc: 0.927 | train f1: 0.8019551282051283\n",
      "batch idx 123: | train loss: 0.5179879069328308 | train accu: 0.758 | train roc: 0.906 | train f1: 0.7438032710544141\n",
      "batch idx 124: | train loss: 0.4221670925617218 | train accu: 0.766 | train roc: 0.920 | train f1: 0.7335539253000432\n",
      "batch idx 125: | train loss: 0.4542403519153595 | train accu: 0.781 | train roc: 0.923 | train f1: 0.770686544991511\n",
      "batch idx 126: | train loss: 0.347992867231369 | train accu: 0.844 | train roc: 0.948 | train f1: 0.8409844509179251\n",
      "batch idx 127: | train loss: 0.44514548778533936 | train accu: 0.805 | train roc: 0.908 | train f1: 0.7990813078703705\n",
      "batch idx 128: | train loss: 0.4336162209510803 | train accu: 0.812 | train roc: 0.934 | train f1: 0.8096475583827832\n",
      "batch idx 129: | train loss: 0.3978504240512848 | train accu: 0.766 | train roc: 0.930 | train f1: 0.7563873851706037\n",
      "batch idx 130: | train loss: 0.5100794434547424 | train accu: 0.781 | train roc: 0.907 | train f1: 0.7793642656500802\n",
      "batch idx 131: | train loss: 0.38861921429634094 | train accu: 0.805 | train roc: 0.945 | train f1: 0.8059514360244879\n",
      "batch idx 132: | train loss: 0.42389899492263794 | train accu: 0.828 | train roc: 0.935 | train f1: 0.8282534431877862\n",
      "batch idx 133: | train loss: 0.43831196427345276 | train accu: 0.875 | train roc: 0.919 | train f1: 0.8749878885357725\n",
      "batch idx 134: | train loss: 0.49924585223197937 | train accu: 0.742 | train roc: 0.909 | train f1: 0.7284613113094347\n",
      "batch idx 135: | train loss: 0.47043487429618835 | train accu: 0.742 | train roc: 0.911 | train f1: 0.7171186542145593\n",
      "batch idx 136: | train loss: 0.46960756182670593 | train accu: 0.750 | train roc: 0.912 | train f1: 0.7337313941308199\n",
      "batch idx 137: | train loss: 0.5218143463134766 | train accu: 0.734 | train roc: 0.862 | train f1: 0.7259922395556859\n",
      "batch idx 138: | train loss: 0.46802616119384766 | train accu: 0.758 | train roc: 0.908 | train f1: 0.7276182128730673\n",
      "batch idx 139: | train loss: 0.4008651077747345 | train accu: 0.820 | train roc: 0.953 | train f1: 0.8098619825182325\n",
      "batch idx 140: | train loss: 0.547900378704071 | train accu: 0.719 | train roc: 0.889 | train f1: 0.6891234005201778\n",
      "batch idx 141: | train loss: 0.45730358362197876 | train accu: 0.758 | train roc: 0.911 | train f1: 0.742212424672102\n",
      "batch idx 142: | train loss: 0.45078277587890625 | train accu: 0.766 | train roc: 0.911 | train f1: 0.7579802578767811\n",
      "batch idx 143: | train loss: 0.4293622374534607 | train accu: 0.812 | train roc: 0.934 | train f1: 0.8079029404330609\n",
      "batch idx 144: | train loss: 0.4568926692008972 | train accu: 0.766 | train roc: 0.923 | train f1: 0.7624280816519546\n",
      "batch idx 145: | train loss: 0.4492315351963043 | train accu: 0.781 | train roc: 0.928 | train f1: 0.7760541583075986\n",
      "batch idx 146: | train loss: 0.49919047951698303 | train accu: 0.727 | train roc: 0.906 | train f1: 0.7176732772435896\n",
      "batch idx 147: | train loss: 0.3837720453739166 | train accu: 0.805 | train roc: 0.944 | train f1: 0.8008321107647167\n",
      "batch idx 148: | train loss: 0.4356001913547516 | train accu: 0.789 | train roc: 0.924 | train f1: 0.7816014131234815\n",
      "batch idx 149: | train loss: 0.4507277011871338 | train accu: 0.758 | train roc: 0.919 | train f1: 0.7501621319980696\n",
      "batch idx 150: | train loss: 0.4719173312187195 | train accu: 0.766 | train roc: 0.916 | train f1: 0.752854938271605\n",
      "batch idx 151: | train loss: 0.45067301392555237 | train accu: 0.758 | train roc: 0.901 | train f1: 0.7316203987208274\n",
      "batch idx 152: | train loss: 0.5623071193695068 | train accu: 0.711 | train roc: 0.874 | train f1: 0.6917107345852219\n",
      "batch idx 153: | train loss: 0.49260613322257996 | train accu: 0.711 | train roc: 0.910 | train f1: 0.669229797979798\n",
      "batch idx 154: | train loss: 0.5034586787223816 | train accu: 0.688 | train roc: 0.909 | train f1: 0.6438442887931035\n",
      "batch idx 155: | train loss: 0.49966758489608765 | train accu: 0.711 | train roc: 0.890 | train f1: 0.6833011183733151\n",
      "batch idx 156: | train loss: 0.46316152811050415 | train accu: 0.766 | train roc: 0.921 | train f1: 0.7607358047385621\n",
      "batch idx 157: | train loss: 0.4095216393470764 | train accu: 0.812 | train roc: 0.942 | train f1: 0.8086511985836329\n",
      "batch idx 158: | train loss: 0.4891684055328369 | train accu: 0.773 | train roc: 0.911 | train f1: 0.7725737476808905\n",
      "batch idx 159: | train loss: 0.45461660623550415 | train accu: 0.758 | train roc: 0.914 | train f1: 0.7553843470982143\n",
      "batch idx 160: | train loss: 0.38087671995162964 | train accu: 0.773 | train roc: 0.935 | train f1: 0.7623794053315809\n",
      "batch idx 161: | train loss: 0.366874635219574 | train accu: 0.828 | train roc: 0.950 | train f1: 0.8228516721781993\n",
      "batch idx 162: | train loss: 0.44866058230400085 | train accu: 0.742 | train roc: 0.906 | train f1: 0.7161473184145151\n",
      "batch idx 163: | train loss: 0.4973517060279846 | train accu: 0.742 | train roc: 0.899 | train f1: 0.7152959887334887\n",
      "batch idx 164: | train loss: 0.677932620048523 | train accu: 0.609 | train roc: 0.865 | train f1: 0.5693273460410557\n",
      "batch idx 165: | train loss: 0.3705584406852722 | train accu: 0.789 | train roc: 0.922 | train f1: 0.747732843137255\n",
      "batch idx 166: | train loss: 0.4161498248577118 | train accu: 0.781 | train roc: 0.920 | train f1: 0.7561652131782945\n",
      "batch idx 167: | train loss: 0.5272424817085266 | train accu: 0.695 | train roc: 0.891 | train f1: 0.6781932653654924\n",
      "batch idx 168: | train loss: 0.5261887311935425 | train accu: 0.734 | train roc: 0.882 | train f1: 0.7220306794470528\n",
      "batch idx 169: | train loss: 0.46377265453338623 | train accu: 0.789 | train roc: 0.927 | train f1: 0.788753005650083\n",
      "batch idx 170: | train loss: 0.4637206792831421 | train accu: 0.773 | train roc: 0.919 | train f1: 0.76960193046463\n",
      "batch idx 171: | train loss: 0.4435388743877411 | train accu: 0.797 | train roc: 0.900 | train f1: 0.7917169037858691\n",
      "batch idx 172: | train loss: 0.37734249234199524 | train accu: 0.797 | train roc: 0.934 | train f1: 0.7903624380483558\n",
      "batch idx 173: | train loss: 0.44199204444885254 | train accu: 0.750 | train roc: 0.912 | train f1: 0.7198988970588236\n",
      "batch idx 174: | train loss: 0.540066123008728 | train accu: 0.742 | train roc: 0.888 | train f1: 0.722234410673516\n",
      "batch idx 175: | train loss: 0.45187297463417053 | train accu: 0.789 | train roc: 0.930 | train f1: 0.7791531385281385\n",
      "batch idx 176: | train loss: 0.42134344577789307 | train accu: 0.812 | train roc: 0.920 | train f1: 0.7952353475349048\n",
      "batch idx 177: | train loss: 0.5164491534233093 | train accu: 0.734 | train roc: 0.874 | train f1: 0.7133666907817819\n",
      "batch idx 178: | train loss: 0.39095041155815125 | train accu: 0.766 | train roc: 0.942 | train f1: 0.7554281717884659\n",
      "batch idx 179: | train loss: 0.4675903618335724 | train accu: 0.781 | train roc: 0.916 | train f1: 0.775131194760101\n",
      "batch idx 180: | train loss: 0.49826911091804504 | train accu: 0.766 | train roc: 0.887 | train f1: 0.7442734010659562\n",
      "batch idx 181: | train loss: 0.4074753224849701 | train accu: 0.797 | train roc: 0.923 | train f1: 0.7872620545993834\n",
      "batch idx 182: | train loss: 0.41684088110923767 | train accu: 0.773 | train roc: 0.953 | train f1: 0.7644859086059743\n",
      "batch idx 183: | train loss: 0.43536365032196045 | train accu: 0.742 | train roc: 0.945 | train f1: 0.7289233977172959\n",
      "batch idx 184: | train loss: 0.4883011281490326 | train accu: 0.727 | train roc: 0.927 | train f1: 0.7058527691974856\n",
      "batch idx 185: | train loss: 0.34741532802581787 | train accu: 0.820 | train roc: 0.953 | train f1: 0.8115551603432701\n",
      "batch idx 186: | train loss: 0.510528028011322 | train accu: 0.773 | train roc: 0.900 | train f1: 0.7608134179736121\n",
      "batch idx 187: | train loss: 0.41310903429985046 | train accu: 0.766 | train roc: 0.933 | train f1: 0.7615464154411764\n",
      "batch idx 188: | train loss: 0.46355000138282776 | train accu: 0.789 | train roc: 0.938 | train f1: 0.7873996267053389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 189: | train loss: 0.4805808961391449 | train accu: 0.781 | train roc: 0.913 | train f1: 0.7659125707718177\n",
      "batch idx 190: | train loss: 0.5184698700904846 | train accu: 0.734 | train roc: 0.898 | train f1: 0.7275904778364197\n",
      "batch idx 191: | train loss: 0.4582973122596741 | train accu: 0.750 | train roc: 0.911 | train f1: 0.7444622312362548\n",
      "batch idx 192: | train loss: 0.5622130036354065 | train accu: 0.750 | train roc: 0.904 | train f1: 0.7473807251908398\n",
      "batch idx 193: | train loss: 0.4014185070991516 | train accu: 0.789 | train roc: 0.928 | train f1: 0.7809899566013697\n",
      "batch idx 194: | train loss: 0.45610469579696655 | train accu: 0.797 | train roc: 0.928 | train f1: 0.7920298946101767\n",
      "batch idx 195: | train loss: 0.5288923382759094 | train accu: 0.734 | train roc: 0.889 | train f1: 0.7160335354300871\n",
      "batch idx 196: | train loss: 0.5613672733306885 | train accu: 0.695 | train roc: 0.889 | train f1: 0.683034093855328\n",
      "batch idx 197: | train loss: 0.3758898675441742 | train accu: 0.836 | train roc: 0.941 | train f1: 0.8330100574712644\n",
      "batch idx 198: | train loss: 0.4773181974887848 | train accu: 0.789 | train roc: 0.919 | train f1: 0.7845931307305529\n",
      "batch idx 199: | train loss: 0.4246804118156433 | train accu: 0.773 | train roc: 0.922 | train f1: 0.7659129607371795\n",
      "batch idx 200: | train loss: 0.5190848708152771 | train accu: 0.773 | train roc: 0.883 | train f1: 0.765025559183168\n",
      "batch idx 201: | train loss: 0.48063725233078003 | train accu: 0.734 | train roc: 0.924 | train f1: 0.7306904815821256\n",
      "batch idx 202: | train loss: 0.5793853402137756 | train accu: 0.672 | train roc: 0.881 | train f1: 0.6518902089698821\n",
      "batch idx 203: | train loss: 0.5521093010902405 | train accu: 0.695 | train roc: 0.888 | train f1: 0.6912059294871795\n",
      "batch idx 204: | train loss: 0.41142523288726807 | train accu: 0.773 | train roc: 0.933 | train f1: 0.7681740064446831\n",
      "batch idx 205: | train loss: 0.473258376121521 | train accu: 0.758 | train roc: 0.923 | train f1: 0.7493387658437975\n",
      "batch idx 206: | train loss: 0.6239351630210876 | train accu: 0.648 | train roc: 0.859 | train f1: 0.6173988217213114\n",
      "batch idx 207: | train loss: 0.4462275207042694 | train accu: 0.719 | train roc: 0.929 | train f1: 0.7007161888252991\n",
      "batch idx 208: | train loss: 0.5316144227981567 | train accu: 0.719 | train roc: 0.878 | train f1: 0.6898344651952462\n",
      "batch idx 209: | train loss: 0.4376145005226135 | train accu: 0.781 | train roc: 0.922 | train f1: 0.7773921530537868\n",
      "batch idx 210: | train loss: 0.5530263781547546 | train accu: 0.688 | train roc: 0.888 | train f1: 0.6799169981640146\n",
      "batch idx 211: | train loss: 0.4516304135322571 | train accu: 0.727 | train roc: 0.946 | train f1: 0.7208926775030444\n",
      "batch idx 212: | train loss: 0.41354766488075256 | train accu: 0.820 | train roc: 0.935 | train f1: 0.8160168168382915\n",
      "batch idx 213: | train loss: 0.4487190544605255 | train accu: 0.789 | train roc: 0.923 | train f1: 0.7851006596851398\n",
      "batch idx 214: | train loss: 0.3923332095146179 | train accu: 0.828 | train roc: 0.927 | train f1: 0.8226349133403361\n",
      "batch idx 215: | train loss: 0.4182484447956085 | train accu: 0.812 | train roc: 0.926 | train f1: 0.801914074976046\n",
      "batch idx 216: | train loss: 0.505721390247345 | train accu: 0.750 | train roc: 0.893 | train f1: 0.7349405122842623\n",
      "batch idx 217: | train loss: 0.45921236276626587 | train accu: 0.758 | train roc: 0.917 | train f1: 0.7559700291406884\n",
      "batch idx 218: | train loss: 0.41232043504714966 | train accu: 0.812 | train roc: 0.936 | train f1: 0.8112562396485095\n",
      "batch idx 219: | train loss: 0.38661450147628784 | train accu: 0.820 | train roc: 0.935 | train f1: 0.8184475461696306\n",
      "batch idx 220: | train loss: 0.46016618609428406 | train accu: 0.742 | train roc: 0.905 | train f1: 0.7396868530020704\n",
      "batch idx 221: | train loss: 0.4322785437107086 | train accu: 0.758 | train roc: 0.939 | train f1: 0.740234375\n",
      "batch idx 222: | train loss: 0.3679908812046051 | train accu: 0.812 | train roc: 0.939 | train f1: 0.8081362612612613\n",
      "batch idx 223: | train loss: 0.4500283896923065 | train accu: 0.773 | train roc: 0.911 | train f1: 0.764289874204069\n",
      "batch idx 224: | train loss: 0.40002888441085815 | train accu: 0.797 | train roc: 0.927 | train f1: 0.7833381280230924\n",
      "batch idx 225: | train loss: 0.42384567856788635 | train accu: 0.773 | train roc: 0.907 | train f1: 0.7444911858974359\n",
      "batch idx 226: | train loss: 0.4790147840976715 | train accu: 0.758 | train roc: 0.902 | train f1: 0.7344200330734705\n",
      "batch idx 227: | train loss: 0.5269545316696167 | train accu: 0.727 | train roc: 0.884 | train f1: 0.7092332287644787\n",
      "batch idx 228: | train loss: 0.5734285712242126 | train accu: 0.727 | train roc: 0.884 | train f1: 0.7217124558193166\n",
      "batch idx 229: | train loss: 0.4738990366458893 | train accu: 0.758 | train roc: 0.914 | train f1: 0.7498076057766478\n",
      "batch idx 230: | train loss: 0.4437732398509979 | train accu: 0.828 | train roc: 0.932 | train f1: 0.8234876079247611\n",
      "batch idx 231: | train loss: 0.5087371468544006 | train accu: 0.742 | train roc: 0.910 | train f1: 0.738406703754618\n",
      "batch idx 232: | train loss: 0.42579352855682373 | train accu: 0.828 | train roc: 0.934 | train f1: 0.8262165037377804\n",
      "batch idx 233: | train loss: 0.4112870693206787 | train accu: 0.797 | train roc: 0.937 | train f1: 0.7935276930894308\n",
      "batch idx 234: | train loss: 0.4200214743614197 | train accu: 0.812 | train roc: 0.926 | train f1: 0.8060067267502613\n",
      "batch idx 235: | train loss: 0.5329126715660095 | train accu: 0.742 | train roc: 0.894 | train f1: 0.7407220361315723\n",
      "batch idx 236: | train loss: 0.44634515047073364 | train accu: 0.805 | train roc: 0.934 | train f1: 0.8007486465147755\n",
      "batch idx 237: | train loss: 0.4971270263195038 | train accu: 0.750 | train roc: 0.924 | train f1: 0.7433261084284459\n",
      "batch idx 238: | train loss: 0.39607229828834534 | train accu: 0.781 | train roc: 0.926 | train f1: 0.7745280622027919\n",
      "batch idx 239: | train loss: 0.43510666489601135 | train accu: 0.781 | train roc: 0.923 | train f1: 0.7787811753285543\n",
      "batch idx 240: | train loss: 0.40291470289230347 | train accu: 0.836 | train roc: 0.948 | train f1: 0.8372047430334948\n",
      "Epoch: 06 | Epoch Time: 2m 13s\n",
      "\tTrain Loss: 0.451 | Train Acc: 77.24 | Train rocauc: 0.9194831732531085 | Train f1: 0.7620171395542744%\n",
      "\t Val. Loss: 0.709 |  Val. Acc: 68.68 | Val. rocauc: 0.8488936125000296 | Val. f1: 0.6849774717494161%\n",
      "batch idx 0: | train loss: 0.31259143352508545 | train accu: 0.875 | train roc: 0.972 | train f1: 0.8720556972789115\n",
      "batch idx 1: | train loss: 0.525993824005127 | train accu: 0.750 | train roc: 0.897 | train f1: 0.7438625861178312\n",
      "batch idx 2: | train loss: 0.39752957224845886 | train accu: 0.781 | train roc: 0.935 | train f1: 0.7744220890410959\n",
      "batch idx 3: | train loss: 0.4855685830116272 | train accu: 0.742 | train roc: 0.937 | train f1: 0.7269902634593356\n",
      "batch idx 4: | train loss: 0.3940805494785309 | train accu: 0.812 | train roc: 0.940 | train f1: 0.7980783932068238\n",
      "batch idx 5: | train loss: 0.3732643127441406 | train accu: 0.789 | train roc: 0.951 | train f1: 0.7832715320092001\n",
      "batch idx 6: | train loss: 0.28803882002830505 | train accu: 0.859 | train roc: 0.963 | train f1: 0.8557210818355119\n",
      "batch idx 7: | train loss: 0.37419721484184265 | train accu: 0.820 | train roc: 0.948 | train f1: 0.8164324904580152\n",
      "batch idx 8: | train loss: 0.35332658886909485 | train accu: 0.797 | train roc: 0.948 | train f1: 0.7905138764701837\n",
      "batch idx 9: | train loss: 0.3674563467502594 | train accu: 0.797 | train roc: 0.940 | train f1: 0.7887517407798694\n",
      "batch idx 10: | train loss: 0.4374391734600067 | train accu: 0.766 | train roc: 0.951 | train f1: 0.7655026719739622\n",
      "batch idx 11: | train loss: 0.4306963384151459 | train accu: 0.820 | train roc: 0.929 | train f1: 0.8165930521514162\n",
      "batch idx 12: | train loss: 0.39852046966552734 | train accu: 0.742 | train roc: 0.915 | train f1: 0.7185480152365677\n",
      "batch idx 13: | train loss: 0.3577507734298706 | train accu: 0.859 | train roc: 0.947 | train f1: 0.8573409433332144\n",
      "batch idx 14: | train loss: 0.4008307158946991 | train accu: 0.820 | train roc: 0.907 | train f1: 0.7996291068664697\n",
      "batch idx 15: | train loss: 0.4361569285392761 | train accu: 0.773 | train roc: 0.932 | train f1: 0.7597343039084061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 16: | train loss: 0.40063098073005676 | train accu: 0.797 | train roc: 0.903 | train f1: 0.7748122358816751\n",
      "batch idx 17: | train loss: 0.3672890365123749 | train accu: 0.820 | train roc: 0.953 | train f1: 0.812591131314864\n",
      "batch idx 18: | train loss: 0.3326413333415985 | train accu: 0.820 | train roc: 0.956 | train f1: 0.810055441634389\n",
      "batch idx 19: | train loss: 0.4176826775074005 | train accu: 0.750 | train roc: 0.925 | train f1: 0.729828477443609\n",
      "batch idx 20: | train loss: 0.45345360040664673 | train accu: 0.766 | train roc: 0.910 | train f1: 0.7637880986937591\n",
      "batch idx 21: | train loss: 0.38278165459632874 | train accu: 0.844 | train roc: 0.938 | train f1: 0.8418537801484229\n",
      "batch idx 22: | train loss: 0.3975241780281067 | train accu: 0.820 | train roc: 0.942 | train f1: 0.816950002929802\n",
      "batch idx 23: | train loss: 0.4432690143585205 | train accu: 0.789 | train roc: 0.938 | train f1: 0.7877617431733286\n",
      "batch idx 24: | train loss: 0.4504992663860321 | train accu: 0.812 | train roc: 0.931 | train f1: 0.8066807184750733\n",
      "batch idx 25: | train loss: 0.3092731237411499 | train accu: 0.844 | train roc: 0.961 | train f1: 0.8362542980321626\n",
      "batch idx 26: | train loss: 0.3128056824207306 | train accu: 0.836 | train roc: 0.953 | train f1: 0.8303467827004221\n",
      "batch idx 27: | train loss: 0.4531373679637909 | train accu: 0.758 | train roc: 0.915 | train f1: 0.7271774433622376\n",
      "batch idx 28: | train loss: 0.4043073356151581 | train accu: 0.812 | train roc: 0.936 | train f1: 0.8052361853832442\n",
      "batch idx 29: | train loss: 0.3257782459259033 | train accu: 0.789 | train roc: 0.958 | train f1: 0.7767897353559727\n",
      "batch idx 30: | train loss: 0.41950181126594543 | train accu: 0.789 | train roc: 0.930 | train f1: 0.7839230599647267\n",
      "batch idx 31: | train loss: 0.3596440255641937 | train accu: 0.867 | train roc: 0.948 | train f1: 0.8656000382974067\n",
      "batch idx 32: | train loss: 0.4135417938232422 | train accu: 0.797 | train roc: 0.937 | train f1: 0.7944196428571428\n",
      "batch idx 33: | train loss: 0.37407559156417847 | train accu: 0.859 | train roc: 0.957 | train f1: 0.8585339161134673\n",
      "batch idx 34: | train loss: 0.5071455836296082 | train accu: 0.750 | train roc: 0.914 | train f1: 0.7467153501174573\n",
      "batch idx 35: | train loss: 0.4579688608646393 | train accu: 0.797 | train roc: 0.917 | train f1: 0.7901430043171115\n",
      "batch idx 36: | train loss: 0.40808820724487305 | train accu: 0.766 | train roc: 0.922 | train f1: 0.7404930385556916\n",
      "batch idx 37: | train loss: 0.3272418677806854 | train accu: 0.852 | train roc: 0.965 | train f1: 0.8472319003716409\n",
      "batch idx 38: | train loss: 0.36627912521362305 | train accu: 0.805 | train roc: 0.949 | train f1: 0.7880103114478114\n",
      "batch idx 39: | train loss: 0.31828752160072327 | train accu: 0.859 | train roc: 0.944 | train f1: 0.8427083333333333\n",
      "batch idx 40: | train loss: 0.4094673693180084 | train accu: 0.773 | train roc: 0.931 | train f1: 0.768375191974842\n",
      "batch idx 41: | train loss: 0.4335412383079529 | train accu: 0.750 | train roc: 0.924 | train f1: 0.7444857726752057\n",
      "batch idx 42: | train loss: 0.3289482593536377 | train accu: 0.867 | train roc: 0.954 | train f1: 0.8641520979020979\n",
      "batch idx 43: | train loss: 0.39023557305336 | train accu: 0.820 | train roc: 0.938 | train f1: 0.8160856762917932\n",
      "batch idx 44: | train loss: 0.3577992916107178 | train accu: 0.852 | train roc: 0.952 | train f1: 0.8508304531490015\n",
      "batch idx 45: | train loss: 0.4643239378929138 | train accu: 0.797 | train roc: 0.929 | train f1: 0.796211985055443\n",
      "batch idx 46: | train loss: 0.4053207337856293 | train accu: 0.812 | train roc: 0.933 | train f1: 0.8117326788963009\n",
      "batch idx 47: | train loss: 0.33568239212036133 | train accu: 0.828 | train roc: 0.949 | train f1: 0.8201135775366208\n",
      "batch idx 48: | train loss: 0.32232466340065 | train accu: 0.828 | train roc: 0.940 | train f1: 0.8231412226243215\n",
      "batch idx 49: | train loss: 0.537092387676239 | train accu: 0.711 | train roc: 0.904 | train f1: 0.6955700809134906\n",
      "batch idx 50: | train loss: 0.45567741990089417 | train accu: 0.719 | train roc: 0.929 | train f1: 0.6771959194862156\n",
      "batch idx 51: | train loss: 0.39763909578323364 | train accu: 0.852 | train roc: 0.936 | train f1: 0.849526913372582\n",
      "batch idx 52: | train loss: 0.2828149199485779 | train accu: 0.875 | train roc: 0.972 | train f1: 0.8697779605263158\n",
      "batch idx 53: | train loss: 0.4018699824810028 | train accu: 0.797 | train roc: 0.932 | train f1: 0.7929575215586075\n",
      "batch idx 54: | train loss: 0.5566433072090149 | train accu: 0.766 | train roc: 0.912 | train f1: 0.7650833012326657\n",
      "batch idx 55: | train loss: 0.5152967572212219 | train accu: 0.727 | train roc: 0.908 | train f1: 0.7154903628117912\n",
      "batch idx 56: | train loss: 0.3174511790275574 | train accu: 0.859 | train roc: 0.963 | train f1: 0.8567023522795155\n",
      "batch idx 57: | train loss: 0.45790421962738037 | train accu: 0.773 | train roc: 0.909 | train f1: 0.7605719656283565\n",
      "batch idx 58: | train loss: 0.4330294728279114 | train accu: 0.789 | train roc: 0.915 | train f1: 0.7727058640942552\n",
      "batch idx 59: | train loss: 0.3646353483200073 | train accu: 0.805 | train roc: 0.940 | train f1: 0.7875187868647913\n",
      "batch idx 60: | train loss: 0.4023202061653137 | train accu: 0.781 | train roc: 0.931 | train f1: 0.7677060703542782\n",
      "batch idx 61: | train loss: 0.4344639182090759 | train accu: 0.773 | train roc: 0.917 | train f1: 0.7545572916666666\n",
      "batch idx 62: | train loss: 0.3601676821708679 | train accu: 0.805 | train roc: 0.945 | train f1: 0.785638293045877\n",
      "batch idx 63: | train loss: 0.31237858533859253 | train accu: 0.828 | train roc: 0.965 | train f1: 0.8050824175824176\n",
      "batch idx 64: | train loss: 0.46390387415885925 | train accu: 0.727 | train roc: 0.930 | train f1: 0.7163526564710043\n",
      "batch idx 65: | train loss: 0.4749503433704376 | train accu: 0.781 | train roc: 0.918 | train f1: 0.7805596406200016\n",
      "batch idx 66: | train loss: 0.5518466830253601 | train accu: 0.727 | train roc: 0.899 | train f1: 0.7251645704619005\n",
      "batch idx 67: | train loss: 0.450860857963562 | train accu: 0.781 | train roc: 0.923 | train f1: 0.7809235636801929\n",
      "batch idx 68: | train loss: 0.4895024597644806 | train accu: 0.773 | train roc: 0.898 | train f1: 0.7692141595307714\n",
      "batch idx 69: | train loss: 0.42355552315711975 | train accu: 0.812 | train roc: 0.935 | train f1: 0.810857865052617\n",
      "batch idx 70: | train loss: 0.34420230984687805 | train accu: 0.805 | train roc: 0.952 | train f1: 0.8012569805691555\n",
      "batch idx 71: | train loss: 0.4281172454357147 | train accu: 0.742 | train roc: 0.927 | train f1: 0.7340442346885647\n",
      "batch idx 72: | train loss: 0.4756649434566498 | train accu: 0.812 | train roc: 0.919 | train f1: 0.8105122972743827\n",
      "batch idx 73: | train loss: 0.37037381529808044 | train accu: 0.805 | train roc: 0.944 | train f1: 0.8013618762243594\n",
      "batch idx 74: | train loss: 0.34856751561164856 | train accu: 0.867 | train roc: 0.942 | train f1: 0.8638009612873743\n",
      "batch idx 75: | train loss: 0.34033894538879395 | train accu: 0.836 | train roc: 0.954 | train f1: 0.83056640625\n",
      "batch idx 76: | train loss: 0.3970679044723511 | train accu: 0.797 | train roc: 0.946 | train f1: 0.7932563668600903\n",
      "batch idx 77: | train loss: 0.4443131685256958 | train accu: 0.789 | train roc: 0.919 | train f1: 0.7827690972222222\n",
      "batch idx 78: | train loss: 0.4085862338542938 | train accu: 0.805 | train roc: 0.927 | train f1: 0.7926415598290598\n",
      "batch idx 79: | train loss: 0.3730659484863281 | train accu: 0.781 | train roc: 0.949 | train f1: 0.7721097570842922\n",
      "batch idx 80: | train loss: 0.5553885102272034 | train accu: 0.688 | train roc: 0.901 | train f1: 0.6493407524328082\n",
      "batch idx 81: | train loss: 0.4586474597454071 | train accu: 0.766 | train roc: 0.919 | train f1: 0.7604135205879392\n",
      "batch idx 82: | train loss: 0.4454900622367859 | train accu: 0.766 | train roc: 0.920 | train f1: 0.7565381047523905\n",
      "batch idx 83: | train loss: 0.5429062843322754 | train accu: 0.711 | train roc: 0.895 | train f1: 0.6934636358347356\n",
      "batch idx 84: | train loss: 0.3422817587852478 | train accu: 0.828 | train roc: 0.943 | train f1: 0.8195586622807018\n",
      "batch idx 85: | train loss: 0.39116331934928894 | train accu: 0.797 | train roc: 0.933 | train f1: 0.7872106196686351\n",
      "batch idx 86: | train loss: 0.3771156370639801 | train accu: 0.812 | train roc: 0.950 | train f1: 0.8144367190385942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch idx 87: | train loss: 0.42158886790275574 | train accu: 0.734 | train roc: 0.925 | train f1: 0.7213046907107891\n",
      "batch idx 88: | train loss: 0.49347206950187683 | train accu: 0.773 | train roc: 0.904 | train f1: 0.7708670236013986\n",
      "batch idx 89: | train loss: 0.37206050753593445 | train accu: 0.781 | train roc: 0.942 | train f1: 0.7725095319976076\n",
      "batch idx 90: | train loss: 0.4351467490196228 | train accu: 0.750 | train roc: 0.934 | train f1: 0.7385900444664033\n",
      "batch idx 91: | train loss: 0.429010272026062 | train accu: 0.797 | train roc: 0.939 | train f1: 0.7934189003799071\n",
      "batch idx 92: | train loss: 0.44829487800598145 | train accu: 0.742 | train roc: 0.931 | train f1: 0.722532236346733\n",
      "batch idx 93: | train loss: 0.3481709659099579 | train accu: 0.859 | train roc: 0.951 | train f1: 0.8542998120300752\n",
      "batch idx 94: | train loss: 0.4007661044597626 | train accu: 0.773 | train roc: 0.940 | train f1: 0.7704581314548005\n",
      "batch idx 95: | train loss: 0.45691630244255066 | train accu: 0.773 | train roc: 0.915 | train f1: 0.7606217590341922\n",
      "batch idx 96: | train loss: 0.44308605790138245 | train accu: 0.742 | train roc: 0.914 | train f1: 0.7334981076507319\n",
      "batch idx 97: | train loss: 0.4427790939807892 | train accu: 0.758 | train roc: 0.895 | train f1: 0.7442206037122081\n",
      "batch idx 98: | train loss: 0.47800666093826294 | train accu: 0.742 | train roc: 0.907 | train f1: 0.7309329757792545\n",
      "batch idx 99: | train loss: 0.40341106057167053 | train accu: 0.781 | train roc: 0.932 | train f1: 0.7802671370967742\n",
      "batch idx 100: | train loss: 0.35504382848739624 | train accu: 0.812 | train roc: 0.957 | train f1: 0.8118156895374637\n",
      "batch idx 101: | train loss: 0.418443500995636 | train accu: 0.766 | train roc: 0.921 | train f1: 0.7368361193398223\n",
      "batch idx 102: | train loss: 0.4077286422252655 | train accu: 0.828 | train roc: 0.934 | train f1: 0.8128986811724651\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"valid_loss\": []\n",
    "}\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(args['n_epochs']):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc, train_rocauc, train_f1 = train(model, train_loader, optimizer, criterion)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    valid_loss, valid_acc, valid_rocauc, valid_f1 = evaluate(model, valid_loader, criterion)\n",
    "    history[\"valid_loss\"].append(valid_loss)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model_3.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | Train rocauc: {train_rocauc} | Train f1: {train_f1}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | Val. rocauc: {valid_rocauc} | Val. f1: {valid_f1}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RmkY8rQnoIsW",
    "outputId": "d43de9cc-92d5-4a4c-e865-031af97d3936"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model_3.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NhZ7azqzEzxY",
    "outputId": "dbf8ef34-d9c4-4573-88eb-d5cc15b174e7"
   },
   "outputs": [],
   "source": [
    "valid_loss, valid_acc, valid_rocauc, valid_f1 = evaluate(model, valid_loader, criterion)\n",
    "print(\"Valid loss: {} | Valid Acc: {:.3f} | Valid ROC-AUC: {} | Valid f1: {}\".format(\n",
    "    valid_loss, valid_acc, valid_rocauc, valid_f1))\n",
    "test_loss, test_acc, test_rocauc, test_f1 = evaluate(model, test_loader, criterion)\n",
    "print(\"Test loss: {} | Test Acc: {:.3f} | Test ROC-AUC: {} | Test f1: {}\".format(\n",
    "    test_loss, test_acc, test_rocauc, test_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(hist):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(np.arange(1, args[\"n_epochs\"] + 1), history[\"train_loss\"], label=\"training loss\")\n",
    "    plt.plot(np.arange(1, args[\"n_epochs\"] + 1), history[\"valid_loss\"], label=\"validation loss\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.title(\"Training and Validation Losses\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Off8zqkRHVeK",
    "outputId": "e4055bdc-64b8-42fe-d178-3db779fe7da9"
   },
   "outputs": [],
   "source": [
    "a= \"COVID fears in Toronto: to me single biggest worry right now is this: the situation is massively worse for the average person now than it was at peak. why? Because at peak it was almost all LTCFs. Now? Unchecked community spread. That's terrifying to me.\"\n",
    "a_encoded = tokenizer.encode(a, add_special_tokens=True)\n",
    "a_final = torch.tensor(a_encoded + [0] * (max_len - len(a_encoded))).view(1, -1).to(device)\n",
    "softmax = nn.Softmax(dim=1)\n",
    "probs = softmax(model(a_final))\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hpS-CoSrIVZO"
   },
   "source": [
    "## Randomized Search for optimal hyper"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of main_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
