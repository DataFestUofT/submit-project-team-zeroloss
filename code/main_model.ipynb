{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Copy of main_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOuPcrympZNP",
        "colab_type": "code",
        "outputId": "7d7aa666-7673-4d34-a1dc-7be90d7330ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff7619ca490>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdBoXN9vrpFk",
        "colab_type": "code",
        "outputId": "59ca0bd5-7b3f-4306-db75-0ff52d9ee7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  8 02:32:51 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   81C    P8    12W /  75W |      0MiB /  7611MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDlWkGH2pZNV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud7G5HtNpZNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = {'batch_size': 128,\n",
        "        'lr': 3e-4,\n",
        "        'hidden_dim': 128,\n",
        "        'n_layers': 2,\n",
        "        'bidirectional': True,\n",
        "        'dropout': 0.25,\n",
        "        'n_epochs': 50,\n",
        "        'weight': torch.tensor([0.15, 0.48, 0.37])\n",
        "        }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4q_7bs-pZNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\n",
        "    'data1.csv',\n",
        "    sep=',')\n",
        "train_data = df.iloc[:7500, :]\n",
        "valid_data = df.iloc[7500:, :].reset_index()\n",
        "test_data = pd.read_csv(\n",
        "    'data2.csv',\n",
        "    sep=',')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k0emIZYpZNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc73gO9zpZNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_train = train_data['text'].apply((\n",
        "    lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized_valid = valid_data['text'].apply((\n",
        "    lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
        "tokenized_test = test_data['text'].apply((\n",
        "    lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yfrURp5pZNm",
        "colab_type": "code",
        "outputId": "2f06b8f7-dc3c-420a-e7c1-8128dc116b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# max_len = tokenizer.max_model_input_sizes['distilbert-base-uncased']\n",
        "\n",
        "# print(max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xdf2dN5pZNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_len(tokenized):\n",
        "    max_len = 0\n",
        "    for i in tokenized.values:\n",
        "        if len(i) > max_len:\n",
        "            max_len = len(i)\n",
        "    return max_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqyggJL0pZNr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_train = get_max_len(tokenized_train)\n",
        "print(max_len_train)\n",
        "max_len_valid = get_max_len(tokenized_valid)\n",
        "print(max_len_valid)\n",
        "max_len_test = get_max_len(tokenized_test)\n",
        "print(max_len_test)\n",
        "max_len = max([max_len_train, max_len_valid, max_len_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNbavbblpZNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded_train = torch.tensor([i + [0] * (max_len - len(i)) \n",
        "                             for i in tokenized_train.values])\n",
        "padded_valid = torch.tensor([i + [0] * (max_len - len(i)) \n",
        "                             for i in tokenized_valid.values])\n",
        "padded_test = torch.tensor([i + [0] * (max_len - len(i)) \n",
        "                            for i in tokenized_test.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xWoyP2sNpZN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_label = torch.tensor(train_data['sentiment'].replace(\n",
        "    to_replace='positive', value=2).replace(\n",
        "    to_replace='negative', value=0).replace(\n",
        "    to_replace='neutral', value=1))\n",
        "valid_label = torch.tensor(valid_data['sentiment'].replace(\n",
        "    to_replace='positive', value=2).replace(\n",
        "    to_replace='negative', value=0).replace(\n",
        "    to_replace='neutral', value=1))\n",
        "test_label = torch.tensor(test_data['sentiment'].replace(\n",
        "    to_replace='positive', value=2).replace(\n",
        "    to_replace='negative', value=0).replace(\n",
        "    to_replace='neutral', value=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9l1JWIBpZN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the dataset and data iterators\n",
        "class Dataset(data.Dataset):\n",
        "    'Characterizes a dataset for PyTorch'\n",
        "    def __init__(self, x, labels):\n",
        "        'Initialization'\n",
        "        self.x = x\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the total number of samples'\n",
        "        return self.x.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "\n",
        "        # Load data and get label\n",
        "        x = self.x[index]\n",
        "        y = self.labels[index]\n",
        "\n",
        "        return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN8l3lb2pZOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainset = Dataset(padded_train, train_label)\n",
        "validset = Dataset(padded_valid, valid_label)\n",
        "testset = Dataset(padded_test, test_label)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                           batch_size=args['batch_size'],\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "valid_loader = torch.utils.data.DataLoader(validset,\n",
        "                                           batch_size=args['batch_size'],\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset,\n",
        "                                           batch_size=args['batch_size'],\n",
        "                                           shuffle=True,\n",
        "                                           drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38su5K_pZOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = DistilBertModel.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvF4-cF-pZOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BERTGRUSentiment(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['dim']\n",
        "        \n",
        "        self.rnn = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "        attention_mask = text.masked_fill(text != 0, 1)\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded = self.bert(text, attention_mask=attention_mask)[0]\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden = self.rnn(embedded)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn.bidirectional:\n",
        "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden = self.dropout(hidden[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(hidden)\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_LOY0xrpZOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BERTGRUSentiment(bert,\n",
        "                         args['hidden_dim'],\n",
        "                         3,\n",
        "                         args['n_layers'],\n",
        "                         args['bidirectional'],\n",
        "                         args['dropout'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fW94YLX-pZOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h1H2wJ5pZOM",
        "colab_type": "code",
        "outputId": "9c1ddc1a-02dd-4148-854d-ae56ced5e82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 986,883 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTzScxaXpZOT",
        "colab_type": "code",
        "outputId": "7630a095-52a0-4dd2-bcaf-1014da28254c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn.weight_ih_l0\n",
            "rnn.weight_hh_l0\n",
            "rnn.bias_ih_l0\n",
            "rnn.bias_hh_l0\n",
            "rnn.weight_ih_l0_reverse\n",
            "rnn.weight_hh_l0_reverse\n",
            "rnn.bias_ih_l0_reverse\n",
            "rnn.bias_hh_l0_reverse\n",
            "rnn.weight_ih_l1\n",
            "rnn.weight_hh_l1\n",
            "rnn.bias_ih_l1\n",
            "rnn.bias_hh_l1\n",
            "rnn.weight_ih_l1_reverse\n",
            "rnn.weight_hh_l1_reverse\n",
            "rnn.bias_ih_l1_reverse\n",
            "rnn.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqpKLW5KpZOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=args['lr'])\n",
        "criterion = nn.CrossEntropyLoss(weight=args['weight'])\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuYWWnMcpZOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multi_acc(y_pred, y_label):\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    y_pred_softmax = softmax(y_pred)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
        "\n",
        "    # accu\n",
        "    correct_pred = (y_pred_tags == y_label).float()\n",
        "    acc = correct_pred.sum() / len(y_label)\n",
        "\n",
        "    # roc-auc\n",
        "    one_hot_label = nn.functional.one_hot(y_label)\n",
        "    roc_auc = roc_auc_score(one_hot_label.cpu(), y_pred_softmax.cpu(), average=\"micro\")\n",
        "\n",
        "    # f1\n",
        "    f1 = f1_score(y_label.cpu(), y_pred_tags.cpu(), average='micro')\n",
        "    \n",
        "    return acc, roc_auc, f1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC4S8kt4pZOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, data_loader, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_rocauc = 0\n",
        "    epoch_f1 = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(data_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(data).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, target)\n",
        "        \n",
        "        acc, roc_auc, f1 = multi_acc(predictions, target)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        epoch_rocauc += roc_auc\n",
        "        epoch_f1 += f1\n",
        "\n",
        "        print(\"batch idx {}: | train loss: {} | train accu: {:.3f} | train roc: {:.3f} | train f1: {}\".format(\n",
        "            batch_idx, loss.item(), acc.item(), roc_auc, f1))\n",
        "        \n",
        "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader), epoch_rocauc / len(data_loader), epoch_f1 / len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJWccuIGpZOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data_loader, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    epoch_rocauc = 0\n",
        "    epoch_f1 = 0\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch_idx, (data, target) in enumerate(data_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            predictions = model(data).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, target)\n",
        "            \n",
        "            acc, roc_auc, f1 = multi_acc(predictions, target)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_rocauc += roc_auc\n",
        "            epoch_f1 += f1\n",
        "        \n",
        "    return epoch_loss / len(data_loader), epoch_acc / len(data_loader), epoch_rocauc / len(data_loader), epoch_f1 / len(data_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANdP4TtjpZOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkGmKBdcpZOl",
        "colab_type": "code",
        "outputId": "1f634257-c5a8-499c-f379-48f183f486cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(args['n_epochs']):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc, train_rocauc, train_f1 = train(model, train_loader, optimizer, criterion)\n",
        "    valid_loss, valid_acc, valid_rocauc, valid_f1 = evaluate(model, valid_loader, criterion)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'best_model_3.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f} | Train rocauc: {train_rocauc} | Train f1: {train_f1}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f} | Val. rocauc: {valid_rocauc} | Val. f1: {valid_f1}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch idx 0: | train loss: 1.1268832683563232 | train accu: 0.312\n",
            "batch idx 1: | train loss: 1.007917046546936 | train accu: 0.500\n",
            "batch idx 2: | train loss: 0.9564115405082703 | train accu: 0.422\n",
            "batch idx 3: | train loss: 0.8708832263946533 | train accu: 0.492\n",
            "batch idx 4: | train loss: 0.8485457897186279 | train accu: 0.523\n",
            "batch idx 5: | train loss: 0.8379719853401184 | train accu: 0.508\n",
            "batch idx 6: | train loss: 0.7903225421905518 | train accu: 0.547\n",
            "batch idx 7: | train loss: 0.7675091028213501 | train accu: 0.547\n",
            "batch idx 8: | train loss: 0.8438669443130493 | train accu: 0.477\n",
            "batch idx 9: | train loss: 0.8189470767974854 | train accu: 0.516\n",
            "batch idx 10: | train loss: 0.8264365792274475 | train accu: 0.500\n",
            "batch idx 11: | train loss: 0.7894354462623596 | train accu: 0.492\n",
            "batch idx 12: | train loss: 0.7960377931594849 | train accu: 0.523\n",
            "batch idx 13: | train loss: 0.8151302933692932 | train accu: 0.484\n",
            "batch idx 14: | train loss: 0.8371462225914001 | train accu: 0.570\n",
            "batch idx 15: | train loss: 0.7443982362747192 | train accu: 0.586\n",
            "batch idx 16: | train loss: 0.7885242104530334 | train accu: 0.523\n",
            "batch idx 17: | train loss: 0.8212465047836304 | train accu: 0.523\n",
            "batch idx 18: | train loss: 0.785300612449646 | train accu: 0.523\n",
            "batch idx 19: | train loss: 0.7754959464073181 | train accu: 0.547\n",
            "batch idx 20: | train loss: 0.8094652891159058 | train accu: 0.523\n",
            "batch idx 21: | train loss: 0.7342550158500671 | train accu: 0.609\n",
            "batch idx 22: | train loss: 0.8585464954376221 | train accu: 0.445\n",
            "batch idx 23: | train loss: 0.7682640552520752 | train accu: 0.562\n",
            "batch idx 24: | train loss: 0.7832525372505188 | train accu: 0.586\n",
            "batch idx 25: | train loss: 0.7253463864326477 | train accu: 0.648\n",
            "batch idx 26: | train loss: 0.7264498472213745 | train accu: 0.578\n",
            "batch idx 27: | train loss: 0.7333410978317261 | train accu: 0.641\n",
            "batch idx 28: | train loss: 0.6993851065635681 | train accu: 0.602\n",
            "batch idx 29: | train loss: 0.6598578095436096 | train accu: 0.648\n",
            "batch idx 30: | train loss: 0.7551249265670776 | train accu: 0.547\n",
            "batch idx 31: | train loss: 0.7846863865852356 | train accu: 0.516\n",
            "batch idx 32: | train loss: 0.711236298084259 | train accu: 0.570\n",
            "batch idx 33: | train loss: 0.6731370091438293 | train accu: 0.641\n",
            "batch idx 34: | train loss: 0.6678671836853027 | train accu: 0.672\n",
            "batch idx 35: | train loss: 0.766413152217865 | train accu: 0.508\n",
            "batch idx 36: | train loss: 0.6675428748130798 | train accu: 0.648\n",
            "batch idx 37: | train loss: 0.7117365598678589 | train accu: 0.641\n",
            "batch idx 38: | train loss: 0.7356187701225281 | train accu: 0.562\n",
            "batch idx 39: | train loss: 0.743263840675354 | train accu: 0.562\n",
            "batch idx 40: | train loss: 0.6915194392204285 | train accu: 0.594\n",
            "batch idx 41: | train loss: 0.6515856385231018 | train accu: 0.633\n",
            "batch idx 42: | train loss: 0.7076036334037781 | train accu: 0.594\n",
            "batch idx 43: | train loss: 0.6285786628723145 | train accu: 0.672\n",
            "batch idx 44: | train loss: 0.6906905770301819 | train accu: 0.641\n",
            "batch idx 45: | train loss: 0.730280339717865 | train accu: 0.602\n",
            "batch idx 46: | train loss: 0.6751190423965454 | train accu: 0.625\n",
            "batch idx 47: | train loss: 0.7507747411727905 | train accu: 0.578\n",
            "batch idx 48: | train loss: 0.7146058678627014 | train accu: 0.578\n",
            "batch idx 49: | train loss: 0.7283188104629517 | train accu: 0.609\n",
            "batch idx 50: | train loss: 0.7323813438415527 | train accu: 0.594\n",
            "batch idx 51: | train loss: 0.6430190801620483 | train accu: 0.633\n",
            "batch idx 52: | train loss: 0.6836628913879395 | train accu: 0.633\n",
            "batch idx 53: | train loss: 0.654188334941864 | train accu: 0.609\n",
            "batch idx 54: | train loss: 0.6418123841285706 | train accu: 0.664\n",
            "batch idx 55: | train loss: 0.7431060075759888 | train accu: 0.578\n",
            "batch idx 56: | train loss: 0.7450670003890991 | train accu: 0.578\n",
            "batch idx 57: | train loss: 0.6369190216064453 | train accu: 0.672\n",
            "Epoch: 01 | Epoch Time: 3m 40s\n",
            "\tTrain Loss: 0.759 | Train Acc: 56.75%\n",
            "\t Val. Loss: 0.778 |  Val. Acc: 56.59%\n",
            "batch idx 0: | train loss: 0.7346915006637573 | train accu: 0.625\n",
            "batch idx 1: | train loss: 0.7424200177192688 | train accu: 0.609\n",
            "batch idx 2: | train loss: 0.5001296401023865 | train accu: 0.734\n",
            "batch idx 3: | train loss: 0.5960378646850586 | train accu: 0.695\n",
            "batch idx 4: | train loss: 0.6775860786437988 | train accu: 0.609\n",
            "batch idx 5: | train loss: 0.703803300857544 | train accu: 0.578\n",
            "batch idx 6: | train loss: 0.6413149833679199 | train accu: 0.625\n",
            "batch idx 7: | train loss: 0.6287618279457092 | train accu: 0.648\n",
            "batch idx 8: | train loss: 0.7168605327606201 | train accu: 0.578\n",
            "batch idx 9: | train loss: 0.7080210447311401 | train accu: 0.594\n",
            "batch idx 10: | train loss: 0.8150532245635986 | train accu: 0.539\n",
            "batch idx 11: | train loss: 0.638041079044342 | train accu: 0.672\n",
            "batch idx 12: | train loss: 0.7232192158699036 | train accu: 0.633\n",
            "batch idx 13: | train loss: 0.6542842388153076 | train accu: 0.656\n",
            "batch idx 14: | train loss: 0.5943682789802551 | train accu: 0.688\n",
            "batch idx 15: | train loss: 0.6603644490242004 | train accu: 0.633\n",
            "batch idx 16: | train loss: 0.5635556578636169 | train accu: 0.695\n",
            "batch idx 17: | train loss: 0.671605110168457 | train accu: 0.617\n",
            "batch idx 18: | train loss: 0.5918784141540527 | train accu: 0.672\n",
            "batch idx 19: | train loss: 0.6678107976913452 | train accu: 0.672\n",
            "batch idx 20: | train loss: 0.6858636140823364 | train accu: 0.594\n",
            "batch idx 21: | train loss: 0.6179918050765991 | train accu: 0.656\n",
            "batch idx 22: | train loss: 0.7431454062461853 | train accu: 0.570\n",
            "batch idx 23: | train loss: 0.7089892625808716 | train accu: 0.594\n",
            "batch idx 24: | train loss: 0.6136696338653564 | train accu: 0.617\n",
            "batch idx 25: | train loss: 0.6436011791229248 | train accu: 0.680\n",
            "batch idx 26: | train loss: 0.6309825778007507 | train accu: 0.633\n",
            "batch idx 27: | train loss: 0.628207802772522 | train accu: 0.672\n",
            "batch idx 28: | train loss: 0.6028980016708374 | train accu: 0.688\n",
            "batch idx 29: | train loss: 0.6863602995872498 | train accu: 0.617\n",
            "batch idx 30: | train loss: 0.6253544688224792 | train accu: 0.633\n",
            "batch idx 31: | train loss: 0.6427890658378601 | train accu: 0.586\n",
            "batch idx 32: | train loss: 0.6655489206314087 | train accu: 0.602\n",
            "batch idx 33: | train loss: 0.5616312623023987 | train accu: 0.680\n",
            "batch idx 34: | train loss: 0.6582278609275818 | train accu: 0.602\n",
            "batch idx 35: | train loss: 0.5985080003738403 | train accu: 0.656\n",
            "batch idx 36: | train loss: 0.756626307964325 | train accu: 0.555\n",
            "batch idx 37: | train loss: 0.6807528734207153 | train accu: 0.633\n",
            "batch idx 38: | train loss: 0.5990626811981201 | train accu: 0.703\n",
            "batch idx 39: | train loss: 0.6256769299507141 | train accu: 0.648\n",
            "batch idx 40: | train loss: 0.6043567061424255 | train accu: 0.648\n",
            "batch idx 41: | train loss: 0.6153228282928467 | train accu: 0.641\n",
            "batch idx 42: | train loss: 0.6496062278747559 | train accu: 0.609\n",
            "batch idx 43: | train loss: 0.5538074970245361 | train accu: 0.711\n",
            "batch idx 44: | train loss: 0.7210052013397217 | train accu: 0.617\n",
            "batch idx 45: | train loss: 0.6722635626792908 | train accu: 0.586\n",
            "batch idx 46: | train loss: 0.6258552074432373 | train accu: 0.641\n",
            "batch idx 47: | train loss: 0.5248726010322571 | train accu: 0.719\n",
            "batch idx 48: | train loss: 0.6482256650924683 | train accu: 0.641\n",
            "batch idx 49: | train loss: 0.5223429203033447 | train accu: 0.758\n",
            "batch idx 50: | train loss: 0.5596345067024231 | train accu: 0.711\n",
            "batch idx 51: | train loss: 0.5815709829330444 | train accu: 0.648\n",
            "batch idx 52: | train loss: 0.5382184386253357 | train accu: 0.719\n",
            "batch idx 53: | train loss: 0.5524552464485168 | train accu: 0.727\n",
            "batch idx 54: | train loss: 0.4667391777038574 | train accu: 0.750\n",
            "batch idx 55: | train loss: 0.6114920973777771 | train accu: 0.680\n",
            "batch idx 56: | train loss: 0.6178242564201355 | train accu: 0.641\n",
            "batch idx 57: | train loss: 0.5857508182525635 | train accu: 0.672\n",
            "Epoch: 02 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.635 | Train Acc: 64.67%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 60.64%\n",
            "batch idx 0: | train loss: 0.6231705546379089 | train accu: 0.633\n",
            "batch idx 1: | train loss: 0.6415227055549622 | train accu: 0.625\n",
            "batch idx 2: | train loss: 0.6258530020713806 | train accu: 0.641\n",
            "batch idx 3: | train loss: 0.5748883485794067 | train accu: 0.672\n",
            "batch idx 4: | train loss: 0.6035474538803101 | train accu: 0.680\n",
            "batch idx 5: | train loss: 0.6086589694023132 | train accu: 0.648\n",
            "batch idx 6: | train loss: 0.5069797039031982 | train accu: 0.711\n",
            "batch idx 7: | train loss: 0.511395275592804 | train accu: 0.680\n",
            "batch idx 8: | train loss: 0.708351194858551 | train accu: 0.562\n",
            "batch idx 9: | train loss: 0.6138206124305725 | train accu: 0.641\n",
            "batch idx 10: | train loss: 0.5851888656616211 | train accu: 0.648\n",
            "batch idx 11: | train loss: 0.5956667065620422 | train accu: 0.680\n",
            "batch idx 12: | train loss: 0.5438013672828674 | train accu: 0.680\n",
            "batch idx 13: | train loss: 0.5735043287277222 | train accu: 0.648\n",
            "batch idx 14: | train loss: 0.5609139800071716 | train accu: 0.688\n",
            "batch idx 15: | train loss: 0.5731689929962158 | train accu: 0.711\n",
            "batch idx 16: | train loss: 0.5895892977714539 | train accu: 0.688\n",
            "batch idx 17: | train loss: 0.6261806488037109 | train accu: 0.688\n",
            "batch idx 18: | train loss: 0.5866006016731262 | train accu: 0.680\n",
            "batch idx 19: | train loss: 0.6507845520973206 | train accu: 0.602\n",
            "batch idx 20: | train loss: 0.6805345416069031 | train accu: 0.570\n",
            "batch idx 21: | train loss: 0.6206386089324951 | train accu: 0.617\n",
            "batch idx 22: | train loss: 0.6243118643760681 | train accu: 0.586\n",
            "batch idx 23: | train loss: 0.6142431497573853 | train accu: 0.680\n",
            "batch idx 24: | train loss: 0.6493899822235107 | train accu: 0.664\n",
            "batch idx 25: | train loss: 0.6184901595115662 | train accu: 0.680\n",
            "batch idx 26: | train loss: 0.47322702407836914 | train accu: 0.727\n",
            "batch idx 27: | train loss: 0.6773310899734497 | train accu: 0.609\n",
            "batch idx 28: | train loss: 0.608548641204834 | train accu: 0.664\n",
            "batch idx 29: | train loss: 0.7831087112426758 | train accu: 0.586\n",
            "batch idx 30: | train loss: 0.5690608024597168 | train accu: 0.633\n",
            "batch idx 31: | train loss: 0.6093118786811829 | train accu: 0.719\n",
            "batch idx 32: | train loss: 0.548382580280304 | train accu: 0.664\n",
            "batch idx 33: | train loss: 0.6191145777702332 | train accu: 0.727\n",
            "batch idx 34: | train loss: 0.5770074725151062 | train accu: 0.711\n",
            "batch idx 35: | train loss: 0.6125050783157349 | train accu: 0.695\n",
            "batch idx 36: | train loss: 0.5689907670021057 | train accu: 0.672\n",
            "batch idx 37: | train loss: 0.5642250180244446 | train accu: 0.664\n",
            "batch idx 38: | train loss: 0.626254677772522 | train accu: 0.633\n",
            "batch idx 39: | train loss: 0.5706119537353516 | train accu: 0.695\n",
            "batch idx 40: | train loss: 0.6630567908287048 | train accu: 0.625\n",
            "batch idx 41: | train loss: 0.5598957538604736 | train accu: 0.719\n",
            "batch idx 42: | train loss: 0.5310310125350952 | train accu: 0.711\n",
            "batch idx 43: | train loss: 0.5589420795440674 | train accu: 0.742\n",
            "batch idx 44: | train loss: 0.5346716046333313 | train accu: 0.734\n",
            "batch idx 45: | train loss: 0.6600984334945679 | train accu: 0.617\n",
            "batch idx 46: | train loss: 0.5999796390533447 | train accu: 0.680\n",
            "batch idx 47: | train loss: 0.5472931861877441 | train accu: 0.664\n",
            "batch idx 48: | train loss: 0.517611026763916 | train accu: 0.695\n",
            "batch idx 49: | train loss: 0.5563849210739136 | train accu: 0.719\n",
            "batch idx 50: | train loss: 0.5705291032791138 | train accu: 0.641\n",
            "batch idx 51: | train loss: 0.6009773015975952 | train accu: 0.656\n",
            "batch idx 52: | train loss: 0.5021919012069702 | train accu: 0.766\n",
            "batch idx 53: | train loss: 0.48028892278671265 | train accu: 0.750\n",
            "batch idx 54: | train loss: 0.5471973419189453 | train accu: 0.727\n",
            "batch idx 55: | train loss: 0.5768222212791443 | train accu: 0.703\n",
            "batch idx 56: | train loss: 0.5902628898620605 | train accu: 0.641\n",
            "batch idx 57: | train loss: 0.5663739442825317 | train accu: 0.727\n",
            "Epoch: 03 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.591 | Train Acc: 67.09%\n",
            "\t Val. Loss: 0.649 |  Val. Acc: 62.79%\n",
            "batch idx 0: | train loss: 0.5346892476081848 | train accu: 0.688\n",
            "batch idx 1: | train loss: 0.5187529921531677 | train accu: 0.734\n",
            "batch idx 2: | train loss: 0.5847464799880981 | train accu: 0.633\n",
            "batch idx 3: | train loss: 0.5681278705596924 | train accu: 0.656\n",
            "batch idx 4: | train loss: 0.5760108828544617 | train accu: 0.719\n",
            "batch idx 5: | train loss: 0.5597261190414429 | train accu: 0.656\n",
            "batch idx 6: | train loss: 0.6268866658210754 | train accu: 0.648\n",
            "batch idx 7: | train loss: 0.6018900275230408 | train accu: 0.641\n",
            "batch idx 8: | train loss: 0.5122262835502625 | train accu: 0.734\n",
            "batch idx 9: | train loss: 0.5930439233779907 | train accu: 0.680\n",
            "batch idx 10: | train loss: 0.620887041091919 | train accu: 0.664\n",
            "batch idx 11: | train loss: 0.5402076840400696 | train accu: 0.727\n",
            "batch idx 12: | train loss: 0.5378246307373047 | train accu: 0.680\n",
            "batch idx 13: | train loss: 0.653855562210083 | train accu: 0.609\n",
            "batch idx 14: | train loss: 0.5560092329978943 | train accu: 0.672\n",
            "batch idx 15: | train loss: 0.5630695223808289 | train accu: 0.648\n",
            "batch idx 16: | train loss: 0.6042120456695557 | train accu: 0.656\n",
            "batch idx 17: | train loss: 0.5149575471878052 | train accu: 0.742\n",
            "batch idx 18: | train loss: 0.5582740902900696 | train accu: 0.711\n",
            "batch idx 19: | train loss: 0.5889776349067688 | train accu: 0.680\n",
            "batch idx 20: | train loss: 0.5472075343132019 | train accu: 0.719\n",
            "batch idx 21: | train loss: 0.5599335432052612 | train accu: 0.680\n",
            "batch idx 22: | train loss: 0.5800963640213013 | train accu: 0.617\n",
            "batch idx 23: | train loss: 0.7123420834541321 | train accu: 0.602\n",
            "batch idx 24: | train loss: 0.5937258005142212 | train accu: 0.656\n",
            "batch idx 25: | train loss: 0.5351830720901489 | train accu: 0.703\n",
            "batch idx 26: | train loss: 0.543957531452179 | train accu: 0.664\n",
            "batch idx 27: | train loss: 0.6176037192344666 | train accu: 0.711\n",
            "batch idx 28: | train loss: 0.6565510034561157 | train accu: 0.617\n",
            "batch idx 29: | train loss: 0.5196930766105652 | train accu: 0.750\n",
            "batch idx 30: | train loss: 0.5866155028343201 | train accu: 0.664\n",
            "batch idx 31: | train loss: 0.4367012679576874 | train accu: 0.766\n",
            "batch idx 32: | train loss: 0.5660880208015442 | train accu: 0.672\n",
            "batch idx 33: | train loss: 0.7779435515403748 | train accu: 0.547\n",
            "batch idx 34: | train loss: 0.5738986730575562 | train accu: 0.664\n",
            "batch idx 35: | train loss: 0.6079496145248413 | train accu: 0.617\n",
            "batch idx 36: | train loss: 0.44087547063827515 | train accu: 0.781\n",
            "batch idx 37: | train loss: 0.5893223285675049 | train accu: 0.719\n",
            "batch idx 38: | train loss: 0.5177022218704224 | train accu: 0.750\n",
            "batch idx 39: | train loss: 0.5714663863182068 | train accu: 0.672\n",
            "batch idx 40: | train loss: 0.5890395045280457 | train accu: 0.680\n",
            "batch idx 41: | train loss: 0.6465041041374207 | train accu: 0.633\n",
            "batch idx 42: | train loss: 0.5208117961883545 | train accu: 0.727\n",
            "batch idx 43: | train loss: 0.5734045505523682 | train accu: 0.695\n",
            "batch idx 44: | train loss: 0.5415805578231812 | train accu: 0.742\n",
            "batch idx 45: | train loss: 0.5715544819831848 | train accu: 0.688\n",
            "batch idx 46: | train loss: 0.4953005611896515 | train accu: 0.727\n",
            "batch idx 47: | train loss: 0.5484803318977356 | train accu: 0.703\n",
            "batch idx 48: | train loss: 0.5564727783203125 | train accu: 0.703\n",
            "batch idx 49: | train loss: 0.43950384855270386 | train accu: 0.797\n",
            "batch idx 50: | train loss: 0.5469945669174194 | train accu: 0.734\n",
            "batch idx 51: | train loss: 0.5290902256965637 | train accu: 0.680\n",
            "batch idx 52: | train loss: 0.5851312279701233 | train accu: 0.672\n",
            "batch idx 53: | train loss: 0.5178169012069702 | train accu: 0.703\n",
            "batch idx 54: | train loss: 0.5407292246818542 | train accu: 0.688\n",
            "batch idx 55: | train loss: 0.5495789647102356 | train accu: 0.727\n",
            "batch idx 56: | train loss: 0.5163686871528625 | train accu: 0.695\n",
            "batch idx 57: | train loss: 0.5309371948242188 | train accu: 0.695\n",
            "Epoch: 04 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.565 | Train Acc: 68.68%\n",
            "\t Val. Loss: 0.604 |  Val. Acc: 66.06%\n",
            "batch idx 0: | train loss: 0.603912889957428 | train accu: 0.664\n",
            "batch idx 1: | train loss: 0.35952016711235046 | train accu: 0.828\n",
            "batch idx 2: | train loss: 0.6015286445617676 | train accu: 0.664\n",
            "batch idx 3: | train loss: 0.5065399408340454 | train accu: 0.695\n",
            "batch idx 4: | train loss: 0.5072377324104309 | train accu: 0.773\n",
            "batch idx 5: | train loss: 0.5084739327430725 | train accu: 0.680\n",
            "batch idx 6: | train loss: 0.6225017309188843 | train accu: 0.680\n",
            "batch idx 7: | train loss: 0.5401694178581238 | train accu: 0.703\n",
            "batch idx 8: | train loss: 0.5870323181152344 | train accu: 0.656\n",
            "batch idx 9: | train loss: 0.5443241596221924 | train accu: 0.680\n",
            "batch idx 10: | train loss: 0.5026183724403381 | train accu: 0.758\n",
            "batch idx 11: | train loss: 0.46384769678115845 | train accu: 0.766\n",
            "batch idx 12: | train loss: 0.5757385492324829 | train accu: 0.656\n",
            "batch idx 13: | train loss: 0.5288591980934143 | train accu: 0.734\n",
            "batch idx 14: | train loss: 0.6339765191078186 | train accu: 0.625\n",
            "batch idx 15: | train loss: 0.5004267692565918 | train accu: 0.773\n",
            "batch idx 16: | train loss: 0.5024862289428711 | train accu: 0.758\n",
            "batch idx 17: | train loss: 0.5424686670303345 | train accu: 0.688\n",
            "batch idx 18: | train loss: 0.5480684041976929 | train accu: 0.672\n",
            "batch idx 19: | train loss: 0.5818303227424622 | train accu: 0.688\n",
            "batch idx 20: | train loss: 0.5757167339324951 | train accu: 0.680\n",
            "batch idx 21: | train loss: 0.5769529342651367 | train accu: 0.680\n",
            "batch idx 22: | train loss: 0.5644206404685974 | train accu: 0.727\n",
            "batch idx 23: | train loss: 0.5567878484725952 | train accu: 0.742\n",
            "batch idx 24: | train loss: 0.5410335659980774 | train accu: 0.727\n",
            "batch idx 25: | train loss: 0.532848596572876 | train accu: 0.711\n",
            "batch idx 26: | train loss: 0.6308122277259827 | train accu: 0.656\n",
            "batch idx 27: | train loss: 0.5468577742576599 | train accu: 0.688\n",
            "batch idx 28: | train loss: 0.4553244113922119 | train accu: 0.750\n",
            "batch idx 29: | train loss: 0.46460840106010437 | train accu: 0.773\n",
            "batch idx 30: | train loss: 0.5281357765197754 | train accu: 0.742\n",
            "batch idx 31: | train loss: 0.4972867965698242 | train accu: 0.727\n",
            "batch idx 32: | train loss: 0.4341181516647339 | train accu: 0.836\n",
            "batch idx 33: | train loss: 0.548581600189209 | train accu: 0.734\n",
            "batch idx 34: | train loss: 0.46951547265052795 | train accu: 0.758\n",
            "batch idx 35: | train loss: 0.5177831649780273 | train accu: 0.734\n",
            "batch idx 36: | train loss: 0.5816370844841003 | train accu: 0.680\n",
            "batch idx 37: | train loss: 0.4590052664279938 | train accu: 0.695\n",
            "batch idx 38: | train loss: 0.5098879933357239 | train accu: 0.734\n",
            "batch idx 39: | train loss: 0.524652898311615 | train accu: 0.727\n",
            "batch idx 40: | train loss: 0.5872794985771179 | train accu: 0.625\n",
            "batch idx 41: | train loss: 0.6046993732452393 | train accu: 0.672\n",
            "batch idx 42: | train loss: 0.5274888277053833 | train accu: 0.750\n",
            "batch idx 43: | train loss: 0.500140905380249 | train accu: 0.781\n",
            "batch idx 44: | train loss: 0.509279727935791 | train accu: 0.758\n",
            "batch idx 45: | train loss: 0.48767873644828796 | train accu: 0.750\n",
            "batch idx 46: | train loss: 0.48676812648773193 | train accu: 0.766\n",
            "batch idx 47: | train loss: 0.5624071955680847 | train accu: 0.711\n",
            "batch idx 48: | train loss: 0.5419631600379944 | train accu: 0.688\n",
            "batch idx 49: | train loss: 0.5506755709648132 | train accu: 0.719\n",
            "batch idx 50: | train loss: 0.589133083820343 | train accu: 0.680\n",
            "batch idx 51: | train loss: 0.5024008750915527 | train accu: 0.734\n",
            "batch idx 52: | train loss: 0.5641362071037292 | train accu: 0.727\n",
            "batch idx 53: | train loss: 0.6597932577133179 | train accu: 0.625\n",
            "batch idx 54: | train loss: 0.5859886407852173 | train accu: 0.648\n",
            "batch idx 55: | train loss: 0.6316283941268921 | train accu: 0.672\n",
            "batch idx 56: | train loss: 0.4802600145339966 | train accu: 0.773\n",
            "batch idx 57: | train loss: 0.5057500600814819 | train accu: 0.773\n",
            "Epoch: 05 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.537 | Train Acc: 71.54%\n",
            "\t Val. Loss: 0.577 |  Val. Acc: 68.99%\n",
            "batch idx 0: | train loss: 0.5085146427154541 | train accu: 0.742\n",
            "batch idx 1: | train loss: 0.48247700929641724 | train accu: 0.742\n",
            "batch idx 2: | train loss: 0.4732789993286133 | train accu: 0.734\n",
            "batch idx 3: | train loss: 0.5145440697669983 | train accu: 0.750\n",
            "batch idx 4: | train loss: 0.5518269538879395 | train accu: 0.695\n",
            "batch idx 5: | train loss: 0.4468463659286499 | train accu: 0.766\n",
            "batch idx 6: | train loss: 0.5704745650291443 | train accu: 0.688\n",
            "batch idx 7: | train loss: 0.578420877456665 | train accu: 0.688\n",
            "batch idx 8: | train loss: 0.562364399433136 | train accu: 0.695\n",
            "batch idx 9: | train loss: 0.4352588653564453 | train accu: 0.789\n",
            "batch idx 10: | train loss: 0.45706966519355774 | train accu: 0.789\n",
            "batch idx 11: | train loss: 0.6064704656600952 | train accu: 0.688\n",
            "batch idx 12: | train loss: 0.48415622115135193 | train accu: 0.734\n",
            "batch idx 13: | train loss: 0.451132595539093 | train accu: 0.766\n",
            "batch idx 14: | train loss: 0.6450461745262146 | train accu: 0.594\n",
            "batch idx 15: | train loss: 0.5160750150680542 | train accu: 0.742\n",
            "batch idx 16: | train loss: 0.5092779994010925 | train accu: 0.688\n",
            "batch idx 17: | train loss: 0.5634530782699585 | train accu: 0.688\n",
            "batch idx 18: | train loss: 0.5971239805221558 | train accu: 0.625\n",
            "batch idx 19: | train loss: 0.49166178703308105 | train accu: 0.734\n",
            "batch idx 20: | train loss: 0.5356243848800659 | train accu: 0.688\n",
            "batch idx 21: | train loss: 0.4723581075668335 | train accu: 0.727\n",
            "batch idx 22: | train loss: 0.5853080749511719 | train accu: 0.703\n",
            "batch idx 23: | train loss: 0.5799258351325989 | train accu: 0.664\n",
            "batch idx 24: | train loss: 0.5726978182792664 | train accu: 0.703\n",
            "batch idx 25: | train loss: 0.6170039772987366 | train accu: 0.672\n",
            "batch idx 26: | train loss: 0.4808908998966217 | train accu: 0.750\n",
            "batch idx 27: | train loss: 0.5347509980201721 | train accu: 0.742\n",
            "batch idx 28: | train loss: 0.5015512108802795 | train accu: 0.742\n",
            "batch idx 29: | train loss: 0.5570601224899292 | train accu: 0.727\n",
            "batch idx 30: | train loss: 0.5334798693656921 | train accu: 0.758\n",
            "batch idx 31: | train loss: 0.5534385442733765 | train accu: 0.719\n",
            "batch idx 32: | train loss: 0.476613312959671 | train accu: 0.742\n",
            "batch idx 33: | train loss: 0.5949175953865051 | train accu: 0.633\n",
            "batch idx 34: | train loss: 0.4721147418022156 | train accu: 0.758\n",
            "batch idx 35: | train loss: 0.44275030493736267 | train accu: 0.812\n",
            "batch idx 36: | train loss: 0.5777329206466675 | train accu: 0.641\n",
            "batch idx 37: | train loss: 0.541991651058197 | train accu: 0.664\n",
            "batch idx 38: | train loss: 0.4213515520095825 | train accu: 0.781\n",
            "batch idx 39: | train loss: 0.5785909295082092 | train accu: 0.672\n",
            "batch idx 40: | train loss: 0.49538454413414 | train accu: 0.727\n",
            "batch idx 41: | train loss: 0.48808982968330383 | train accu: 0.727\n",
            "batch idx 42: | train loss: 0.5519697666168213 | train accu: 0.688\n",
            "batch idx 43: | train loss: 0.6065651178359985 | train accu: 0.656\n",
            "batch idx 44: | train loss: 0.5779422521591187 | train accu: 0.711\n",
            "batch idx 45: | train loss: 0.5572007894515991 | train accu: 0.664\n",
            "batch idx 46: | train loss: 0.5388648509979248 | train accu: 0.758\n",
            "batch idx 47: | train loss: 0.4231095612049103 | train accu: 0.789\n",
            "batch idx 48: | train loss: 0.5479961037635803 | train accu: 0.703\n",
            "batch idx 49: | train loss: 0.503401517868042 | train accu: 0.695\n",
            "batch idx 50: | train loss: 0.49682682752609253 | train accu: 0.695\n",
            "batch idx 51: | train loss: 0.5109007358551025 | train accu: 0.711\n",
            "batch idx 52: | train loss: 0.5318893790245056 | train accu: 0.695\n",
            "batch idx 53: | train loss: 0.5594176054000854 | train accu: 0.719\n",
            "batch idx 54: | train loss: 0.4150873124599457 | train accu: 0.773\n",
            "batch idx 55: | train loss: 0.4528215825557709 | train accu: 0.742\n",
            "batch idx 56: | train loss: 0.512462854385376 | train accu: 0.734\n",
            "batch idx 57: | train loss: 0.4756135642528534 | train accu: 0.727\n",
            "Epoch: 06 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.523 | Train Acc: 71.63%\n",
            "\t Val. Loss: 0.578 |  Val. Acc: 68.80%\n",
            "batch idx 0: | train loss: 0.5179455876350403 | train accu: 0.711\n",
            "batch idx 1: | train loss: 0.4864014983177185 | train accu: 0.781\n",
            "batch idx 2: | train loss: 0.6099106669425964 | train accu: 0.688\n",
            "batch idx 3: | train loss: 0.43868911266326904 | train accu: 0.773\n",
            "batch idx 4: | train loss: 0.5318965315818787 | train accu: 0.711\n",
            "batch idx 5: | train loss: 0.5700544714927673 | train accu: 0.656\n",
            "batch idx 6: | train loss: 0.6966955065727234 | train accu: 0.625\n",
            "batch idx 7: | train loss: 0.5658839344978333 | train accu: 0.680\n",
            "batch idx 8: | train loss: 0.5590386986732483 | train accu: 0.688\n",
            "batch idx 9: | train loss: 0.4819185435771942 | train accu: 0.758\n",
            "batch idx 10: | train loss: 0.6759023070335388 | train accu: 0.641\n",
            "batch idx 11: | train loss: 0.5028370022773743 | train accu: 0.781\n",
            "batch idx 12: | train loss: 0.5296620726585388 | train accu: 0.766\n",
            "batch idx 13: | train loss: 0.4596305787563324 | train accu: 0.789\n",
            "batch idx 14: | train loss: 0.4987752437591553 | train accu: 0.742\n",
            "batch idx 15: | train loss: 0.528365433216095 | train accu: 0.727\n",
            "batch idx 16: | train loss: 0.5115219950675964 | train accu: 0.695\n",
            "batch idx 17: | train loss: 0.5922956466674805 | train accu: 0.656\n",
            "batch idx 18: | train loss: 0.41231194138526917 | train accu: 0.797\n",
            "batch idx 19: | train loss: 0.5417932868003845 | train accu: 0.695\n",
            "batch idx 20: | train loss: 0.5520392656326294 | train accu: 0.742\n",
            "batch idx 21: | train loss: 0.5007663369178772 | train accu: 0.781\n",
            "batch idx 22: | train loss: 0.6097915768623352 | train accu: 0.688\n",
            "batch idx 23: | train loss: 0.5345726609230042 | train accu: 0.742\n",
            "batch idx 24: | train loss: 0.48800328373908997 | train accu: 0.703\n",
            "batch idx 25: | train loss: 0.5418099164962769 | train accu: 0.711\n",
            "batch idx 26: | train loss: 0.51078200340271 | train accu: 0.742\n",
            "batch idx 27: | train loss: 0.464057058095932 | train accu: 0.727\n",
            "batch idx 28: | train loss: 0.5192888379096985 | train accu: 0.719\n",
            "batch idx 29: | train loss: 0.5186951160430908 | train accu: 0.711\n",
            "batch idx 30: | train loss: 0.5700949430465698 | train accu: 0.703\n",
            "batch idx 31: | train loss: 0.5082897543907166 | train accu: 0.734\n",
            "batch idx 32: | train loss: 0.5344725847244263 | train accu: 0.742\n",
            "batch idx 33: | train loss: 0.4891655445098877 | train accu: 0.727\n",
            "batch idx 34: | train loss: 0.4789387285709381 | train accu: 0.797\n",
            "batch idx 35: | train loss: 0.4761601984500885 | train accu: 0.766\n",
            "batch idx 36: | train loss: 0.4566805362701416 | train accu: 0.766\n",
            "batch idx 37: | train loss: 0.47942930459976196 | train accu: 0.758\n",
            "batch idx 38: | train loss: 0.38987746834754944 | train accu: 0.867\n",
            "batch idx 39: | train loss: 0.536643385887146 | train accu: 0.734\n",
            "batch idx 40: | train loss: 0.6231200098991394 | train accu: 0.672\n",
            "batch idx 41: | train loss: 0.5248470306396484 | train accu: 0.719\n",
            "batch idx 42: | train loss: 0.533597469329834 | train accu: 0.703\n",
            "batch idx 43: | train loss: 0.475511759519577 | train accu: 0.719\n",
            "batch idx 44: | train loss: 0.4248400926589966 | train accu: 0.797\n",
            "batch idx 45: | train loss: 0.37987250089645386 | train accu: 0.766\n",
            "batch idx 46: | train loss: 0.4903828799724579 | train accu: 0.727\n",
            "batch idx 47: | train loss: 0.3996903896331787 | train accu: 0.773\n",
            "batch idx 48: | train loss: 0.5415183305740356 | train accu: 0.734\n",
            "batch idx 49: | train loss: 0.4614524841308594 | train accu: 0.781\n",
            "batch idx 50: | train loss: 0.5349203944206238 | train accu: 0.789\n",
            "batch idx 51: | train loss: 0.5010348558425903 | train accu: 0.727\n",
            "batch idx 52: | train loss: 0.4452146887779236 | train accu: 0.711\n",
            "batch idx 53: | train loss: 0.3944834768772125 | train accu: 0.773\n",
            "batch idx 54: | train loss: 0.5763066411018372 | train accu: 0.688\n",
            "batch idx 55: | train loss: 0.5133367776870728 | train accu: 0.703\n",
            "batch idx 56: | train loss: 0.43101948499679565 | train accu: 0.773\n",
            "batch idx 57: | train loss: 0.5523454546928406 | train accu: 0.695\n",
            "Epoch: 07 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.512 | Train Acc: 73.22%\n",
            "\t Val. Loss: 0.600 |  Val. Acc: 69.14%\n",
            "batch idx 0: | train loss: 0.46140816807746887 | train accu: 0.727\n",
            "batch idx 1: | train loss: 0.4684247672557831 | train accu: 0.750\n",
            "batch idx 2: | train loss: 0.49352455139160156 | train accu: 0.734\n",
            "batch idx 3: | train loss: 0.4548763930797577 | train accu: 0.766\n",
            "batch idx 4: | train loss: 0.5206451416015625 | train accu: 0.727\n",
            "batch idx 5: | train loss: 0.45228123664855957 | train accu: 0.812\n",
            "batch idx 6: | train loss: 0.5519900918006897 | train accu: 0.680\n",
            "batch idx 7: | train loss: 0.43855178356170654 | train accu: 0.773\n",
            "batch idx 8: | train loss: 0.5054766535758972 | train accu: 0.695\n",
            "batch idx 9: | train loss: 0.4487321972846985 | train accu: 0.750\n",
            "batch idx 10: | train loss: 0.4831162393093109 | train accu: 0.711\n",
            "batch idx 11: | train loss: 0.43211662769317627 | train accu: 0.789\n",
            "batch idx 12: | train loss: 0.5000443458557129 | train accu: 0.734\n",
            "batch idx 13: | train loss: 0.5049463510513306 | train accu: 0.750\n",
            "batch idx 14: | train loss: 0.5314518809318542 | train accu: 0.750\n",
            "batch idx 15: | train loss: 0.5007843971252441 | train accu: 0.703\n",
            "batch idx 16: | train loss: 0.5956611633300781 | train accu: 0.664\n",
            "batch idx 17: | train loss: 0.4281748831272125 | train accu: 0.781\n",
            "batch idx 18: | train loss: 0.473743736743927 | train accu: 0.766\n",
            "batch idx 19: | train loss: 0.4460866451263428 | train accu: 0.766\n",
            "batch idx 20: | train loss: 0.4899725914001465 | train accu: 0.781\n",
            "batch idx 21: | train loss: 0.5654921531677246 | train accu: 0.719\n",
            "batch idx 22: | train loss: 0.46608030796051025 | train accu: 0.758\n",
            "batch idx 23: | train loss: 0.4524555802345276 | train accu: 0.750\n",
            "batch idx 24: | train loss: 0.5638667941093445 | train accu: 0.664\n",
            "batch idx 25: | train loss: 0.4166891276836395 | train accu: 0.797\n",
            "batch idx 26: | train loss: 0.469044953584671 | train accu: 0.758\n",
            "batch idx 27: | train loss: 0.4770784378051758 | train accu: 0.758\n",
            "batch idx 28: | train loss: 0.35186687111854553 | train accu: 0.820\n",
            "batch idx 29: | train loss: 0.5022019147872925 | train accu: 0.742\n",
            "batch idx 30: | train loss: 0.41449207067489624 | train accu: 0.789\n",
            "batch idx 31: | train loss: 0.4187929928302765 | train accu: 0.805\n",
            "batch idx 32: | train loss: 0.5643348693847656 | train accu: 0.719\n",
            "batch idx 33: | train loss: 0.5020942091941833 | train accu: 0.742\n",
            "batch idx 34: | train loss: 0.5633957386016846 | train accu: 0.711\n",
            "batch idx 35: | train loss: 0.5987460017204285 | train accu: 0.672\n",
            "batch idx 36: | train loss: 0.4651656448841095 | train accu: 0.742\n",
            "batch idx 37: | train loss: 0.4424566626548767 | train accu: 0.797\n",
            "batch idx 38: | train loss: 0.5523676872253418 | train accu: 0.719\n",
            "batch idx 39: | train loss: 0.5230042934417725 | train accu: 0.734\n",
            "batch idx 40: | train loss: 0.5332744717597961 | train accu: 0.719\n",
            "batch idx 41: | train loss: 0.46396079659461975 | train accu: 0.766\n",
            "batch idx 42: | train loss: 0.5046981573104858 | train accu: 0.766\n",
            "batch idx 43: | train loss: 0.4821215569972992 | train accu: 0.766\n",
            "batch idx 44: | train loss: 0.5409590601921082 | train accu: 0.734\n",
            "batch idx 45: | train loss: 0.6517531871795654 | train accu: 0.664\n",
            "batch idx 46: | train loss: 0.5014297366142273 | train accu: 0.727\n",
            "batch idx 47: | train loss: 0.4746967554092407 | train accu: 0.750\n",
            "batch idx 48: | train loss: 0.5867748260498047 | train accu: 0.648\n",
            "batch idx 49: | train loss: 0.4751874804496765 | train accu: 0.773\n",
            "batch idx 50: | train loss: 0.5524324178695679 | train accu: 0.680\n",
            "batch idx 51: | train loss: 0.495933473110199 | train accu: 0.750\n",
            "batch idx 52: | train loss: 0.5697265863418579 | train accu: 0.656\n",
            "batch idx 53: | train loss: 0.47080790996551514 | train accu: 0.742\n",
            "batch idx 54: | train loss: 0.37115877866744995 | train accu: 0.805\n",
            "batch idx 55: | train loss: 0.4412420988082886 | train accu: 0.742\n",
            "batch idx 56: | train loss: 0.5941460728645325 | train accu: 0.656\n",
            "batch idx 57: | train loss: 0.5444568395614624 | train accu: 0.727\n",
            "Epoch: 08 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.496 | Train Acc: 73.92%\n",
            "\t Val. Loss: 0.614 |  Val. Acc: 68.36%\n",
            "batch idx 0: | train loss: 0.6717900037765503 | train accu: 0.656\n",
            "batch idx 1: | train loss: 0.4913943111896515 | train accu: 0.719\n",
            "batch idx 2: | train loss: 0.4737313985824585 | train accu: 0.758\n",
            "batch idx 3: | train loss: 0.4337218701839447 | train accu: 0.781\n",
            "batch idx 4: | train loss: 0.4751286208629608 | train accu: 0.734\n",
            "batch idx 5: | train loss: 0.46496841311454773 | train accu: 0.781\n",
            "batch idx 6: | train loss: 0.4447591006755829 | train accu: 0.797\n",
            "batch idx 7: | train loss: 0.4825400710105896 | train accu: 0.734\n",
            "batch idx 8: | train loss: 0.5206601023674011 | train accu: 0.727\n",
            "batch idx 9: | train loss: 0.43914875388145447 | train accu: 0.734\n",
            "batch idx 10: | train loss: 0.472104549407959 | train accu: 0.742\n",
            "batch idx 11: | train loss: 0.444800466299057 | train accu: 0.758\n",
            "batch idx 12: | train loss: 0.5397167205810547 | train accu: 0.695\n",
            "batch idx 13: | train loss: 0.49183598160743713 | train accu: 0.750\n",
            "batch idx 14: | train loss: 0.4736844301223755 | train accu: 0.773\n",
            "batch idx 15: | train loss: 0.4229411482810974 | train accu: 0.805\n",
            "batch idx 16: | train loss: 0.39739659428596497 | train accu: 0.812\n",
            "batch idx 17: | train loss: 0.4786125123500824 | train accu: 0.750\n",
            "batch idx 18: | train loss: 0.48517554998397827 | train accu: 0.742\n",
            "batch idx 19: | train loss: 0.4212343990802765 | train accu: 0.812\n",
            "batch idx 20: | train loss: 0.3215999901294708 | train accu: 0.805\n",
            "batch idx 21: | train loss: 0.5182581543922424 | train accu: 0.695\n",
            "batch idx 22: | train loss: 0.37301281094551086 | train accu: 0.781\n",
            "batch idx 23: | train loss: 0.41734758019447327 | train accu: 0.781\n",
            "batch idx 24: | train loss: 0.48311150074005127 | train accu: 0.750\n",
            "batch idx 25: | train loss: 0.38601019978523254 | train accu: 0.789\n",
            "batch idx 26: | train loss: 0.4641122817993164 | train accu: 0.758\n",
            "batch idx 27: | train loss: 0.4393940567970276 | train accu: 0.805\n",
            "batch idx 28: | train loss: 0.4800817370414734 | train accu: 0.758\n",
            "batch idx 29: | train loss: 0.49322620034217834 | train accu: 0.750\n",
            "batch idx 30: | train loss: 0.5287243723869324 | train accu: 0.711\n",
            "batch idx 31: | train loss: 0.4778680205345154 | train accu: 0.750\n",
            "batch idx 32: | train loss: 0.4671356678009033 | train accu: 0.711\n",
            "batch idx 33: | train loss: 0.48258060216903687 | train accu: 0.734\n",
            "batch idx 34: | train loss: 0.4409830570220947 | train accu: 0.734\n",
            "batch idx 35: | train loss: 0.39136382937431335 | train accu: 0.812\n",
            "batch idx 36: | train loss: 0.43813368678092957 | train accu: 0.789\n",
            "batch idx 37: | train loss: 0.4136928617954254 | train accu: 0.812\n",
            "batch idx 38: | train loss: 0.5315102934837341 | train accu: 0.703\n",
            "batch idx 39: | train loss: 0.48451024293899536 | train accu: 0.719\n",
            "batch idx 40: | train loss: 0.43411359190940857 | train accu: 0.742\n",
            "batch idx 41: | train loss: 0.4622534215450287 | train accu: 0.758\n",
            "batch idx 42: | train loss: 0.4220380187034607 | train accu: 0.750\n",
            "batch idx 43: | train loss: 0.5340474843978882 | train accu: 0.750\n",
            "batch idx 44: | train loss: 0.4967666268348694 | train accu: 0.750\n",
            "batch idx 45: | train loss: 0.48883554339408875 | train accu: 0.742\n",
            "batch idx 46: | train loss: 0.4277907609939575 | train accu: 0.750\n",
            "batch idx 47: | train loss: 0.5861116051673889 | train accu: 0.664\n",
            "batch idx 48: | train loss: 0.4848930835723877 | train accu: 0.766\n",
            "batch idx 49: | train loss: 0.40111303329467773 | train accu: 0.797\n",
            "batch idx 50: | train loss: 0.49364930391311646 | train accu: 0.750\n",
            "batch idx 51: | train loss: 0.5135165452957153 | train accu: 0.734\n",
            "batch idx 52: | train loss: 0.5079928636550903 | train accu: 0.719\n",
            "batch idx 53: | train loss: 0.48919376730918884 | train accu: 0.758\n",
            "batch idx 54: | train loss: 0.593441903591156 | train accu: 0.688\n",
            "batch idx 55: | train loss: 0.5229937434196472 | train accu: 0.703\n",
            "batch idx 56: | train loss: 0.5132063031196594 | train accu: 0.734\n",
            "batch idx 57: | train loss: 0.411539763212204 | train accu: 0.789\n",
            "Epoch: 09 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.471 | Train Acc: 75.09%\n",
            "\t Val. Loss: 0.601 |  Val. Acc: 68.36%\n",
            "batch idx 0: | train loss: 0.4587192237377167 | train accu: 0.758\n",
            "batch idx 1: | train loss: 0.42847740650177 | train accu: 0.805\n",
            "batch idx 2: | train loss: 0.5682579874992371 | train accu: 0.711\n",
            "batch idx 3: | train loss: 0.3854827582836151 | train accu: 0.836\n",
            "batch idx 4: | train loss: 0.3911501467227936 | train accu: 0.773\n",
            "batch idx 5: | train loss: 0.5413740277290344 | train accu: 0.688\n",
            "batch idx 6: | train loss: 0.45612385869026184 | train accu: 0.789\n",
            "batch idx 7: | train loss: 0.5032978653907776 | train accu: 0.711\n",
            "batch idx 8: | train loss: 0.42591527104377747 | train accu: 0.750\n",
            "batch idx 9: | train loss: 0.3651813268661499 | train accu: 0.805\n",
            "batch idx 10: | train loss: 0.4325319230556488 | train accu: 0.789\n",
            "batch idx 11: | train loss: 0.37349119782447815 | train accu: 0.836\n",
            "batch idx 12: | train loss: 0.44782355427742004 | train accu: 0.773\n",
            "batch idx 13: | train loss: 0.45535311102867126 | train accu: 0.773\n",
            "batch idx 14: | train loss: 0.5404971241950989 | train accu: 0.711\n",
            "batch idx 15: | train loss: 0.5051910281181335 | train accu: 0.734\n",
            "batch idx 16: | train loss: 0.5238946080207825 | train accu: 0.719\n",
            "batch idx 17: | train loss: 0.391063392162323 | train accu: 0.781\n",
            "batch idx 18: | train loss: 0.5763316750526428 | train accu: 0.719\n",
            "batch idx 19: | train loss: 0.40729930996894836 | train accu: 0.781\n",
            "batch idx 20: | train loss: 0.4043324887752533 | train accu: 0.812\n",
            "batch idx 21: | train loss: 0.4256073534488678 | train accu: 0.758\n",
            "batch idx 22: | train loss: 0.42650607228279114 | train accu: 0.812\n",
            "batch idx 23: | train loss: 0.5790047645568848 | train accu: 0.766\n",
            "batch idx 24: | train loss: 0.5026308298110962 | train accu: 0.750\n",
            "batch idx 25: | train loss: 0.49305054545402527 | train accu: 0.758\n",
            "batch idx 26: | train loss: 0.525780975818634 | train accu: 0.719\n",
            "batch idx 27: | train loss: 0.48485884070396423 | train accu: 0.742\n",
            "batch idx 28: | train loss: 0.5201215744018555 | train accu: 0.695\n",
            "batch idx 29: | train loss: 0.460455983877182 | train accu: 0.719\n",
            "batch idx 30: | train loss: 0.46599239110946655 | train accu: 0.773\n",
            "batch idx 31: | train loss: 0.47034910321235657 | train accu: 0.797\n",
            "batch idx 32: | train loss: 0.5081111788749695 | train accu: 0.750\n",
            "batch idx 33: | train loss: 0.4438071846961975 | train accu: 0.773\n",
            "batch idx 34: | train loss: 0.49851563572883606 | train accu: 0.719\n",
            "batch idx 35: | train loss: 0.3706539571285248 | train accu: 0.797\n",
            "batch idx 36: | train loss: 0.35586148500442505 | train accu: 0.805\n",
            "batch idx 37: | train loss: 0.4439137578010559 | train accu: 0.750\n",
            "batch idx 38: | train loss: 0.4465413987636566 | train accu: 0.758\n",
            "batch idx 39: | train loss: 0.42508623003959656 | train accu: 0.773\n",
            "batch idx 40: | train loss: 0.4166978895664215 | train accu: 0.773\n",
            "batch idx 41: | train loss: 0.4382343590259552 | train accu: 0.758\n",
            "batch idx 42: | train loss: 0.47861358523368835 | train accu: 0.727\n",
            "batch idx 43: | train loss: 0.49171268939971924 | train accu: 0.781\n",
            "batch idx 44: | train loss: 0.4637589156627655 | train accu: 0.766\n",
            "batch idx 45: | train loss: 0.38645139336586 | train accu: 0.773\n",
            "batch idx 46: | train loss: 0.3747496008872986 | train accu: 0.852\n",
            "batch idx 47: | train loss: 0.5160648822784424 | train accu: 0.742\n",
            "batch idx 48: | train loss: 0.49420633912086487 | train accu: 0.766\n",
            "batch idx 49: | train loss: 0.5828539133071899 | train accu: 0.688\n",
            "batch idx 50: | train loss: 0.41021206974983215 | train accu: 0.797\n",
            "batch idx 51: | train loss: 0.3982994556427002 | train accu: 0.789\n",
            "batch idx 52: | train loss: 0.41327542066574097 | train accu: 0.797\n",
            "batch idx 53: | train loss: 0.5195382237434387 | train accu: 0.688\n",
            "batch idx 54: | train loss: 0.5087915658950806 | train accu: 0.742\n",
            "batch idx 55: | train loss: 0.4243776798248291 | train accu: 0.758\n",
            "batch idx 56: | train loss: 0.423695832490921 | train accu: 0.766\n",
            "batch idx 57: | train loss: 0.4693591594696045 | train accu: 0.719\n",
            "Epoch: 10 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.459 | Train Acc: 76.12%\n",
            "\t Val. Loss: 0.629 |  Val. Acc: 67.68%\n",
            "batch idx 0: | train loss: 0.37686067819595337 | train accu: 0.805\n",
            "batch idx 1: | train loss: 0.5225324630737305 | train accu: 0.750\n",
            "batch idx 2: | train loss: 0.3997479975223541 | train accu: 0.812\n",
            "batch idx 3: | train loss: 0.45056360960006714 | train accu: 0.773\n",
            "batch idx 4: | train loss: 0.405335396528244 | train accu: 0.797\n",
            "batch idx 5: | train loss: 0.4012131094932556 | train accu: 0.789\n",
            "batch idx 6: | train loss: 0.3404824733734131 | train accu: 0.859\n",
            "batch idx 7: | train loss: 0.6728000640869141 | train accu: 0.656\n",
            "batch idx 8: | train loss: 0.3869318962097168 | train accu: 0.812\n",
            "batch idx 9: | train loss: 0.3952857255935669 | train accu: 0.781\n",
            "batch idx 10: | train loss: 0.37353214621543884 | train accu: 0.805\n",
            "batch idx 11: | train loss: 0.45691919326782227 | train accu: 0.742\n",
            "batch idx 12: | train loss: 0.461453378200531 | train accu: 0.812\n",
            "batch idx 13: | train loss: 0.5382969975471497 | train accu: 0.703\n",
            "batch idx 14: | train loss: 0.4402143955230713 | train accu: 0.805\n",
            "batch idx 15: | train loss: 0.36710280179977417 | train accu: 0.828\n",
            "batch idx 16: | train loss: 0.462832510471344 | train accu: 0.781\n",
            "batch idx 17: | train loss: 0.4286339581012726 | train accu: 0.750\n",
            "batch idx 18: | train loss: 0.4276118874549866 | train accu: 0.797\n",
            "batch idx 19: | train loss: 0.40410834550857544 | train accu: 0.766\n",
            "batch idx 20: | train loss: 0.43201950192451477 | train accu: 0.742\n",
            "batch idx 21: | train loss: 0.45046597719192505 | train accu: 0.742\n",
            "batch idx 22: | train loss: 0.37377381324768066 | train accu: 0.828\n",
            "batch idx 23: | train loss: 0.34937211871147156 | train accu: 0.805\n",
            "batch idx 24: | train loss: 0.5216081738471985 | train accu: 0.711\n",
            "batch idx 25: | train loss: 0.35562920570373535 | train accu: 0.812\n",
            "batch idx 26: | train loss: 0.35522761940956116 | train accu: 0.820\n",
            "batch idx 27: | train loss: 0.47880423069000244 | train accu: 0.781\n",
            "batch idx 28: | train loss: 0.5355172157287598 | train accu: 0.742\n",
            "batch idx 29: | train loss: 0.41374072432518005 | train accu: 0.781\n",
            "batch idx 30: | train loss: 0.5219963192939758 | train accu: 0.711\n",
            "batch idx 31: | train loss: 0.534362256526947 | train accu: 0.672\n",
            "batch idx 32: | train loss: 0.3796198070049286 | train accu: 0.734\n",
            "batch idx 33: | train loss: 0.4675108790397644 | train accu: 0.750\n",
            "batch idx 34: | train loss: 0.5197843313217163 | train accu: 0.680\n",
            "batch idx 35: | train loss: 0.4341132938861847 | train accu: 0.773\n",
            "batch idx 36: | train loss: 0.42292413115501404 | train accu: 0.781\n",
            "batch idx 37: | train loss: 0.4649293124675751 | train accu: 0.781\n",
            "batch idx 38: | train loss: 0.5300511121749878 | train accu: 0.742\n",
            "batch idx 39: | train loss: 0.4436953365802765 | train accu: 0.789\n",
            "batch idx 40: | train loss: 0.4555250406265259 | train accu: 0.750\n",
            "batch idx 41: | train loss: 0.48122626543045044 | train accu: 0.758\n",
            "batch idx 42: | train loss: 0.5019367933273315 | train accu: 0.742\n",
            "batch idx 43: | train loss: 0.474372535943985 | train accu: 0.711\n",
            "batch idx 44: | train loss: 0.561398983001709 | train accu: 0.711\n",
            "batch idx 45: | train loss: 0.36525723338127136 | train accu: 0.820\n",
            "batch idx 46: | train loss: 0.3964172303676605 | train accu: 0.781\n",
            "batch idx 47: | train loss: 0.43262919783592224 | train accu: 0.766\n",
            "batch idx 48: | train loss: 0.47416847944259644 | train accu: 0.797\n",
            "batch idx 49: | train loss: 0.4171917140483856 | train accu: 0.781\n",
            "batch idx 50: | train loss: 0.5452324151992798 | train accu: 0.742\n",
            "batch idx 51: | train loss: 0.30746668577194214 | train accu: 0.844\n",
            "batch idx 52: | train loss: 0.5099689960479736 | train accu: 0.742\n",
            "batch idx 53: | train loss: 0.4979132115840912 | train accu: 0.766\n",
            "batch idx 54: | train loss: 0.4169773459434509 | train accu: 0.773\n",
            "batch idx 55: | train loss: 0.43278393149375916 | train accu: 0.781\n",
            "batch idx 56: | train loss: 0.462372362613678 | train accu: 0.750\n",
            "batch idx 57: | train loss: 0.4999799430370331 | train accu: 0.742\n",
            "Epoch: 11 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.447 | Train Acc: 76.83%\n",
            "\t Val. Loss: 0.603 |  Val. Acc: 68.95%\n",
            "batch idx 0: | train loss: 0.41443052887916565 | train accu: 0.836\n",
            "batch idx 1: | train loss: 0.42477551102638245 | train accu: 0.758\n",
            "batch idx 2: | train loss: 0.48340246081352234 | train accu: 0.766\n",
            "batch idx 3: | train loss: 0.4357682764530182 | train accu: 0.789\n",
            "batch idx 4: | train loss: 0.4803711175918579 | train accu: 0.781\n",
            "batch idx 5: | train loss: 0.4189341068267822 | train accu: 0.812\n",
            "batch idx 6: | train loss: 0.32789847254753113 | train accu: 0.836\n",
            "batch idx 7: | train loss: 0.37093475461006165 | train accu: 0.812\n",
            "batch idx 8: | train loss: 0.34971296787261963 | train accu: 0.836\n",
            "batch idx 9: | train loss: 0.43467211723327637 | train accu: 0.773\n",
            "batch idx 10: | train loss: 0.3662464916706085 | train accu: 0.844\n",
            "batch idx 11: | train loss: 0.4153912365436554 | train accu: 0.766\n",
            "batch idx 12: | train loss: 0.38875794410705566 | train accu: 0.812\n",
            "batch idx 13: | train loss: 0.39499494433403015 | train accu: 0.812\n",
            "batch idx 14: | train loss: 0.4202796220779419 | train accu: 0.734\n",
            "batch idx 15: | train loss: 0.40886878967285156 | train accu: 0.789\n",
            "batch idx 16: | train loss: 0.4350605309009552 | train accu: 0.805\n",
            "batch idx 17: | train loss: 0.3013208508491516 | train accu: 0.875\n",
            "batch idx 18: | train loss: 0.46551600098609924 | train accu: 0.773\n",
            "batch idx 19: | train loss: 0.4880612790584564 | train accu: 0.750\n",
            "batch idx 20: | train loss: 0.45978784561157227 | train accu: 0.758\n",
            "batch idx 21: | train loss: 0.34417739510536194 | train accu: 0.852\n",
            "batch idx 22: | train loss: 0.37404394149780273 | train accu: 0.828\n",
            "batch idx 23: | train loss: 0.4634336829185486 | train accu: 0.727\n",
            "batch idx 24: | train loss: 0.40683987736701965 | train accu: 0.789\n",
            "batch idx 25: | train loss: 0.3698303997516632 | train accu: 0.859\n",
            "batch idx 26: | train loss: 0.5248941779136658 | train accu: 0.766\n",
            "batch idx 27: | train loss: 0.4544351100921631 | train accu: 0.773\n",
            "batch idx 28: | train loss: 0.5295911431312561 | train accu: 0.695\n",
            "batch idx 29: | train loss: 0.42096608877182007 | train accu: 0.758\n",
            "batch idx 30: | train loss: 0.5163682699203491 | train accu: 0.695\n",
            "batch idx 31: | train loss: 0.39293453097343445 | train accu: 0.781\n",
            "batch idx 32: | train loss: 0.4518374800682068 | train accu: 0.766\n",
            "batch idx 33: | train loss: 0.537525475025177 | train accu: 0.734\n",
            "batch idx 34: | train loss: 0.41934362053871155 | train accu: 0.773\n",
            "batch idx 35: | train loss: 0.3709565997123718 | train accu: 0.844\n",
            "batch idx 36: | train loss: 0.49477726221084595 | train accu: 0.781\n",
            "batch idx 37: | train loss: 0.44301164150238037 | train accu: 0.758\n",
            "batch idx 38: | train loss: 0.4815438687801361 | train accu: 0.734\n",
            "batch idx 39: | train loss: 0.43585652112960815 | train accu: 0.734\n",
            "batch idx 40: | train loss: 0.4057285785675049 | train accu: 0.742\n",
            "batch idx 41: | train loss: 0.4174443185329437 | train accu: 0.805\n",
            "batch idx 42: | train loss: 0.42144110798835754 | train accu: 0.758\n",
            "batch idx 43: | train loss: 0.42404019832611084 | train accu: 0.797\n",
            "batch idx 44: | train loss: 0.3944624960422516 | train accu: 0.820\n",
            "batch idx 45: | train loss: 0.3610111176967621 | train accu: 0.812\n",
            "batch idx 46: | train loss: 0.48648178577423096 | train accu: 0.719\n",
            "batch idx 47: | train loss: 0.33832067251205444 | train accu: 0.844\n",
            "batch idx 48: | train loss: 0.39831840991973877 | train accu: 0.828\n",
            "batch idx 49: | train loss: 0.40890270471572876 | train accu: 0.797\n",
            "batch idx 50: | train loss: 0.49532225728034973 | train accu: 0.742\n",
            "batch idx 51: | train loss: 0.43105700612068176 | train accu: 0.789\n",
            "batch idx 52: | train loss: 0.35326558351516724 | train accu: 0.805\n",
            "batch idx 53: | train loss: 0.35332587361335754 | train accu: 0.789\n",
            "batch idx 54: | train loss: 0.32785311341285706 | train accu: 0.828\n",
            "batch idx 55: | train loss: 0.36792850494384766 | train accu: 0.805\n",
            "batch idx 56: | train loss: 0.3392608165740967 | train accu: 0.820\n",
            "batch idx 57: | train loss: 0.3948499858379364 | train accu: 0.781\n",
            "Epoch: 12 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.418 | Train Acc: 78.70%\n",
            "\t Val. Loss: 0.610 |  Val. Acc: 70.02%\n",
            "batch idx 0: | train loss: 0.4137222468852997 | train accu: 0.812\n",
            "batch idx 1: | train loss: 0.39407336711883545 | train accu: 0.797\n",
            "batch idx 2: | train loss: 0.37431326508522034 | train accu: 0.766\n",
            "batch idx 3: | train loss: 0.40217626094818115 | train accu: 0.797\n",
            "batch idx 4: | train loss: 0.35976752638816833 | train accu: 0.859\n",
            "batch idx 5: | train loss: 0.35998329520225525 | train accu: 0.820\n",
            "batch idx 6: | train loss: 0.39397409558296204 | train accu: 0.781\n",
            "batch idx 7: | train loss: 0.3970786929130554 | train accu: 0.758\n",
            "batch idx 8: | train loss: 0.3399324417114258 | train accu: 0.805\n",
            "batch idx 9: | train loss: 0.46769818663597107 | train accu: 0.773\n",
            "batch idx 10: | train loss: 0.34959322214126587 | train accu: 0.828\n",
            "batch idx 11: | train loss: 0.40947872400283813 | train accu: 0.805\n",
            "batch idx 12: | train loss: 0.3046310842037201 | train accu: 0.836\n",
            "batch idx 13: | train loss: 0.3428874611854553 | train accu: 0.820\n",
            "batch idx 14: | train loss: 0.43150594830513 | train accu: 0.758\n",
            "batch idx 15: | train loss: 0.4047529697418213 | train accu: 0.812\n",
            "batch idx 16: | train loss: 0.4424568712711334 | train accu: 0.797\n",
            "batch idx 17: | train loss: 0.3860584497451782 | train accu: 0.820\n",
            "batch idx 18: | train loss: 0.3129231929779053 | train accu: 0.867\n",
            "batch idx 19: | train loss: 0.37052810192108154 | train accu: 0.812\n",
            "batch idx 20: | train loss: 0.3816550076007843 | train accu: 0.805\n",
            "batch idx 21: | train loss: 0.379245400428772 | train accu: 0.812\n",
            "batch idx 22: | train loss: 0.28673163056373596 | train accu: 0.820\n",
            "batch idx 23: | train loss: 0.4687722325325012 | train accu: 0.750\n",
            "batch idx 24: | train loss: 0.3670625686645508 | train accu: 0.836\n",
            "batch idx 25: | train loss: 0.4582955241203308 | train accu: 0.781\n",
            "batch idx 26: | train loss: 0.42651790380477905 | train accu: 0.797\n",
            "batch idx 27: | train loss: 0.3720925450325012 | train accu: 0.812\n",
            "batch idx 28: | train loss: 0.4529455602169037 | train accu: 0.766\n",
            "batch idx 29: | train loss: 0.5753583312034607 | train accu: 0.695\n",
            "batch idx 30: | train loss: 0.3751910924911499 | train accu: 0.797\n",
            "batch idx 31: | train loss: 0.3285074532032013 | train accu: 0.828\n",
            "batch idx 32: | train loss: 0.4832785129547119 | train accu: 0.773\n",
            "batch idx 33: | train loss: 0.43858861923217773 | train accu: 0.781\n",
            "batch idx 34: | train loss: 0.40164053440093994 | train accu: 0.820\n",
            "batch idx 35: | train loss: 0.4137028455734253 | train accu: 0.805\n",
            "batch idx 36: | train loss: 0.33391666412353516 | train accu: 0.828\n",
            "batch idx 37: | train loss: 0.3668126165866852 | train accu: 0.820\n",
            "batch idx 38: | train loss: 0.5050621628761292 | train accu: 0.695\n",
            "batch idx 39: | train loss: 0.44409364461898804 | train accu: 0.719\n",
            "batch idx 40: | train loss: 0.3456582725048065 | train accu: 0.859\n",
            "batch idx 41: | train loss: 0.4182834029197693 | train accu: 0.797\n",
            "batch idx 42: | train loss: 0.47781726717948914 | train accu: 0.781\n",
            "batch idx 43: | train loss: 0.5115926265716553 | train accu: 0.719\n",
            "batch idx 44: | train loss: 0.392372727394104 | train accu: 0.773\n",
            "batch idx 45: | train loss: 0.3717096745967865 | train accu: 0.820\n",
            "batch idx 46: | train loss: 0.42535263299942017 | train accu: 0.797\n",
            "batch idx 47: | train loss: 0.37442222237586975 | train accu: 0.828\n",
            "batch idx 48: | train loss: 0.4182497262954712 | train accu: 0.828\n",
            "batch idx 49: | train loss: 0.3700943887233734 | train accu: 0.797\n",
            "batch idx 50: | train loss: 0.4052570164203644 | train accu: 0.734\n",
            "batch idx 51: | train loss: 0.3678354322910309 | train accu: 0.789\n",
            "batch idx 52: | train loss: 0.38088956475257874 | train accu: 0.789\n",
            "batch idx 53: | train loss: 0.4100469648838043 | train accu: 0.750\n",
            "batch idx 54: | train loss: 0.3506219983100891 | train accu: 0.781\n",
            "batch idx 55: | train loss: 0.4607749879360199 | train accu: 0.789\n",
            "batch idx 56: | train loss: 0.5006103515625 | train accu: 0.766\n",
            "batch idx 57: | train loss: 0.3789568543434143 | train accu: 0.789\n",
            "Epoch: 13 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.401 | Train Acc: 79.40%\n",
            "\t Val. Loss: 0.690 |  Val. Acc: 67.63%\n",
            "batch idx 0: | train loss: 0.34266579151153564 | train accu: 0.844\n",
            "batch idx 1: | train loss: 0.4351814389228821 | train accu: 0.773\n",
            "batch idx 2: | train loss: 0.4220094680786133 | train accu: 0.734\n",
            "batch idx 3: | train loss: 0.384775310754776 | train accu: 0.836\n",
            "batch idx 4: | train loss: 0.4258732199668884 | train accu: 0.758\n",
            "batch idx 5: | train loss: 0.35315579175949097 | train accu: 0.859\n",
            "batch idx 6: | train loss: 0.3636288344860077 | train accu: 0.820\n",
            "batch idx 7: | train loss: 0.4120997190475464 | train accu: 0.820\n",
            "batch idx 8: | train loss: 0.40891003608703613 | train accu: 0.797\n",
            "batch idx 9: | train loss: 0.36290064454078674 | train accu: 0.805\n",
            "batch idx 10: | train loss: 0.4462663233280182 | train accu: 0.773\n",
            "batch idx 11: | train loss: 0.2990368902683258 | train accu: 0.891\n",
            "batch idx 12: | train loss: 0.40353578329086304 | train accu: 0.828\n",
            "batch idx 13: | train loss: 0.3442351520061493 | train accu: 0.852\n",
            "batch idx 14: | train loss: 0.40404975414276123 | train accu: 0.789\n",
            "batch idx 15: | train loss: 0.3281186819076538 | train accu: 0.844\n",
            "batch idx 16: | train loss: 0.3461645245552063 | train accu: 0.836\n",
            "batch idx 17: | train loss: 0.37880319356918335 | train accu: 0.789\n",
            "batch idx 18: | train loss: 0.3279644846916199 | train accu: 0.820\n",
            "batch idx 19: | train loss: 0.34106138348579407 | train accu: 0.789\n",
            "batch idx 20: | train loss: 0.539209246635437 | train accu: 0.703\n",
            "batch idx 21: | train loss: 0.36639082431793213 | train accu: 0.844\n",
            "batch idx 22: | train loss: 0.3127328157424927 | train accu: 0.836\n",
            "batch idx 23: | train loss: 0.40163454413414 | train accu: 0.797\n",
            "batch idx 24: | train loss: 0.3639598786830902 | train accu: 0.812\n",
            "batch idx 25: | train loss: 0.36868318915367126 | train accu: 0.789\n",
            "batch idx 26: | train loss: 0.4309650659561157 | train accu: 0.789\n",
            "batch idx 27: | train loss: 0.33844733238220215 | train accu: 0.852\n",
            "batch idx 28: | train loss: 0.38911154866218567 | train accu: 0.820\n",
            "batch idx 29: | train loss: 0.352836936712265 | train accu: 0.828\n",
            "batch idx 30: | train loss: 0.4638168215751648 | train accu: 0.766\n",
            "batch idx 31: | train loss: 0.41412025690078735 | train accu: 0.797\n",
            "batch idx 32: | train loss: 0.35725000500679016 | train accu: 0.844\n",
            "batch idx 33: | train loss: 0.33867064118385315 | train accu: 0.820\n",
            "batch idx 34: | train loss: 0.44198718667030334 | train accu: 0.758\n",
            "batch idx 35: | train loss: 0.3452737331390381 | train accu: 0.812\n",
            "batch idx 36: | train loss: 0.4669913649559021 | train accu: 0.734\n",
            "batch idx 37: | train loss: 0.3266066014766693 | train accu: 0.766\n",
            "batch idx 38: | train loss: 0.3341020941734314 | train accu: 0.828\n",
            "batch idx 39: | train loss: 0.30349764227867126 | train accu: 0.875\n",
            "batch idx 40: | train loss: 0.393598347902298 | train accu: 0.797\n",
            "batch idx 41: | train loss: 0.3779562711715698 | train accu: 0.789\n",
            "batch idx 42: | train loss: 0.4762270152568817 | train accu: 0.766\n",
            "batch idx 43: | train loss: 0.36389872431755066 | train accu: 0.789\n",
            "batch idx 44: | train loss: 0.3531045913696289 | train accu: 0.836\n",
            "batch idx 45: | train loss: 0.3786047697067261 | train accu: 0.789\n",
            "batch idx 46: | train loss: 0.25086167454719543 | train accu: 0.859\n",
            "batch idx 47: | train loss: 0.3201422393321991 | train accu: 0.859\n",
            "batch idx 48: | train loss: 0.3971419930458069 | train accu: 0.797\n",
            "batch idx 49: | train loss: 0.42092689871788025 | train accu: 0.797\n",
            "batch idx 50: | train loss: 0.3815723657608032 | train accu: 0.836\n",
            "batch idx 51: | train loss: 0.40801557898521423 | train accu: 0.758\n",
            "batch idx 52: | train loss: 0.36577796936035156 | train accu: 0.805\n",
            "batch idx 53: | train loss: 0.4591316878795624 | train accu: 0.781\n",
            "batch idx 54: | train loss: 0.3615815341472626 | train accu: 0.805\n",
            "batch idx 55: | train loss: 0.3060416281223297 | train accu: 0.820\n",
            "batch idx 56: | train loss: 0.29356250166893005 | train accu: 0.852\n",
            "batch idx 57: | train loss: 0.40046560764312744 | train accu: 0.820\n",
            "Epoch: 14 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.378 | Train Acc: 80.83%\n",
            "\t Val. Loss: 0.645 |  Val. Acc: 70.61%\n",
            "batch idx 0: | train loss: 0.29528072476387024 | train accu: 0.875\n",
            "batch idx 1: | train loss: 0.23149389028549194 | train accu: 0.867\n",
            "batch idx 2: | train loss: 0.3359676003456116 | train accu: 0.805\n",
            "batch idx 3: | train loss: 0.30112648010253906 | train accu: 0.836\n",
            "batch idx 4: | train loss: 0.35332369804382324 | train accu: 0.828\n",
            "batch idx 5: | train loss: 0.34535497426986694 | train accu: 0.805\n",
            "batch idx 6: | train loss: 0.32777664065361023 | train accu: 0.820\n",
            "batch idx 7: | train loss: 0.30631503462791443 | train accu: 0.852\n",
            "batch idx 8: | train loss: 0.28867781162261963 | train accu: 0.875\n",
            "batch idx 9: | train loss: 0.3383108377456665 | train accu: 0.836\n",
            "batch idx 10: | train loss: 0.3762626647949219 | train accu: 0.781\n",
            "batch idx 11: | train loss: 0.3175244629383087 | train accu: 0.852\n",
            "batch idx 12: | train loss: 0.38877183198928833 | train accu: 0.805\n",
            "batch idx 13: | train loss: 0.34701186418533325 | train accu: 0.820\n",
            "batch idx 14: | train loss: 0.3811327815055847 | train accu: 0.812\n",
            "batch idx 15: | train loss: 0.32290399074554443 | train accu: 0.836\n",
            "batch idx 16: | train loss: 0.35645097494125366 | train accu: 0.812\n",
            "batch idx 17: | train loss: 0.28916749358177185 | train accu: 0.852\n",
            "batch idx 18: | train loss: 0.33321648836135864 | train accu: 0.805\n",
            "batch idx 19: | train loss: 0.36342722177505493 | train accu: 0.789\n",
            "batch idx 20: | train loss: 0.28424936532974243 | train accu: 0.852\n",
            "batch idx 21: | train loss: 0.35297462344169617 | train accu: 0.844\n",
            "batch idx 22: | train loss: 0.32862675189971924 | train accu: 0.859\n",
            "batch idx 23: | train loss: 0.4158172607421875 | train accu: 0.797\n",
            "batch idx 24: | train loss: 0.3663475811481476 | train accu: 0.836\n",
            "batch idx 25: | train loss: 0.3902576267719269 | train accu: 0.820\n",
            "batch idx 26: | train loss: 0.48515352606773376 | train accu: 0.789\n",
            "batch idx 27: | train loss: 0.23449264466762543 | train accu: 0.891\n",
            "batch idx 28: | train loss: 0.3775499165058136 | train accu: 0.766\n",
            "batch idx 29: | train loss: 0.3894498944282532 | train accu: 0.836\n",
            "batch idx 30: | train loss: 0.3301068842411041 | train accu: 0.828\n",
            "batch idx 31: | train loss: 0.37417736649513245 | train accu: 0.781\n",
            "batch idx 32: | train loss: 0.3230118155479431 | train accu: 0.844\n",
            "batch idx 33: | train loss: 0.33246245980262756 | train accu: 0.844\n",
            "batch idx 34: | train loss: 0.32709550857543945 | train accu: 0.820\n",
            "batch idx 35: | train loss: 0.303925096988678 | train accu: 0.844\n",
            "batch idx 36: | train loss: 0.3426179885864258 | train accu: 0.836\n",
            "batch idx 37: | train loss: 0.40500447154045105 | train accu: 0.812\n",
            "batch idx 38: | train loss: 0.30885204672813416 | train accu: 0.875\n",
            "batch idx 39: | train loss: 0.3596620559692383 | train accu: 0.797\n",
            "batch idx 40: | train loss: 0.38586515188217163 | train accu: 0.797\n",
            "batch idx 41: | train loss: 0.46315011382102966 | train accu: 0.773\n",
            "batch idx 42: | train loss: 0.3571302592754364 | train accu: 0.820\n",
            "batch idx 43: | train loss: 0.35571780800819397 | train accu: 0.797\n",
            "batch idx 44: | train loss: 0.45854589343070984 | train accu: 0.742\n",
            "batch idx 45: | train loss: 0.36685076355934143 | train accu: 0.828\n",
            "batch idx 46: | train loss: 0.3979211151599884 | train accu: 0.812\n",
            "batch idx 47: | train loss: 0.34016501903533936 | train accu: 0.828\n",
            "batch idx 48: | train loss: 0.4645756185054779 | train accu: 0.789\n",
            "batch idx 49: | train loss: 0.40699562430381775 | train accu: 0.812\n",
            "batch idx 50: | train loss: 0.40922248363494873 | train accu: 0.820\n",
            "batch idx 51: | train loss: 0.37704795598983765 | train accu: 0.836\n",
            "batch idx 52: | train loss: 0.3054113984107971 | train accu: 0.859\n",
            "batch idx 53: | train loss: 0.34662240743637085 | train accu: 0.812\n",
            "batch idx 54: | train loss: 0.4222099483013153 | train accu: 0.773\n",
            "batch idx 55: | train loss: 0.3672890067100525 | train accu: 0.812\n",
            "batch idx 56: | train loss: 0.306932657957077 | train accu: 0.844\n",
            "batch idx 57: | train loss: 0.3053889572620392 | train accu: 0.867\n",
            "Epoch: 15 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.353 | Train Acc: 82.34%\n",
            "\t Val. Loss: 0.647 |  Val. Acc: 69.29%\n",
            "batch idx 0: | train loss: 0.36288881301879883 | train accu: 0.805\n",
            "batch idx 1: | train loss: 0.3343944549560547 | train accu: 0.844\n",
            "batch idx 2: | train loss: 0.20626027882099152 | train accu: 0.914\n",
            "batch idx 3: | train loss: 0.2739480137825012 | train accu: 0.883\n",
            "batch idx 4: | train loss: 0.2832971513271332 | train accu: 0.859\n",
            "batch idx 5: | train loss: 0.31736093759536743 | train accu: 0.812\n",
            "batch idx 6: | train loss: 0.2722190022468567 | train accu: 0.852\n",
            "batch idx 7: | train loss: 0.35644853115081787 | train accu: 0.781\n",
            "batch idx 8: | train loss: 0.33619189262390137 | train accu: 0.820\n",
            "batch idx 9: | train loss: 0.3311450481414795 | train accu: 0.836\n",
            "batch idx 10: | train loss: 0.2897402346134186 | train accu: 0.859\n",
            "batch idx 11: | train loss: 0.2518017292022705 | train accu: 0.875\n",
            "batch idx 12: | train loss: 0.4110149145126343 | train accu: 0.766\n",
            "batch idx 13: | train loss: 0.31936395168304443 | train accu: 0.844\n",
            "batch idx 14: | train loss: 0.40660449862480164 | train accu: 0.773\n",
            "batch idx 15: | train loss: 0.28688734769821167 | train accu: 0.875\n",
            "batch idx 16: | train loss: 0.34573841094970703 | train accu: 0.812\n",
            "batch idx 17: | train loss: 0.39502280950546265 | train accu: 0.789\n",
            "batch idx 18: | train loss: 0.24974164366722107 | train accu: 0.891\n",
            "batch idx 19: | train loss: 0.3617652952671051 | train accu: 0.812\n",
            "batch idx 20: | train loss: 0.29981932044029236 | train accu: 0.859\n",
            "batch idx 21: | train loss: 0.32391467690467834 | train accu: 0.789\n",
            "batch idx 22: | train loss: 0.352887898683548 | train accu: 0.828\n",
            "batch idx 23: | train loss: 0.33695536851882935 | train accu: 0.867\n",
            "batch idx 24: | train loss: 0.3583393096923828 | train accu: 0.844\n",
            "batch idx 25: | train loss: 0.30130717158317566 | train accu: 0.875\n",
            "batch idx 26: | train loss: 0.21715569496154785 | train accu: 0.914\n",
            "batch idx 27: | train loss: 0.3420535922050476 | train accu: 0.820\n",
            "batch idx 28: | train loss: 0.3594191372394562 | train accu: 0.773\n",
            "batch idx 29: | train loss: 0.3150998055934906 | train accu: 0.828\n",
            "batch idx 30: | train loss: 0.39737990498542786 | train accu: 0.797\n",
            "batch idx 31: | train loss: 0.2815866470336914 | train accu: 0.836\n",
            "batch idx 32: | train loss: 0.3386906385421753 | train accu: 0.797\n",
            "batch idx 33: | train loss: 0.2923790514469147 | train accu: 0.812\n",
            "batch idx 34: | train loss: 0.31308332085609436 | train accu: 0.828\n",
            "batch idx 35: | train loss: 0.3601090610027313 | train accu: 0.844\n",
            "batch idx 36: | train loss: 0.3319327235221863 | train accu: 0.852\n",
            "batch idx 37: | train loss: 0.3339199721813202 | train accu: 0.828\n",
            "batch idx 38: | train loss: 0.2831036448478699 | train accu: 0.867\n",
            "batch idx 39: | train loss: 0.33524733781814575 | train accu: 0.797\n",
            "batch idx 40: | train loss: 0.2721936106681824 | train accu: 0.859\n",
            "batch idx 41: | train loss: 0.27745363116264343 | train accu: 0.859\n",
            "batch idx 42: | train loss: 0.4141281843185425 | train accu: 0.820\n",
            "batch idx 43: | train loss: 0.3701217472553253 | train accu: 0.789\n",
            "batch idx 44: | train loss: 0.27918779850006104 | train accu: 0.844\n",
            "batch idx 45: | train loss: 0.2903839349746704 | train accu: 0.844\n",
            "batch idx 46: | train loss: 0.37082764506340027 | train accu: 0.789\n",
            "batch idx 47: | train loss: 0.30161216855049133 | train accu: 0.852\n",
            "batch idx 48: | train loss: 0.30394765734672546 | train accu: 0.852\n",
            "batch idx 49: | train loss: 0.2832105755805969 | train accu: 0.852\n",
            "batch idx 50: | train loss: 0.35120612382888794 | train accu: 0.844\n",
            "batch idx 51: | train loss: 0.31786030530929565 | train accu: 0.867\n",
            "batch idx 52: | train loss: 0.2857804298400879 | train accu: 0.875\n",
            "batch idx 53: | train loss: 0.3085813522338867 | train accu: 0.812\n",
            "batch idx 54: | train loss: 0.35869067907333374 | train accu: 0.797\n",
            "batch idx 55: | train loss: 0.47813916206359863 | train accu: 0.727\n",
            "batch idx 56: | train loss: 0.33805957436561584 | train accu: 0.844\n",
            "batch idx 57: | train loss: 0.2963978946208954 | train accu: 0.852\n",
            "Epoch: 16 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.324 | Train Acc: 83.34%\n",
            "\t Val. Loss: 0.705 |  Val. Acc: 68.41%\n",
            "batch idx 0: | train loss: 0.32730334997177124 | train accu: 0.781\n",
            "batch idx 1: | train loss: 0.2376219928264618 | train accu: 0.859\n",
            "batch idx 2: | train loss: 0.3132334053516388 | train accu: 0.859\n",
            "batch idx 3: | train loss: 0.32127586007118225 | train accu: 0.859\n",
            "batch idx 4: | train loss: 0.3684317171573639 | train accu: 0.789\n",
            "batch idx 5: | train loss: 0.286724328994751 | train accu: 0.875\n",
            "batch idx 6: | train loss: 0.32106199860572815 | train accu: 0.820\n",
            "batch idx 7: | train loss: 0.23801639676094055 | train accu: 0.891\n",
            "batch idx 8: | train loss: 0.3984590470790863 | train accu: 0.805\n",
            "batch idx 9: | train loss: 0.2986692488193512 | train accu: 0.836\n",
            "batch idx 10: | train loss: 0.19321554899215698 | train accu: 0.883\n",
            "batch idx 11: | train loss: 0.2554164230823517 | train accu: 0.875\n",
            "batch idx 12: | train loss: 0.23766250908374786 | train accu: 0.875\n",
            "batch idx 13: | train loss: 0.303288072347641 | train accu: 0.859\n",
            "batch idx 14: | train loss: 0.30584749579429626 | train accu: 0.812\n",
            "batch idx 15: | train loss: 0.2539867162704468 | train accu: 0.883\n",
            "batch idx 16: | train loss: 0.35596132278442383 | train accu: 0.844\n",
            "batch idx 17: | train loss: 0.32157018780708313 | train accu: 0.852\n",
            "batch idx 18: | train loss: 0.3387809991836548 | train accu: 0.828\n",
            "batch idx 19: | train loss: 0.24443617463111877 | train accu: 0.867\n",
            "batch idx 20: | train loss: 0.416607528924942 | train accu: 0.758\n",
            "batch idx 21: | train loss: 0.35493409633636475 | train accu: 0.789\n",
            "batch idx 22: | train loss: 0.4031652510166168 | train accu: 0.773\n",
            "batch idx 23: | train loss: 0.4307335615158081 | train accu: 0.789\n",
            "batch idx 24: | train loss: 0.25241944193840027 | train accu: 0.867\n",
            "batch idx 25: | train loss: 0.30786219239234924 | train accu: 0.805\n",
            "batch idx 26: | train loss: 0.3163502812385559 | train accu: 0.844\n",
            "batch idx 27: | train loss: 0.3202761113643646 | train accu: 0.836\n",
            "batch idx 28: | train loss: 0.2546110451221466 | train accu: 0.875\n",
            "batch idx 29: | train loss: 0.298297643661499 | train accu: 0.844\n",
            "batch idx 30: | train loss: 0.2901987135410309 | train accu: 0.859\n",
            "batch idx 31: | train loss: 0.3670106828212738 | train accu: 0.812\n",
            "batch idx 32: | train loss: 0.2913592755794525 | train accu: 0.844\n",
            "batch idx 33: | train loss: 0.31074270606040955 | train accu: 0.812\n",
            "batch idx 34: | train loss: 0.28021448850631714 | train accu: 0.828\n",
            "batch idx 35: | train loss: 0.2731036841869354 | train accu: 0.820\n",
            "batch idx 36: | train loss: 0.20197035372257233 | train accu: 0.891\n",
            "batch idx 37: | train loss: 0.32157739996910095 | train accu: 0.805\n",
            "batch idx 38: | train loss: 0.3573381006717682 | train accu: 0.820\n",
            "batch idx 39: | train loss: 0.2714974880218506 | train accu: 0.859\n",
            "batch idx 40: | train loss: 0.3016817569732666 | train accu: 0.805\n",
            "batch idx 41: | train loss: 0.3029370903968811 | train accu: 0.867\n",
            "batch idx 42: | train loss: 0.24927587807178497 | train accu: 0.875\n",
            "batch idx 43: | train loss: 0.2648506164550781 | train accu: 0.867\n",
            "batch idx 44: | train loss: 0.22928974032402039 | train accu: 0.891\n",
            "batch idx 45: | train loss: 0.22484879195690155 | train accu: 0.883\n",
            "batch idx 46: | train loss: 0.29621124267578125 | train accu: 0.836\n",
            "batch idx 47: | train loss: 0.31134235858917236 | train accu: 0.852\n",
            "batch idx 48: | train loss: 0.3306119441986084 | train accu: 0.828\n",
            "batch idx 49: | train loss: 0.2625555396080017 | train accu: 0.875\n",
            "batch idx 50: | train loss: 0.287677139043808 | train accu: 0.859\n",
            "batch idx 51: | train loss: 0.24396727979183197 | train accu: 0.852\n",
            "batch idx 52: | train loss: 0.32601985335350037 | train accu: 0.797\n",
            "batch idx 53: | train loss: 0.23353822529315948 | train accu: 0.867\n",
            "batch idx 54: | train loss: 0.3964228928089142 | train accu: 0.852\n",
            "batch idx 55: | train loss: 0.3726983070373535 | train accu: 0.812\n",
            "batch idx 56: | train loss: 0.2935502529144287 | train accu: 0.844\n",
            "batch idx 57: | train loss: 0.26839137077331543 | train accu: 0.836\n",
            "Epoch: 17 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.301 | Train Acc: 84.11%\n",
            "\t Val. Loss: 0.731 |  Val. Acc: 70.07%\n",
            "batch idx 0: | train loss: 0.2770812511444092 | train accu: 0.883\n",
            "batch idx 1: | train loss: 0.3244924545288086 | train accu: 0.805\n",
            "batch idx 2: | train loss: 0.23715104162693024 | train accu: 0.883\n",
            "batch idx 3: | train loss: 0.36711829900741577 | train accu: 0.836\n",
            "batch idx 4: | train loss: 0.26918941736221313 | train accu: 0.828\n",
            "batch idx 5: | train loss: 0.2632380425930023 | train accu: 0.883\n",
            "batch idx 6: | train loss: 0.31511402130126953 | train accu: 0.867\n",
            "batch idx 7: | train loss: 0.294802188873291 | train accu: 0.852\n",
            "batch idx 8: | train loss: 0.21086525917053223 | train accu: 0.898\n",
            "batch idx 9: | train loss: 0.23441213369369507 | train accu: 0.867\n",
            "batch idx 10: | train loss: 0.34231749176979065 | train accu: 0.797\n",
            "batch idx 11: | train loss: 0.19978250563144684 | train accu: 0.891\n",
            "batch idx 12: | train loss: 0.2497897446155548 | train accu: 0.867\n",
            "batch idx 13: | train loss: 0.2960164546966553 | train accu: 0.836\n",
            "batch idx 14: | train loss: 0.3567359447479248 | train accu: 0.836\n",
            "batch idx 15: | train loss: 0.27753904461860657 | train accu: 0.852\n",
            "batch idx 16: | train loss: 0.1868436187505722 | train accu: 0.898\n",
            "batch idx 17: | train loss: 0.27721428871154785 | train accu: 0.859\n",
            "batch idx 18: | train loss: 0.36716732382774353 | train accu: 0.820\n",
            "batch idx 19: | train loss: 0.23507384955883026 | train accu: 0.875\n",
            "batch idx 20: | train loss: 0.27818563580513 | train accu: 0.859\n",
            "batch idx 21: | train loss: 0.262296587228775 | train accu: 0.891\n",
            "batch idx 22: | train loss: 0.3025423586368561 | train accu: 0.820\n",
            "batch idx 23: | train loss: 0.24567994475364685 | train accu: 0.852\n",
            "batch idx 24: | train loss: 0.24754130840301514 | train accu: 0.844\n",
            "batch idx 25: | train loss: 0.309665709733963 | train accu: 0.836\n",
            "batch idx 26: | train loss: 0.2616272568702698 | train accu: 0.867\n",
            "batch idx 27: | train loss: 0.23294657468795776 | train accu: 0.867\n",
            "batch idx 28: | train loss: 0.33425191044807434 | train accu: 0.859\n",
            "batch idx 29: | train loss: 0.303143173456192 | train accu: 0.828\n",
            "batch idx 30: | train loss: 0.3447744846343994 | train accu: 0.781\n",
            "batch idx 31: | train loss: 0.20446686446666718 | train accu: 0.898\n",
            "batch idx 32: | train loss: 0.27689215540885925 | train accu: 0.828\n",
            "batch idx 33: | train loss: 0.20938661694526672 | train accu: 0.914\n",
            "batch idx 34: | train loss: 0.3815249800682068 | train accu: 0.797\n",
            "batch idx 35: | train loss: 0.3048248887062073 | train accu: 0.836\n",
            "batch idx 36: | train loss: 0.2408715784549713 | train accu: 0.875\n",
            "batch idx 37: | train loss: 0.3854611814022064 | train accu: 0.828\n",
            "batch idx 38: | train loss: 0.32093575596809387 | train accu: 0.875\n",
            "batch idx 39: | train loss: 0.2941252291202545 | train accu: 0.859\n",
            "batch idx 40: | train loss: 0.27847933769226074 | train accu: 0.859\n",
            "batch idx 41: | train loss: 0.2424059808254242 | train accu: 0.852\n",
            "batch idx 42: | train loss: 0.278018057346344 | train accu: 0.836\n",
            "batch idx 43: | train loss: 0.2778339684009552 | train accu: 0.836\n",
            "batch idx 44: | train loss: 0.2233637571334839 | train accu: 0.852\n",
            "batch idx 45: | train loss: 0.21766918897628784 | train accu: 0.906\n",
            "batch idx 46: | train loss: 0.2712812125682831 | train accu: 0.875\n",
            "batch idx 47: | train loss: 0.27617281675338745 | train accu: 0.859\n",
            "batch idx 48: | train loss: 0.22800274193286896 | train accu: 0.875\n",
            "batch idx 49: | train loss: 0.28538474440574646 | train accu: 0.844\n",
            "batch idx 50: | train loss: 0.22169405221939087 | train accu: 0.906\n",
            "batch idx 51: | train loss: 0.2878946363925934 | train accu: 0.859\n",
            "batch idx 52: | train loss: 0.20567533373832703 | train accu: 0.875\n",
            "batch idx 53: | train loss: 0.30366867780685425 | train accu: 0.828\n",
            "batch idx 54: | train loss: 0.24572192132472992 | train accu: 0.883\n",
            "batch idx 55: | train loss: 0.2582039535045624 | train accu: 0.883\n",
            "batch idx 56: | train loss: 0.3175417184829712 | train accu: 0.805\n",
            "batch idx 57: | train loss: 0.25392693281173706 | train accu: 0.836\n",
            "Epoch: 18 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.276 | Train Acc: 85.55%\n",
            "\t Val. Loss: 0.801 |  Val. Acc: 69.04%\n",
            "batch idx 0: | train loss: 0.14494259655475616 | train accu: 0.953\n",
            "batch idx 1: | train loss: 0.2413807213306427 | train accu: 0.875\n",
            "batch idx 2: | train loss: 0.26608356833457947 | train accu: 0.914\n",
            "batch idx 3: | train loss: 0.19137302041053772 | train accu: 0.914\n",
            "batch idx 4: | train loss: 0.19719937443733215 | train accu: 0.898\n",
            "batch idx 5: | train loss: 0.17159312963485718 | train accu: 0.914\n",
            "batch idx 6: | train loss: 0.1620441973209381 | train accu: 0.891\n",
            "batch idx 7: | train loss: 0.21133756637573242 | train accu: 0.898\n",
            "batch idx 8: | train loss: 0.3048630356788635 | train accu: 0.867\n",
            "batch idx 9: | train loss: 0.22840173542499542 | train accu: 0.906\n",
            "batch idx 10: | train loss: 0.17183348536491394 | train accu: 0.898\n",
            "batch idx 11: | train loss: 0.22207127511501312 | train accu: 0.867\n",
            "batch idx 12: | train loss: 0.3089575171470642 | train accu: 0.836\n",
            "batch idx 13: | train loss: 0.24010968208312988 | train accu: 0.898\n",
            "batch idx 14: | train loss: 0.22489117085933685 | train accu: 0.867\n",
            "batch idx 15: | train loss: 0.17338480055332184 | train accu: 0.922\n",
            "batch idx 16: | train loss: 0.2143605351448059 | train accu: 0.898\n",
            "batch idx 17: | train loss: 0.3283331096172333 | train accu: 0.859\n",
            "batch idx 18: | train loss: 0.20718181133270264 | train accu: 0.867\n",
            "batch idx 19: | train loss: 0.27621200680732727 | train accu: 0.852\n",
            "batch idx 20: | train loss: 0.26042354106903076 | train accu: 0.875\n",
            "batch idx 21: | train loss: 0.20702388882637024 | train accu: 0.883\n",
            "batch idx 22: | train loss: 0.22180062532424927 | train accu: 0.883\n",
            "batch idx 23: | train loss: 0.2384328991174698 | train accu: 0.828\n",
            "batch idx 24: | train loss: 0.2892487943172455 | train accu: 0.836\n",
            "batch idx 25: | train loss: 0.2636418342590332 | train accu: 0.883\n",
            "batch idx 26: | train loss: 0.2867905795574188 | train accu: 0.906\n",
            "batch idx 27: | train loss: 0.241307333111763 | train accu: 0.891\n",
            "batch idx 28: | train loss: 0.19800007343292236 | train accu: 0.891\n",
            "batch idx 29: | train loss: 0.3045051395893097 | train accu: 0.820\n",
            "batch idx 30: | train loss: 0.2778235673904419 | train accu: 0.828\n",
            "batch idx 31: | train loss: 0.2432468831539154 | train accu: 0.859\n",
            "batch idx 32: | train loss: 0.19886751472949982 | train accu: 0.898\n",
            "batch idx 33: | train loss: 0.24524030089378357 | train accu: 0.867\n",
            "batch idx 34: | train loss: 0.2743823230266571 | train accu: 0.859\n",
            "batch idx 35: | train loss: 0.33803650736808777 | train accu: 0.867\n",
            "batch idx 36: | train loss: 0.2466573268175125 | train accu: 0.852\n",
            "batch idx 37: | train loss: 0.1947508305311203 | train accu: 0.867\n",
            "batch idx 38: | train loss: 0.24786454439163208 | train accu: 0.875\n",
            "batch idx 39: | train loss: 0.24636730551719666 | train accu: 0.898\n",
            "batch idx 40: | train loss: 0.22186964750289917 | train accu: 0.898\n",
            "batch idx 41: | train loss: 0.2968851327896118 | train accu: 0.836\n",
            "batch idx 42: | train loss: 0.20711344480514526 | train accu: 0.883\n",
            "batch idx 43: | train loss: 0.16521556675434113 | train accu: 0.922\n",
            "batch idx 44: | train loss: 0.2707419991493225 | train accu: 0.875\n",
            "batch idx 45: | train loss: 0.3219064176082611 | train accu: 0.836\n",
            "batch idx 46: | train loss: 0.2984851002693176 | train accu: 0.836\n",
            "batch idx 47: | train loss: 0.2481716424226761 | train accu: 0.859\n",
            "batch idx 48: | train loss: 0.3116004467010498 | train accu: 0.875\n",
            "batch idx 49: | train loss: 0.34410127997398376 | train accu: 0.828\n",
            "batch idx 50: | train loss: 0.283088356256485 | train accu: 0.836\n",
            "batch idx 51: | train loss: 0.16195473074913025 | train accu: 0.883\n",
            "batch idx 52: | train loss: 0.30581918358802795 | train accu: 0.820\n",
            "batch idx 53: | train loss: 0.23936067521572113 | train accu: 0.883\n",
            "batch idx 54: | train loss: 0.26000863313674927 | train accu: 0.852\n",
            "batch idx 55: | train loss: 0.21982041001319885 | train accu: 0.922\n",
            "batch idx 56: | train loss: 0.21925069391727448 | train accu: 0.922\n",
            "batch idx 57: | train loss: 0.24248258769512177 | train accu: 0.883\n",
            "Epoch: 19 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.244 | Train Acc: 87.61%\n",
            "\t Val. Loss: 0.805 |  Val. Acc: 68.07%\n",
            "batch idx 0: | train loss: 0.21010227501392365 | train accu: 0.875\n",
            "batch idx 1: | train loss: 0.1660490781068802 | train accu: 0.922\n",
            "batch idx 2: | train loss: 0.2368442565202713 | train accu: 0.859\n",
            "batch idx 3: | train loss: 0.1695093959569931 | train accu: 0.906\n",
            "batch idx 4: | train loss: 0.22364135086536407 | train accu: 0.859\n",
            "batch idx 5: | train loss: 0.23302710056304932 | train accu: 0.875\n",
            "batch idx 6: | train loss: 0.3086164593696594 | train accu: 0.844\n",
            "batch idx 7: | train loss: 0.25574254989624023 | train accu: 0.891\n",
            "batch idx 8: | train loss: 0.25747808814048767 | train accu: 0.875\n",
            "batch idx 9: | train loss: 0.21974091231822968 | train accu: 0.898\n",
            "batch idx 10: | train loss: 0.14069576561450958 | train accu: 0.938\n",
            "batch idx 11: | train loss: 0.23681022226810455 | train accu: 0.852\n",
            "batch idx 12: | train loss: 0.21758274734020233 | train accu: 0.883\n",
            "batch idx 13: | train loss: 0.22928526997566223 | train accu: 0.852\n",
            "batch idx 14: | train loss: 0.18290354311466217 | train accu: 0.906\n",
            "batch idx 15: | train loss: 0.2775759696960449 | train accu: 0.844\n",
            "batch idx 16: | train loss: 0.17114950716495514 | train accu: 0.930\n",
            "batch idx 17: | train loss: 0.323810875415802 | train accu: 0.844\n",
            "batch idx 18: | train loss: 0.3202497363090515 | train accu: 0.859\n",
            "batch idx 19: | train loss: 0.19644695520401 | train accu: 0.891\n",
            "batch idx 20: | train loss: 0.278069406747818 | train accu: 0.836\n",
            "batch idx 21: | train loss: 0.27525410056114197 | train accu: 0.844\n",
            "batch idx 22: | train loss: 0.16195105016231537 | train accu: 0.859\n",
            "batch idx 23: | train loss: 0.26052239537239075 | train accu: 0.859\n",
            "batch idx 24: | train loss: 0.17451009154319763 | train accu: 0.891\n",
            "batch idx 25: | train loss: 0.24237790703773499 | train accu: 0.844\n",
            "batch idx 26: | train loss: 0.29469019174575806 | train accu: 0.867\n",
            "batch idx 27: | train loss: 0.21287600696086884 | train accu: 0.898\n",
            "batch idx 28: | train loss: 0.17031578719615936 | train accu: 0.930\n",
            "batch idx 29: | train loss: 0.17201471328735352 | train accu: 0.906\n",
            "batch idx 30: | train loss: 0.23051820695400238 | train accu: 0.867\n",
            "batch idx 31: | train loss: 0.23588477075099945 | train accu: 0.836\n",
            "batch idx 32: | train loss: 0.2138729691505432 | train accu: 0.867\n",
            "batch idx 33: | train loss: 0.15369853377342224 | train accu: 0.906\n",
            "batch idx 34: | train loss: 0.20718207955360413 | train accu: 0.898\n",
            "batch idx 35: | train loss: 0.24909085035324097 | train accu: 0.898\n",
            "batch idx 36: | train loss: 0.29865947365760803 | train accu: 0.844\n",
            "batch idx 37: | train loss: 0.3496537506580353 | train accu: 0.828\n",
            "batch idx 38: | train loss: 0.276382178068161 | train accu: 0.859\n",
            "batch idx 39: | train loss: 0.1916259378194809 | train accu: 0.914\n",
            "batch idx 40: | train loss: 0.21956267952919006 | train accu: 0.898\n",
            "batch idx 41: | train loss: 0.1428019106388092 | train accu: 0.930\n",
            "batch idx 42: | train loss: 0.27434229850769043 | train accu: 0.875\n",
            "batch idx 43: | train loss: 0.2777557373046875 | train accu: 0.859\n",
            "batch idx 44: | train loss: 0.18498128652572632 | train accu: 0.922\n",
            "batch idx 45: | train loss: 0.2563982903957367 | train accu: 0.891\n",
            "batch idx 46: | train loss: 0.3026079833507538 | train accu: 0.852\n",
            "batch idx 47: | train loss: 0.24969398975372314 | train accu: 0.859\n",
            "batch idx 48: | train loss: 0.1552073210477829 | train accu: 0.875\n",
            "batch idx 49: | train loss: 0.23323887586593628 | train accu: 0.898\n",
            "batch idx 50: | train loss: 0.15134800970554352 | train accu: 0.930\n",
            "batch idx 51: | train loss: 0.13557761907577515 | train accu: 0.953\n",
            "batch idx 52: | train loss: 0.2921917140483856 | train accu: 0.836\n",
            "batch idx 53: | train loss: 0.27225854992866516 | train accu: 0.859\n",
            "batch idx 54: | train loss: 0.19878236949443817 | train accu: 0.883\n",
            "batch idx 55: | train loss: 0.15996287763118744 | train accu: 0.922\n",
            "batch idx 56: | train loss: 0.23783175647258759 | train accu: 0.867\n",
            "batch idx 57: | train loss: 0.24437765777111053 | train accu: 0.867\n",
            "Epoch: 20 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.228 | Train Acc: 87.98%\n",
            "\t Val. Loss: 0.870 |  Val. Acc: 68.90%\n",
            "batch idx 0: | train loss: 0.17621232569217682 | train accu: 0.867\n",
            "batch idx 1: | train loss: 0.12858796119689941 | train accu: 0.953\n",
            "batch idx 2: | train loss: 0.25331032276153564 | train accu: 0.898\n",
            "batch idx 3: | train loss: 0.14229728281497955 | train accu: 0.953\n",
            "batch idx 4: | train loss: 0.12446700781583786 | train accu: 0.969\n",
            "batch idx 5: | train loss: 0.21248404681682587 | train accu: 0.875\n",
            "batch idx 6: | train loss: 0.20602868497371674 | train accu: 0.844\n",
            "batch idx 7: | train loss: 0.24001356959342957 | train accu: 0.883\n",
            "batch idx 8: | train loss: 0.2695405185222626 | train accu: 0.875\n",
            "batch idx 9: | train loss: 0.188631072640419 | train accu: 0.859\n",
            "batch idx 10: | train loss: 0.14082568883895874 | train accu: 0.914\n",
            "batch idx 11: | train loss: 0.14539915323257446 | train accu: 0.953\n",
            "batch idx 12: | train loss: 0.17574338614940643 | train accu: 0.953\n",
            "batch idx 13: | train loss: 0.1932627111673355 | train accu: 0.891\n",
            "batch idx 14: | train loss: 0.14640220999717712 | train accu: 0.930\n",
            "batch idx 15: | train loss: 0.223895862698555 | train accu: 0.852\n",
            "batch idx 16: | train loss: 0.23154610395431519 | train accu: 0.867\n",
            "batch idx 17: | train loss: 0.16276003420352936 | train accu: 0.914\n",
            "batch idx 18: | train loss: 0.16095250844955444 | train accu: 0.906\n",
            "batch idx 19: | train loss: 0.18362587690353394 | train accu: 0.938\n",
            "batch idx 20: | train loss: 0.20809133350849152 | train accu: 0.891\n",
            "batch idx 21: | train loss: 0.16793030500411987 | train accu: 0.914\n",
            "batch idx 22: | train loss: 0.24627812206745148 | train accu: 0.859\n",
            "batch idx 23: | train loss: 0.1458192616701126 | train accu: 0.922\n",
            "batch idx 24: | train loss: 0.20199693739414215 | train accu: 0.922\n",
            "batch idx 25: | train loss: 0.15605424344539642 | train accu: 0.906\n",
            "batch idx 26: | train loss: 0.14631099998950958 | train accu: 0.930\n",
            "batch idx 27: | train loss: 0.15626199543476105 | train accu: 0.945\n",
            "batch idx 28: | train loss: 0.14742952585220337 | train accu: 0.930\n",
            "batch idx 29: | train loss: 0.19935669004917145 | train accu: 0.898\n",
            "batch idx 30: | train loss: 0.2147195041179657 | train accu: 0.883\n",
            "batch idx 31: | train loss: 0.18088647723197937 | train accu: 0.891\n",
            "batch idx 32: | train loss: 0.15285013616085052 | train accu: 0.906\n",
            "batch idx 33: | train loss: 0.1796673834323883 | train accu: 0.898\n",
            "batch idx 34: | train loss: 0.225758358836174 | train accu: 0.844\n",
            "batch idx 35: | train loss: 0.20167629420757294 | train accu: 0.914\n",
            "batch idx 36: | train loss: 0.14737266302108765 | train accu: 0.906\n",
            "batch idx 37: | train loss: 0.23227638006210327 | train accu: 0.914\n",
            "batch idx 38: | train loss: 0.10878603905439377 | train accu: 0.953\n",
            "batch idx 39: | train loss: 0.22354768216609955 | train accu: 0.906\n",
            "batch idx 40: | train loss: 0.18558569252490997 | train accu: 0.914\n",
            "batch idx 41: | train loss: 0.12031000107526779 | train accu: 0.930\n",
            "batch idx 42: | train loss: 0.2673678994178772 | train accu: 0.844\n",
            "batch idx 43: | train loss: 0.24523144960403442 | train accu: 0.852\n",
            "batch idx 44: | train loss: 0.1588171273469925 | train accu: 0.906\n",
            "batch idx 45: | train loss: 0.1451364904642105 | train accu: 0.898\n",
            "batch idx 46: | train loss: 0.18297982215881348 | train accu: 0.891\n",
            "batch idx 47: | train loss: 0.22385409474372864 | train accu: 0.891\n",
            "batch idx 48: | train loss: 0.18313288688659668 | train accu: 0.914\n",
            "batch idx 49: | train loss: 0.15730172395706177 | train accu: 0.914\n",
            "batch idx 50: | train loss: 0.22589650750160217 | train accu: 0.867\n",
            "batch idx 51: | train loss: 0.20737740397453308 | train accu: 0.898\n",
            "batch idx 52: | train loss: 0.22612880170345306 | train accu: 0.930\n",
            "batch idx 53: | train loss: 0.12866617739200592 | train accu: 0.930\n",
            "batch idx 54: | train loss: 0.38569965958595276 | train accu: 0.828\n",
            "batch idx 55: | train loss: 0.186558797955513 | train accu: 0.867\n",
            "batch idx 56: | train loss: 0.21463832259178162 | train accu: 0.875\n",
            "batch idx 57: | train loss: 0.1886865496635437 | train accu: 0.906\n",
            "Epoch: 21 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.189 | Train Acc: 90.14%\n",
            "\t Val. Loss: 1.000 |  Val. Acc: 66.65%\n",
            "batch idx 0: | train loss: 0.21874065697193146 | train accu: 0.898\n",
            "batch idx 1: | train loss: 0.15671734511852264 | train accu: 0.938\n",
            "batch idx 2: | train loss: 0.17145608365535736 | train accu: 0.938\n",
            "batch idx 3: | train loss: 0.16487105190753937 | train accu: 0.914\n",
            "batch idx 4: | train loss: 0.15239150822162628 | train accu: 0.930\n",
            "batch idx 5: | train loss: 0.13672751188278198 | train accu: 0.914\n",
            "batch idx 6: | train loss: 0.15310068428516388 | train accu: 0.906\n",
            "batch idx 7: | train loss: 0.12324806302785873 | train accu: 0.906\n",
            "batch idx 8: | train loss: 0.1847318410873413 | train accu: 0.891\n",
            "batch idx 9: | train loss: 0.15171918272972107 | train accu: 0.930\n",
            "batch idx 10: | train loss: 0.19152012467384338 | train accu: 0.922\n",
            "batch idx 11: | train loss: 0.21368031203746796 | train accu: 0.883\n",
            "batch idx 12: | train loss: 0.1796022355556488 | train accu: 0.898\n",
            "batch idx 13: | train loss: 0.19566136598587036 | train accu: 0.906\n",
            "batch idx 14: | train loss: 0.16057737171649933 | train accu: 0.930\n",
            "batch idx 15: | train loss: 0.18173375725746155 | train accu: 0.898\n",
            "batch idx 16: | train loss: 0.1827220767736435 | train accu: 0.914\n",
            "batch idx 17: | train loss: 0.2245980054140091 | train accu: 0.898\n",
            "batch idx 18: | train loss: 0.12156230956315994 | train accu: 0.961\n",
            "batch idx 19: | train loss: 0.16461233794689178 | train accu: 0.898\n",
            "batch idx 20: | train loss: 0.17336530983448029 | train accu: 0.922\n",
            "batch idx 21: | train loss: 0.17997044324874878 | train accu: 0.930\n",
            "batch idx 22: | train loss: 0.12050794810056686 | train accu: 0.930\n",
            "batch idx 23: | train loss: 0.20556779205799103 | train accu: 0.883\n",
            "batch idx 24: | train loss: 0.14009854197502136 | train accu: 0.914\n",
            "batch idx 25: | train loss: 0.21391838788986206 | train accu: 0.867\n",
            "batch idx 26: | train loss: 0.1595451384782791 | train accu: 0.906\n",
            "batch idx 27: | train loss: 0.25221163034439087 | train accu: 0.891\n",
            "batch idx 28: | train loss: 0.26703041791915894 | train accu: 0.922\n",
            "batch idx 29: | train loss: 0.20822080969810486 | train accu: 0.883\n",
            "batch idx 30: | train loss: 0.14336729049682617 | train accu: 0.938\n",
            "batch idx 31: | train loss: 0.15131470561027527 | train accu: 0.906\n",
            "batch idx 32: | train loss: 0.2123974710702896 | train accu: 0.891\n",
            "batch idx 33: | train loss: 0.18327374756336212 | train accu: 0.891\n",
            "batch idx 34: | train loss: 0.15542683005332947 | train accu: 0.914\n",
            "batch idx 35: | train loss: 0.23078687489032745 | train accu: 0.828\n",
            "batch idx 36: | train loss: 0.26390132308006287 | train accu: 0.852\n",
            "batch idx 37: | train loss: 0.19239474833011627 | train accu: 0.930\n",
            "batch idx 38: | train loss: 0.3175140917301178 | train accu: 0.852\n",
            "batch idx 39: | train loss: 0.21190817654132843 | train accu: 0.906\n",
            "batch idx 40: | train loss: 0.22977477312088013 | train accu: 0.891\n",
            "batch idx 41: | train loss: 0.11316041648387909 | train accu: 0.945\n",
            "batch idx 42: | train loss: 0.19575238227844238 | train accu: 0.883\n",
            "batch idx 43: | train loss: 0.18753892183303833 | train accu: 0.898\n",
            "batch idx 44: | train loss: 0.23280733823776245 | train accu: 0.891\n",
            "batch idx 45: | train loss: 0.14813962578773499 | train accu: 0.914\n",
            "batch idx 46: | train loss: 0.20701360702514648 | train accu: 0.906\n",
            "batch idx 47: | train loss: 0.1541181057691574 | train accu: 0.922\n",
            "batch idx 48: | train loss: 0.17951205372810364 | train accu: 0.898\n",
            "batch idx 49: | train loss: 0.19203396141529083 | train accu: 0.875\n",
            "batch idx 50: | train loss: 0.13809095323085785 | train accu: 0.922\n",
            "batch idx 51: | train loss: 0.11805342882871628 | train accu: 0.914\n",
            "batch idx 52: | train loss: 0.20143930613994598 | train accu: 0.898\n",
            "batch idx 53: | train loss: 0.1402827948331833 | train accu: 0.914\n",
            "batch idx 54: | train loss: 0.21051359176635742 | train accu: 0.914\n",
            "batch idx 55: | train loss: 0.10647071152925491 | train accu: 0.977\n",
            "batch idx 56: | train loss: 0.216801717877388 | train accu: 0.883\n",
            "batch idx 57: | train loss: 0.15054671466350555 | train accu: 0.898\n",
            "Epoch: 22 | Epoch Time: 3m 41s\n",
            "\tTrain Loss: 0.182 | Train Acc: 90.64%\n",
            "\t Val. Loss: 1.051 |  Val. Acc: 67.29%\n",
            "batch idx 0: | train loss: 0.22339113056659698 | train accu: 0.891\n",
            "batch idx 1: | train loss: 0.23651495575904846 | train accu: 0.852\n",
            "batch idx 2: | train loss: 0.15190389752388 | train accu: 0.906\n",
            "batch idx 3: | train loss: 0.15231819450855255 | train accu: 0.906\n",
            "batch idx 4: | train loss: 0.20256082713603973 | train accu: 0.891\n",
            "batch idx 5: | train loss: 0.11844348907470703 | train accu: 0.906\n",
            "batch idx 6: | train loss: 0.19837966561317444 | train accu: 0.898\n",
            "batch idx 7: | train loss: 0.13266433775424957 | train accu: 0.945\n",
            "batch idx 8: | train loss: 0.15368935465812683 | train accu: 0.938\n",
            "batch idx 9: | train loss: 0.218400239944458 | train accu: 0.891\n",
            "batch idx 10: | train loss: 0.17835870385169983 | train accu: 0.867\n",
            "batch idx 11: | train loss: 0.11099877208471298 | train accu: 0.953\n",
            "batch idx 12: | train loss: 0.09657378494739532 | train accu: 0.953\n",
            "batch idx 13: | train loss: 0.1788458377122879 | train accu: 0.906\n",
            "batch idx 14: | train loss: 0.14297184348106384 | train accu: 0.906\n",
            "batch idx 15: | train loss: 0.18250922858715057 | train accu: 0.891\n",
            "batch idx 16: | train loss: 0.14134034514427185 | train accu: 0.898\n",
            "batch idx 17: | train loss: 0.1888808310031891 | train accu: 0.914\n",
            "batch idx 18: | train loss: 0.17892473936080933 | train accu: 0.914\n",
            "batch idx 19: | train loss: 0.18992820382118225 | train accu: 0.930\n",
            "batch idx 20: | train loss: 0.12169107794761658 | train accu: 0.945\n",
            "batch idx 21: | train loss: 0.12131405621767044 | train accu: 0.945\n",
            "batch idx 22: | train loss: 0.22337834537029266 | train accu: 0.891\n",
            "batch idx 23: | train loss: 0.17057488858699799 | train accu: 0.930\n",
            "batch idx 24: | train loss: 0.20108550786972046 | train accu: 0.852\n",
            "batch idx 25: | train loss: 0.11553192883729935 | train accu: 0.953\n",
            "batch idx 26: | train loss: 0.15112419426441193 | train accu: 0.891\n",
            "batch idx 27: | train loss: 0.13118040561676025 | train accu: 0.922\n",
            "batch idx 28: | train loss: 0.1980717033147812 | train accu: 0.891\n",
            "batch idx 29: | train loss: 0.17199288308620453 | train accu: 0.914\n",
            "batch idx 30: | train loss: 0.155630961060524 | train accu: 0.930\n",
            "batch idx 31: | train loss: 0.1443520039319992 | train accu: 0.930\n",
            "batch idx 32: | train loss: 0.1291685849428177 | train accu: 0.930\n",
            "batch idx 33: | train loss: 0.1207149401307106 | train accu: 0.922\n",
            "batch idx 34: | train loss: 0.16396185755729675 | train accu: 0.914\n",
            "batch idx 35: | train loss: 0.265906423330307 | train accu: 0.867\n",
            "batch idx 36: | train loss: 0.3003275394439697 | train accu: 0.836\n",
            "batch idx 37: | train loss: 0.16107064485549927 | train accu: 0.898\n",
            "batch idx 38: | train loss: 0.2652101516723633 | train accu: 0.875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-77c09447fc58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-3667789e3467>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, optimizer, criterion)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-ce05651ddca7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m#embedded = [batch size, sent len, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#hidden = [n layers * n directions, batch size, emb dim]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 727\u001b[0;31m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmkY8rQnoIsW",
        "colab_type": "code",
        "outputId": "d43de9cc-92d5-4a4c-e865-031af97d3936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_state_dict(torch.load('best_model_3.pt'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhZ7azqzEzxY",
        "colab_type": "code",
        "outputId": "dbf8ef34-d9c4-4573-88eb-d5cc15b174e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "valid_loss, valid_acc, valid_rocauc, valid_f1 = evaluate(model, valid_loader, criterion)\n",
        "print(\"Valid loss: {} | Valid Acc: {:.3f} | Valid ROC-AUC: {} | Valid f1: {}\".format(\n",
        "    valid_loss, valid_acc, valid_rocauc, valid_f1))\n",
        "test_loss, test_acc, test_rocauc, test_f1 = evaluate(model, test_loader, criterion)\n",
        "print(\"Test loss: {} | Test Acc: {:.3f} | Test ROC-AUC: {} | Test f1: {}\".format(\n",
        "    test_loss, test_acc, test_rocauc, test_f1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Valid loss: 0.5757627580314875 | Valid Acc: 0.688 | Valid ROC-AUC: 0.8662147521972656 | Valid f1: 0.6884765625\n",
            "Test loss: 0.500682552655538 | Test Acc: 0.776 | Test ROC-AUC: 0.9048258463541666 | Test f1: 0.7760416666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Off8zqkRHVeK",
        "colab_type": "code",
        "outputId": "e4055bdc-64b8-42fe-d178-3db779fe7da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a= \"COVID fears in Toronto: to me single biggest worry right now is this: the situation is massively worse for the average person now than it was at peak. why? Because at peak it was almost all LTCFs. Now? Unchecked community spread. That's terrifying to me.\"\n",
        "a_encoded = tokenizer.encode(a, add_special_tokens=True)\n",
        "a_final = torch.tensor(a_encoded + [0] * (max_len - len(a_encoded))).view(1, -1).to(device)\n",
        "softmax = nn.Softmax(dim=1)\n",
        "probs = softmax(model(a_final))\n",
        "probs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.7234, 0.2172, 0.0594]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpS-CoSrIVZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}